["```py\nTable(\n    \"sometable\",\n    metadata,\n    Column(\n        \"id\", Integer, Sequence(\"some_id_seq\", start=1), primary_key=True\n    )\n)\n```", "```py\nfrom sqlalchemy import Table, Column, MetaData, Integer, Computed\n\nmetadata = MetaData()\n\ndata = Table(\n    \"data\",\n    metadata,\n    Column(\n        'id', Integer, Identity(start=42, cycle=True), primary_key=True\n    ),\n    Column('data', String)\n)\n```", "```py\nCREATE  TABLE  data  (\n  id  INTEGER  GENERATED  BY  DEFAULT  AS  IDENTITY  (START  WITH  42  CYCLE),\n  data  VARCHAR,\n  PRIMARY  KEY  (id)\n)\n```", "```py\nfrom sqlalchemy.schema import CreateColumn\nfrom sqlalchemy.ext.compiler import compiles\n\n@compiles(CreateColumn, 'postgresql')\ndef use_identity(element, compiler, **kw):\n    text = compiler.visit_create_column(element, **kw)\n    text = text.replace(\n        \"SERIAL\", \"INT GENERATED BY DEFAULT AS IDENTITY\"\n     )\n    return text\n```", "```py\nt = Table(\n    't', m,\n    Column('id', Integer, primary_key=True),\n    Column('data', String)\n)\n```", "```py\nCREATE TABLE t (\n    id INT GENERATED BY DEFAULT AS IDENTITY,\n    data VARCHAR,\n    PRIMARY KEY (id)\n)\n```", "```py\nwith engine.connect() as conn:\n    result = conn.execution_options(stream_results=True).execute(text(\"select * from table\"))\n```", "```py\nengine = create_engine(\n    \"postgresql+pg8000://scott:tiger@localhost/test\",\n    isolation_level = \"REPEATABLE READ\"\n)\n```", "```py\nwith engine.connect() as conn:\n    conn = conn.execution_options(\n        isolation_level=\"REPEATABLE READ\"\n    )\n    with conn.begin():\n        # ... work with transaction\n```", "```py\nwith engine.connect() as conn:\n    conn = conn.execution_options(\n        isolation_level=\"SERIALIZABLE\",\n        postgresql_readonly=True,\n        postgresql_deferrable=True\n    )\n    with conn.begin():\n        #  ... work with transaction\n```", "```py\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import event\n\npostgresql_engine = create_engine(\n    \"postgresql+pyscopg2://scott:tiger@hostname/dbname\",\n\n    # disable default reset-on-return scheme\n    pool_reset_on_return=None,\n)\n\n@event.listens_for(postgresql_engine, \"reset\")\ndef _reset_postgresql(dbapi_connection, connection_record, reset_state):\n    if not reset_state.terminate_only:\n        dbapi_connection.execute(\"CLOSE ALL\")\n        dbapi_connection.execute(\"RESET ALL\")\n        dbapi_connection.execute(\"DISCARD TEMP\")\n\n    # so that the DBAPI itself knows that the connection has been\n    # reset\n    dbapi_connection.rollback()\n```", "```py\nfrom sqlalchemy import event\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"postgresql+psycopg2://scott:tiger@host/dbname\")\n\n@event.listens_for(engine, \"connect\", insert=True)\ndef set_search_path(dbapi_connection, connection_record):\n    existing_autocommit = dbapi_connection.autocommit\n    dbapi_connection.autocommit = True\n    cursor = dbapi_connection.cursor()\n    cursor.execute(\"SET SESSION search_path='%s'\" % schema_name)\n    cursor.close()\n    dbapi_connection.autocommit = existing_autocommit\n```", "```py\ntest=> select current_schema();\ncurrent_schema\n----------------\npublic\n(1 row)\n```", "```py\ntest=> select current_schema();\ncurrent_schema\n----------------\npublic\n(1 row)\n\ntest=> create schema scott;\nCREATE SCHEMA\ntest=> select current_schema();\ncurrent_schema\n----------------\nscott\n(1 row)\n```", "```py\ntest=> show search_path;\nsearch_path\n-----------------\n\"$user\", public\n(1 row)\n```", "```py\ntest=> CREATE TABLE test_schema.referred(id INTEGER PRIMARY KEY);\nCREATE TABLE\ntest=> CREATE TABLE referring(\ntest(>         id INTEGER PRIMARY KEY,\ntest(>         referred_id INTEGER REFERENCES test_schema.referred(id));\nCREATE TABLE\ntest=> SET search_path TO public, test_schema;\ntest=> SELECT pg_catalog.pg_get_constraintdef(r.oid, true) FROM\ntest-> pg_catalog.pg_class c JOIN pg_catalog.pg_namespace n\ntest-> ON n.oid = c.relnamespace\ntest-> JOIN pg_catalog.pg_constraint r  ON c.oid = r.conrelid\ntest-> WHERE c.relname='referring' AND r.contype = 'f'\ntest-> ;\n               pg_get_constraintdef\n---------------------------------------------------\n FOREIGN KEY (referred_id) REFERENCES referred(id)\n(1 row)\n```", "```py\ntest=> SET search_path TO public;\nSET\n```", "```py\ntest=> SELECT pg_catalog.pg_get_constraintdef(r.oid, true) FROM\ntest-> pg_catalog.pg_class c JOIN pg_catalog.pg_namespace n\ntest-> ON n.oid = c.relnamespace\ntest-> JOIN pg_catalog.pg_constraint r  ON c.oid = r.conrelid\ntest-> WHERE c.relname='referring' AND r.contype = 'f';\n                     pg_get_constraintdef\n---------------------------------------------------------------\n FOREIGN KEY (referred_id) REFERENCES test_schema.referred(id)\n(1 row)\n```", "```py\n>>> from sqlalchemy import Table, MetaData, create_engine, text\n>>> engine = create_engine(\"postgresql+psycopg2://scott:tiger@localhost/test\")\n>>> with engine.connect() as conn:\n...     conn.execute(text(\"SET search_path TO test_schema, public\"))\n...     metadata_obj = MetaData()\n...     referring = Table('referring', metadata_obj,\n...                       autoload_with=conn)\n...\n<sqlalchemy.engine.result.CursorResult object at 0x101612ed0>\n```", "```py\n>>> metadata_obj.tables['referred'].schema is None\nTrue\n```", "```py\n>>> with engine.connect() as conn:\n...     conn.execute(text(\"SET search_path TO test_schema, public\"))\n...     metadata_obj = MetaData()\n...     referring = Table('referring', metadata_obj,\n...                       autoload_with=conn,\n...                       postgresql_ignore_search_path=True)\n...\n<sqlalchemy.engine.result.CursorResult object at 0x1016126d0>\n```", "```py\n>>> metadata_obj.tables['test_schema.referred'].schema\n'test_schema'\n```", "```py\n# INSERT..RETURNING\nresult = table.insert().returning(table.c.col1, table.c.col2).\\\n    values(name='foo')\nprint(result.fetchall())\n\n# UPDATE..RETURNING\nresult = table.update().returning(table.c.col1, table.c.col2).\\\n    where(table.c.name=='foo').values(name='bar')\nprint(result.fetchall())\n\n# DELETE..RETURNING\nresult = table.delete().returning(table.c.col1, table.c.col2).\\\n    where(table.c.name=='foo')\nprint(result.fetchall())\n```", "```py\n>>> from sqlalchemy.dialects.postgresql import insert\n>>> insert_stmt = insert(my_table).values(\n...     id='some_existing_id',\n...     data='inserted value')\n>>> do_nothing_stmt = insert_stmt.on_conflict_do_nothing(\n...     index_elements=['id']\n... )\n>>> print(do_nothing_stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  (id)  DO  NOTHING\n>>> do_update_stmt = insert_stmt.on_conflict_do_update(\n...     constraint='pk_my_table',\n...     set_=dict(data='updated value')\n... )\n>>> print(do_update_stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  ON  CONSTRAINT  pk_my_table  DO  UPDATE  SET  data  =  %(param_1)s \n```", "```py\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     index_elements=['id'],\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     index_elements=[my_table.c.id],\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s \n    ```", "```py\n    >>> stmt = insert(my_table).values(user_email='a@b.com', data='inserted data')\n    >>> stmt = stmt.on_conflict_do_update(\n    ...     index_elements=[my_table.c.user_email],\n    ...     index_where=my_table.c.user_email.like('%@gmail.com'),\n    ...     set_=dict(data=stmt.excluded.data)\n    ... )\n    >>> print(stmt)\n    INSERT  INTO  my_table  (data,  user_email)\n    VALUES  (%(data)s,  %(user_email)s)  ON  CONFLICT  (user_email)\n    WHERE  user_email  LIKE  %(user_email_1)s  DO  UPDATE  SET  data  =  excluded.data \n    ```", "```py\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     constraint='my_table_idx_1',\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  ON  CONSTRAINT  my_table_idx_1  DO  UPDATE  SET  data  =  %(param_1)s\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     constraint='my_table_pk',\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  ON  CONSTRAINT  my_table_pk  DO  UPDATE  SET  data  =  %(param_1)s \n    ```", "```py\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     constraint=my_table.primary_key,\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s \n    ```", "```py\n>>> stmt = insert(my_table).values(id='some_id', data='inserted value')\n>>> do_update_stmt = stmt.on_conflict_do_update(\n...     index_elements=['id'],\n...     set_=dict(data='updated value')\n... )\n>>> print(do_update_stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s \n```", "```py\n>>> stmt = insert(my_table).values(\n...     id='some_id',\n...     data='inserted value',\n...     author='jlh'\n... )\n>>> do_update_stmt = stmt.on_conflict_do_update(\n...     index_elements=['id'],\n...     set_=dict(data='updated value', author=stmt.excluded.author)\n... )\n>>> print(do_update_stmt)\nINSERT  INTO  my_table  (id,  data,  author)\nVALUES  (%(id)s,  %(data)s,  %(author)s)\nON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s,  author  =  excluded.author \n```", "```py\n>>> stmt = insert(my_table).values(\n...     id='some_id',\n...     data='inserted value',\n...     author='jlh'\n... )\n>>> on_update_stmt = stmt.on_conflict_do_update(\n...     index_elements=['id'],\n...     set_=dict(data='updated value', author=stmt.excluded.author),\n...     where=(my_table.c.status == 2)\n... )\n>>> print(on_update_stmt)\nINSERT  INTO  my_table  (id,  data,  author)\nVALUES  (%(id)s,  %(data)s,  %(author)s)\nON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s,  author  =  excluded.author\nWHERE  my_table.status  =  %(status_1)s \n```", "```py\n>>> stmt = insert(my_table).values(id='some_id', data='inserted value')\n>>> stmt = stmt.on_conflict_do_nothing(index_elements=['id'])\n>>> print(stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  (id)  DO  NOTHING \n```", "```py\n>>> stmt = insert(my_table).values(id='some_id', data='inserted value')\n>>> stmt = stmt.on_conflict_do_nothing()\n>>> print(stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  DO  NOTHING \n```", "```py\nselect(sometable.c.text.match(\"search string\"))\n```", "```py\nSELECT text @@ plainto_tsquery('search string') FROM table\n```", "```py\nfrom sqlalchemy import func\n\nselect(\n    sometable.c.text.bool_op(\"@@\")(func.to_tsquery(\"search string\"))\n)\n```", "```py\nSELECT text @@ to_tsquery('search string') FROM table\n```", "```py\nselect(\n    func.to_tsquery('cat').bool_op(\"@>\")(func.to_tsquery('cat & rat'))\n)\n```", "```py\nSELECT  to_tsquery('cat')  @>  to_tsquery('cat & rat')\n```", "```py\nfrom sqlalchemy.dialects.postgresql import TSVECTOR\nfrom sqlalchemy import select, cast\nselect(cast(\"some text\", TSVECTOR))\n```", "```py\nSELECT CAST('some text' AS TSVECTOR) AS anon_1\n```", "```py\nselect(mytable.c.id).where(\n    mytable.c.title.match('somestring', postgresql_regconfig='english')\n)\n```", "```py\nSELECT mytable.id FROM mytable\nWHERE mytable.title @@ plainto_tsquery('english', 'somestring')\n```", "```py\nselect(mytable.c.id).where(\n    func.to_tsvector(\"english\", mytable.c.title).bool_op(\"@@\")(\n        func.to_tsquery(\"english\", \"somestring\")\n    )\n)\n```", "```py\nSELECT mytable.id FROM mytable\nWHERE to_tsvector('english', mytable.title) @@\n    to_tsquery('english', 'somestring')\n```", "```py\n# SELECT ... FROM ONLY ...\nresult = table.select().with_hint(table, 'ONLY', 'postgresql')\nprint(result.fetchall())\n\n# UPDATE ONLY ...\ntable.update(values=dict(foo='bar')).with_hint('ONLY',\n                                               dialect_name='postgresql')\n\n# DELETE FROM ONLY ...\ntable.delete().with_hint('ONLY', dialect_name='postgresql')\n```", "```py\nIndex(\"my_index\", table.c.x, postgresql_include=['y'])\n```", "```py\nIndex('my_index', my_table.c.id, postgresql_where=my_table.c.value > 10)\n```", "```py\nIndex(\n    'my_index', my_table.c.id, my_table.c.data,\n    postgresql_ops={\n        'data': 'text_pattern_ops',\n        'id': 'int4_ops'\n    })\n```", "```py\nIndex(\n    'my_index', my_table.c.id,\n    func.lower(my_table.c.data).label('data_lower'),\n    postgresql_ops={\n        'data_lower': 'text_pattern_ops',\n        'id': 'int4_ops'\n    })\n```", "```py\nIndex('my_index', my_table.c.data, postgresql_using='gin')\n```", "```py\nIndex('my_index', my_table.c.data, postgresql_with={\"fillfactor\": 50})\n```", "```py\nIndex('my_index', my_table.c.data, postgresql_tablespace='my_tablespace')\n```", "```py\ntbl = Table('testtbl', m, Column('data', Integer))\n\nidx1 = Index('test_idx1', tbl.c.data, postgresql_concurrently=True)\n```", "```py\nCREATE INDEX CONCURRENTLY test_idx1 ON testtbl (data)\n```", "```py\nDROP INDEX CONCURRENTLY test_idx1\n```", "```py\nmetadata = MetaData()\ntable = Table(\n    \"foo\", metadata,\n    Column(\"id\", String))\nindex = Index(\n    \"foo_idx\", table.c.id, postgresql_concurrently=True)\n\nwith engine.connect() as conn:\n    with conn.execution_options(isolation_level='AUTOCOMMIT'):\n        table.create(conn)\n```", "```py\nfrom sqlalchemy import create_engine, inspect\n\nengine = create_engine(\"postgresql+psycopg2://localhost/test\")\ninsp = inspect(engine)  # will be a PGInspector\n\nprint(insp.get_enums())\n```", "```py\nclass sqlalchemy.dialects.postgresql.base.PGInspector\n```", "```py\nmethod get_domains(schema: str | None = None) \u2192 List[ReflectedDomain]\n```", "```py\nmethod get_enums(schema: str | None = None) \u2192 List[ReflectedEnum]\n```", "```py\nmethod get_foreign_table_names(schema: str | None = None) \u2192 List[str]\n```", "```py\nmethod get_table_oid(table_name: str, schema: str | None = None) \u2192 int\n```", "```py\nmethod has_type(type_name: str, schema: str | None = None, **kw: Any) \u2192 bool\n```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_inherits=\"some_supertable\")\n\n    Table(\"some_table\", metadata, ..., postgresql_inherits=(\"t1\", \"t2\", ...))\n    ```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_on_commit='PRESERVE ROWS')\n    ```", "```py\n    Table(\"some_table\", metadata, ...,\n          postgresql_partition_by='LIST (part_column)')\n\n    .. versionadded:: 1.2.6\n    ```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_tablespace='some_tablespace')\n    ```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_using='heap')\n\n    .. versionadded:: 2.0.26\n    ```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_with_oids=True)\n    ```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_with_oids=False)\n    ```", "```py\n    def update():\n        op.create_foreign_key(\n            \"fk_user_address\",\n            \"address\",\n            \"user\",\n            [\"user_id\"],\n            [\"id\"],\n            postgresql_not_valid=True\n        )\n    ```", "```py\n    CheckConstraint(\"some_field IS NOT NULL\", postgresql_not_valid=True)\n\n    ForeignKeyConstraint([\"some_id\"], [\"some_table.some_id\"], postgresql_not_valid=True)\n    ```", "```py\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(func.json_each('{\"a\":\"foo\", \"b\":\"bar\"}').table_valued(\"key\", \"value\"))\n    >>> print(stmt)\n    SELECT  anon_1.key,  anon_1.value\n    FROM  json_each(:json_each_1)  AS  anon_1 \n    ```", "```py\n    >>> from sqlalchemy import select, func, literal_column\n    >>> stmt = select(\n    ...     func.json_populate_record(\n    ...         literal_column(\"null::myrowtype\"),\n    ...         '{\"a\":1,\"b\":2}'\n    ...     ).table_valued(\"a\", \"b\", name=\"x\")\n    ... )\n    >>> print(stmt)\n    SELECT  x.a,  x.b\n    FROM  json_populate_record(null::myrowtype,  :json_populate_record_1)  AS  x \n    ```", "```py\n    >>> from sqlalchemy import select, func, column, Integer, Text\n    >>> stmt = select(\n    ...     func.json_to_record('{\"a\":1,\"b\":[1,2,3],\"c\":\"bar\"}').table_valued(\n    ...         column(\"a\", Integer), column(\"b\", Text), column(\"d\", Text),\n    ...     ).render_derived(name=\"x\", with_types=True)\n    ... )\n    >>> print(stmt)\n    SELECT  x.a,  x.b,  x.d\n    FROM  json_to_record(:json_to_record_1)  AS  x(a  INTEGER,  b  TEXT,  d  TEXT) \n    ```", "```py\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(\n    ...     func.generate_series(4, 1, -1).\n    ...     table_valued(\"value\", with_ordinality=\"ordinality\").\n    ...     render_derived()\n    ... )\n    >>> print(stmt)\n    SELECT  anon_1.value,  anon_1.ordinality\n    FROM  generate_series(:generate_series_1,  :generate_series_2,  :generate_series_3)\n    WITH  ORDINALITY  AS  anon_1(value,  ordinality) \n    ```", "```py\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(func.json_array_elements('[\"one\", \"two\"]').column_valued(\"x\"))\n    >>> print(stmt)\n    SELECT  x\n    FROM  json_array_elements(:json_array_elements_1)  AS  x \n    ```", "```py\n    >>> from sqlalchemy.dialects.postgresql import array\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(func.unnest(array([1, 2])).column_valued())\n    >>> print(stmt)\n    SELECT  anon_1\n    FROM  unnest(ARRAY[%(param_1)s,  %(param_2)s])  AS  anon_1 \n    ```", "```py\n    >>> from sqlalchemy import table, column, ARRAY, Integer\n    >>> from sqlalchemy import select, func\n    >>> t = table(\"t\", column('value', ARRAY(Integer)))\n    >>> stmt = select(func.unnest(t.c.value).column_valued(\"unnested_value\"))\n    >>> print(stmt)\n    SELECT  unnested_value\n    FROM  unnest(t.value)  AS  unnested_value \n    ```", "```py\n>>> from sqlalchemy import table, column, func, tuple_\n>>> t = table(\"t\", column(\"id\"), column(\"fk\"))\n>>> stmt = t.select().where(\n...     tuple_(t.c.id, t.c.fk) > (1,2)\n... ).where(\n...     func.ROW(t.c.id, t.c.fk) < func.ROW(3, 7)\n... )\n>>> print(stmt)\nSELECT  t.id,  t.fk\nFROM  t\nWHERE  (t.id,  t.fk)  >  (:param_1,  :param_2)  AND  ROW(t.id,  t.fk)  <  ROW(:ROW_1,  :ROW_2) \n```", "```py\n>>> from sqlalchemy import table, column, func, select\n>>> a = table( \"a\", column(\"id\"), column(\"x\"), column(\"y\"))\n>>> stmt = select(func.row_to_json(a.table_valued()))\n>>> print(stmt)\nSELECT  row_to_json(a)  AS  row_to_json_1\nFROM  a \n```", "```py\nfrom sqlalchemy import TypeDecorator\nfrom sqlalchemy.dialects.postgresql import ARRAY\n\nclass ArrayOfEnum(TypeDecorator):\n    impl = ARRAY\n\n    def bind_expression(self, bindvalue):\n        return sa.cast(bindvalue, self)\n\n    def result_processor(self, dialect, coltype):\n        super_rp = super(ArrayOfEnum, self).result_processor(dialect, coltype)\n\n        def handle_raw_string(value):\n            inner = re.match(r\"^{(.*)}$\", value).group(1)\n            return inner.split(\",\") if inner else []\n\n        def process(value):\n            if value is None:\n                return None\n            return super_rp(handle_raw_string(value))\n\n        return process\n```", "```py\nTable(\n    \"mydata\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"data\", ArrayOfEnum(ENUM(\"a\", \"b\", \"c\", name=\"myenum\"))),\n)\n```", "```py\nclass CastingArray(ARRAY):\n    def bind_expression(self, bindvalue):\n        return sa.cast(bindvalue, self)\n```", "```py\nTable(\n    \"mydata\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"data\", CastingArray(JSONB)),\n)\n```", "```py\nfrom datetime import datetime\n\nfrom sqlalchemy.dialects.postgresql import Range\nfrom sqlalchemy.dialects.postgresql import TSRANGE\nfrom sqlalchemy.orm import DeclarativeBase\nfrom sqlalchemy.orm import Mapped\nfrom sqlalchemy.orm import mapped_column\n\nclass Base(DeclarativeBase):\n    pass\n\nclass RoomBooking(Base):\n    __tablename__ = \"room_booking\"\n\n    id: Mapped[int] = mapped_column(primary_key=True)\n    room: Mapped[str]\n    during: Mapped[Range[datetime]] = mapped_column(TSRANGE)\n```", "```py\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import Session\n\nengine = create_engine(\"postgresql+psycopg://scott:tiger@pg14/dbname\")\n\nBase.metadata.create_all(engine)\n\nwith Session(engine) as session:\n    booking = RoomBooking(\n        room=\"101\", during=Range(datetime(2013, 3, 23), datetime(2013, 3, 25))\n    )\n    session.add(booking)\n    session.commit()\n```", "```py\nfrom sqlalchemy import select\n\nwith Session(engine) as session:\n    for row in session.execute(select(RoomBooking.during)):\n        print(row)\n```", "```py\nclass sqlalchemy.dialects.postgresql.Range\n```", "```py\nr = Range(10, 50, bounds=\"()\")\n```", "```py\nmethod __eq__(other: Any) \u2192 bool\n```", "```py\nmethod adjacent_to(other: Range[_T]) \u2192 bool\n```", "```py\nmethod contained_by(other: Range[_T]) \u2192 bool\n```", "```py\nmethod contains(value: _T | Range[_T]) \u2192 bool\n```", "```py\nmethod difference(other: Range[_T]) \u2192 Range[_T]\n```", "```py\nmethod intersection(other: Range[_T]) \u2192 Range[_T]\n```", "```py\nattribute is_empty\n```", "```py\nattribute isempty\n```", "```py\nattribute lower: _T | None\n```", "```py\nattribute lower_inc\n```", "```py\nattribute lower_inf\n```", "```py\nmethod not_extend_left_of(other: Range[_T]) \u2192 bool\n```", "```py\nmethod not_extend_right_of(other: Range[_T]) \u2192 bool\n```", "```py\nmethod overlaps(other: Range[_T]) \u2192 bool\n```", "```py\nmethod strictly_left_of(other: Range[_T]) \u2192 bool\n```", "```py\nmethod strictly_right_of(other: Range[_T]) \u2192 bool\n```", "```py\nmethod union(other: Range[_T]) \u2192 Range[_T]\n```", "```py\nattribute upper: _T | None\n```", "```py\nattribute upper_inc\n```", "```py\nattribute upper_inf\n```", "```py\nfrom datetime import datetime\nfrom typing import List\n\nfrom sqlalchemy.dialects.postgresql import Range\nfrom sqlalchemy.dialects.postgresql import TSMULTIRANGE\nfrom sqlalchemy.orm import DeclarativeBase\nfrom sqlalchemy.orm import Mapped\nfrom sqlalchemy.orm import mapped_column\n\nclass Base(DeclarativeBase):\n    pass\n\nclass EventCalendar(Base):\n    __tablename__ = \"event_calendar\"\n\n    id: Mapped[int] = mapped_column(primary_key=True)\n    event_name: Mapped[str]\n    added: Mapped[datetime]\n    in_session_periods: Mapped[List[Range[datetime]]] = mapped_column(TSMULTIRANGE)\n```", "```py\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import select\nfrom sqlalchemy.orm import Session\n\nengine = create_engine(\"postgresql+psycopg://scott:tiger@pg14/test\")\n\nBase.metadata.create_all(engine)\n\nwith Session(engine) as session:\n    calendar = EventCalendar(\n        event_name=\"SQLAlchemy Tutorial Sessions\",\n        in_session_periods=[\n            Range(datetime(2013, 3, 23), datetime(2013, 3, 25)),\n            Range(datetime(2013, 4, 12), datetime(2013, 4, 15)),\n            Range(datetime(2013, 5, 9), datetime(2013, 5, 12)),\n        ],\n    )\n    session.add(calendar)\n    session.commit()\n\n    for multirange in session.scalars(select(EventCalendar.in_session_periods)):\n        for range_ in multirange:\n            print(f\"Start: {range_.lower} End: {range_.upper}\")\n```", "```py\nfrom sqlalchemy import literal\nfrom sqlalchemy.dialects.postgresql import MultiRange\n\nwith Session(engine) as session:\n    stmt = select(EventCalendar).where(\n        EventCalendar.added.op(\"<@\")(\n            MultiRange(\n                [\n                    Range(datetime(2023, 1, 1), datetime(2013, 3, 31)),\n                    Range(datetime(2023, 7, 1), datetime(2013, 9, 30)),\n                ]\n            )\n        )\n    )\n    in_range = session.execute(stmt).all()\n\nwith engine.connect() as conn:\n    row = conn.scalar(select(literal(MultiRange([Range(2, 4)]))))\n    print(f\"{row.lower} -> {row.upper}\")\n```", "```py\ne = create_engine(\n    \"postgresql+psycopg://scott:tiger@host/dbname\", native_inet_types=False\n)\n```", "```py\nfrom sqlalchemy.dialects.postgresql import (\n    ARRAY,\n    BIGINT,\n    BIT,\n    BOOLEAN,\n    BYTEA,\n    CHAR,\n    CIDR,\n    CITEXT,\n    DATE,\n    DATEMULTIRANGE,\n    DATERANGE,\n    DOMAIN,\n    DOUBLE_PRECISION,\n    ENUM,\n    FLOAT,\n    HSTORE,\n    INET,\n    INT4MULTIRANGE,\n    INT4RANGE,\n    INT8MULTIRANGE,\n    INT8RANGE,\n    INTEGER,\n    INTERVAL,\n    JSON,\n    JSONB,\n    JSONPATH,\n    MACADDR,\n    MACADDR8,\n    MONEY,\n    NUMERIC,\n    NUMMULTIRANGE,\n    NUMRANGE,\n    OID,\n    REAL,\n    REGCLASS,\n    REGCONFIG,\n    SMALLINT,\n    TEXT,\n    TIME,\n    TIMESTAMP,\n    TSMULTIRANGE,\n    TSQUERY,\n    TSRANGE,\n    TSTZMULTIRANGE,\n    TSTZRANGE,\n    TSVECTOR,\n    UUID,\n    VARCHAR,\n)\n```", "```py\nclass sqlalchemy.dialects.postgresql.AbstractRange\n```", "```py\nclass comparator_factory\n```", "```py\nmethod adjacent_to(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod contained_by(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod contains(other: Any, **kw: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod difference(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod intersection(other: Any) \u2192 ColumnElement[Range[_T]]\n```", "```py\nmethod not_extend_left_of(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod not_extend_right_of(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod overlaps(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod strictly_left_of(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod strictly_right_of(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod union(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nclass sqlalchemy.dialects.postgresql.AbstractSingleRange\n```", "```py\nclass sqlalchemy.dialects.postgresql.AbstractMultiRange\n```", "```py\nclass sqlalchemy.dialects.postgresql.ARRAY\n```", "```py\nfrom sqlalchemy.dialects import postgresql\n\nmytable = Table(\"mytable\", metadata,\n        Column(\"data\", postgresql.ARRAY(Integer, dimensions=2))\n    )\n```", "```py\nmytable.c.data.contains([1, 2])\n```", "```py\nfrom sqlalchemy.dialects.postgresql import ARRAY\nfrom sqlalchemy.ext.mutable import MutableList\n\nclass SomeOrmClass(Base):\n    # ...\n\n    data = Column(MutableList.as_mutable(ARRAY(Integer)))\n```", "```py\nmethod __init__(item_type: _TypeEngineArgument[Any], as_tuple: bool = False, dimensions: int | None = None, zero_indexes: bool = False)\n```", "```py\nColumn('myarray', ARRAY(Integer))\n```", "```py\nclass Comparator\n```", "```py\nmethod contains(other, **kwargs)\n```", "```py\nmethod contained_by(other)\n```", "```py\nmethod overlap(other)\n```", "```py\nclass sqlalchemy.dialects.postgresql.BIT\n```", "```py\nclass sqlalchemy.dialects.postgresql.BYTEA\n```", "```py\nmethod __init__(length: int | None = None)\n```", "```py\nclass sqlalchemy.dialects.postgresql.CIDR\n```", "```py\nclass sqlalchemy.dialects.postgresql.CITEXT\n```", "```py\nmethod __init__(length: int | None = None, collation: str | None = None)\n```", "```py\n    >>> from sqlalchemy import cast, select, String\n    >>> print(select(cast('some string', String(collation='utf8'))))\n    SELECT  CAST(:param_1  AS  VARCHAR  COLLATE  utf8)  AS  anon_1 \n    ```", "```py\nclass sqlalchemy.dialects.postgresql.DOMAIN\n```", "```py\nPositiveInt = DOMAIN(\n    \"pos_int\", Integer, check=\"VALUE > 0\", not_null=True\n)\n\nUsPostalCode = DOMAIN(\n    \"us_postal_code\",\n    Text,\n    check=\"VALUE ~ '^\\d{5}$' OR VALUE ~ '^\\d{5}-\\d{4}$'\"\n)\n```", "```py\nmethod __init__(name: str, data_type: _TypeEngineArgument[Any], *, collation: str | None = None, default: elements.TextClause | str | None = None, constraint_name: str | None = None, not_null: bool | None = None, check: elements.TextClause | str | None = None, create_type: bool = True, **kw: Any)\n```", "```py\nmethod create(bind, checkfirst=True, **kw)\n```", "```py\nmethod drop(bind, checkfirst=True, **kw)\n```", "```py\nclass sqlalchemy.dialects.postgresql.DOUBLE_PRECISION\n```", "```py\nmethod __init__(precision: int | None = None, asdecimal: bool = False, decimal_return_scale: int | None = None)\n```", "```py\n    from sqlalchemy import Column\n    from sqlalchemy import Float\n    from sqlalchemy.dialects import oracle\n\n    Column(\n        \"float_data\",\n        Float(5).with_variant(oracle.FLOAT(binary_precision=16), \"oracle\")\n    )\n    ```", "```py\nclass sqlalchemy.dialects.postgresql.ENUM\n```", "```py\ntable = Table('sometable', metadata,\n    Column('some_enum', ENUM('a', 'b', 'c', name='myenum'))\n)\n\ntable.create(engine)  # will emit CREATE ENUM and CREATE TABLE\ntable.drop(engine)  # will emit DROP TABLE and DROP ENUM\n```", "```py\nmy_enum = ENUM('a', 'b', 'c', name='myenum', metadata=metadata)\n\nt1 = Table('sometable_one', metadata,\n    Column('some_enum', myenum)\n)\n\nt2 = Table('sometable_two', metadata,\n    Column('some_enum', myenum)\n)\n```", "```py\nt1.create(engine) # will fail: no such type 'myenum'\n```", "```py\n# will check if enum exists, and emit CREATE TYPE if not\nt1.create(engine, checkfirst=True)\n```", "```py\nmetadata.create_all(engine)  # will emit CREATE TYPE\nmetadata.drop_all(engine)  # will emit DROP TYPE\n```", "```py\nmy_enum.create(engine)\nmy_enum.drop(engine)\n```", "```py\nmethod __init__(*enums, name: str | _NoArg | None = _NoArg.NO_ARG, create_type: bool = True, **kw)\n```", "```py\nmethod create(bind=None, checkfirst=True)\n```", "```py\nmethod drop(bind=None, checkfirst=True)\n```", "```py\nclass sqlalchemy.dialects.postgresql.HSTORE\n```", "```py\ndata_table = Table('data_table', metadata,\n    Column('id', Integer, primary_key=True),\n    Column('data', HSTORE)\n)\n\nwith engine.connect() as conn:\n    conn.execute(\n        data_table.insert(),\n        data = {\"key1\": \"value1\", \"key2\": \"value2\"}\n    )\n```", "```py\n    data_table.c.data['some key'] == 'some value'\n    ```", "```py\n    data_table.c.data.has_key('some key')\n\n    data_table.c.data.has_all(['one', 'two', 'three'])\n    ```", "```py\n    data_table.c.data + {\"k1\": \"v1\"}\n    ```", "```py\nfrom sqlalchemy.ext.mutable import MutableDict\n\nclass MyClass(Base):\n    __tablename__ = 'data_table'\n\n    id = Column(Integer, primary_key=True)\n    data = Column(MutableDict.as_mutable(HSTORE))\n\nmy_object = session.query(MyClass).one()\n\n# in-place mutation, requires Mutable extension\n# in order for the ORM to detect\nmy_object.data['some_key'] = 'some value'\n\nsession.commit()\n```", "```py\nclass Comparator\n```", "```py\nmethod array()\n```", "```py\nmethod contained_by(other)\n```", "```py\nmethod contains(other, **kwargs)\n```", "```py\nmethod defined(key)\n```", "```py\nmethod delete(key)\n```", "```py\nmethod has_all(other)\n```", "```py\nmethod has_any(other)\n```", "```py\nmethod has_key(other)\n```", "```py\nmethod keys()\n```", "```py\nmethod matrix()\n```", "```py\nmethod slice(array)\n```", "```py\nmethod vals()\n```", "```py\nmethod __init__(text_type=None)\n```", "```py\nmethod bind_processor(dialect)\n```", "```py\nattribute comparator_factory\n```", "```py\nattribute hashable = False\n```", "```py\nmethod result_processor(dialect, coltype)\n```", "```py\nclass sqlalchemy.dialects.postgresql.INET\n```", "```py\nclass sqlalchemy.dialects.postgresql.INTERVAL\n```", "```py\nmethod __init__(precision: int | None = None, fields: str | None = None) \u2192 None\n```", "```py\nclass sqlalchemy.dialects.postgresql.JSON\n```", "```py\n    data_table.c.data['some key']\n\n    data_table.c.data[5]\n    ```", "```py\n    data_table.c.data['some key'].astext == 'some value'\n    ```", "```py\n    data_table.c.data['some key'].astext.cast(Integer) == 5\n    ```", "```py\n    data_table.c.data[('key_1', 'key_2', 5, ..., 'key_n')]\n    ```", "```py\n    data_table.c.data[('key_1', 'key_2', 5, ..., 'key_n')].astext == 'some value'\n    ```", "```py\nengine = create_engine(\"postgresql+psycopg2://scott:tiger@localhost/test\",\n                        json_serializer=my_serialize_fn,\n                        json_deserializer=my_deserialize_fn\n                )\n```", "```py\nclass Comparator\n```", "```py\nattribute astext\n```", "```py\nselect(data_table.c.data['some key'].astext)\n```", "```py\nmethod __init__(none_as_null=False, astext_type=None)\n```", "```py\n    from sqlalchemy import null\n    conn.execute(table.insert(), {\"data\": null()})\n    ```", "```py\nattribute comparator_factory\n```", "```py\nclass sqlalchemy.dialects.postgresql.JSONB\n```", "```py\ndata_table = Table('data_table', metadata,\n    Column('id', Integer, primary_key=True),\n    Column('data', JSONB)\n)\n\nwith engine.connect() as conn:\n    conn.execute(\n        data_table.insert(),\n        data = {\"key1\": \"value1\", \"key2\": \"value2\"}\n    )\n```", "```py\nclass Comparator\n```", "```py\nmethod contained_by(other)\n```", "```py\nmethod contains(other, **kwargs)\n```", "```py\nmethod delete_path(array)\n```", "```py\nmethod has_all(other)\n```", "```py\nmethod has_any(other)\n```", "```py\nmethod has_key(other)\n```", "```py\nmethod path_exists(other)\n```", "```py\nmethod path_match(other)\n```", "```py\nattribute comparator_factory\n```", "```py\nclass sqlalchemy.dialects.postgresql.JSONPATH\n```", "```py\nstmt = sa.select(\n    sa.func.jsonb_path_query_array(\n        table.c.jsonb_col, cast(\"$.address.id\", JSONPATH)\n    )\n)\n```", "```py\nclass sqlalchemy.dialects.postgresql.MACADDR\n```", "```py\nclass sqlalchemy.dialects.postgresql.MACADDR8\n```", "```py\nclass sqlalchemy.dialects.postgresql.MONEY\n```", "```py\nimport re\nimport decimal\nfrom sqlalchemy import Dialect\nfrom sqlalchemy import TypeDecorator\n\nclass NumericMoney(TypeDecorator):\n    impl = MONEY\n\n    def process_result_value(\n        self, value: Any, dialect: Dialect\n    ) -> None:\n        if value is not None:\n            # adjust this for the currency and numeric\n            m = re.match(r\"\\$([\\d.]+)\", value)\n            if m:\n                value = decimal.Decimal(m.group(1))\n        return value\n```", "```py\nimport decimal\nfrom sqlalchemy import cast\nfrom sqlalchemy import TypeDecorator\n\nclass NumericMoney(TypeDecorator):\n    impl = MONEY\n\n    def column_expression(self, column: Any):\n        return cast(column, Numeric())\n```", "```py\nclass sqlalchemy.dialects.postgresql.OID\n```", "```py\nclass sqlalchemy.dialects.postgresql.REAL\n```", "```py\nmethod __init__(precision: int | None = None, asdecimal: bool = False, decimal_return_scale: int | None = None)\n```", "```py\n    from sqlalchemy import Column\n    from sqlalchemy import Float\n    from sqlalchemy.dialects import oracle\n\n    Column(\n        \"float_data\",\n        Float(5).with_variant(oracle.FLOAT(binary_precision=16), \"oracle\")\n    )\n    ```", "```py\nclass sqlalchemy.dialects.postgresql.REGCONFIG\n```", "```py\nclass sqlalchemy.dialects.postgresql.REGCLASS\n```", "```py\nclass sqlalchemy.dialects.postgresql.TIMESTAMP\n```", "```py\nmethod __init__(timezone: bool = False, precision: int | None = None) \u2192 None\n```", "```py\nclass sqlalchemy.dialects.postgresql.TIME\n```", "```py\nmethod __init__(timezone: bool = False, precision: int | None = None) \u2192 None\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSQUERY\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSVECTOR\n```", "```py\nclass sqlalchemy.dialects.postgresql.UUID\n```", "```py\nmethod __init__(as_uuid: bool = True)\n```", "```py\nclass sqlalchemy.dialects.postgresql.INT4RANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.INT8RANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.NUMRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.DATERANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSTZRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.INT4MULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.INT8MULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.NUMMULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.DATEMULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSMULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSTZMULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.MultiRange\n```", "```py\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects.postgresql import MultiRange, Range\n\nvalue = literal(MultiRange([Range(2, 4)]))\n\nselect(tbl).where(tbl.c.value.op(\"@\")(MultiRange([Range(-3, 7)])))\n```", "```py\nclass sqlalchemy.dialects.postgresql.aggregate_order_by\n```", "```py\nfrom sqlalchemy.dialects.postgresql import aggregate_order_by\nexpr = func.array_agg(aggregate_order_by(table.c.a, table.c.b.desc()))\nstmt = select(expr)\n```", "```py\nSELECT array_agg(a ORDER BY b DESC) FROM table;\n```", "```py\nexpr = func.string_agg(\n    table.c.a,\n    aggregate_order_by(literal_column(\"','\"), table.c.a)\n)\nstmt = select(expr)\n```", "```py\nSELECT string_agg(a, ',' ORDER BY a) FROM table;\n```", "```py\nclass sqlalchemy.dialects.postgresql.array\n```", "```py\nfrom sqlalchemy.dialects.postgresql import array\nfrom sqlalchemy.dialects import postgresql\nfrom sqlalchemy import select, func\n\nstmt = select(array([1,2]) + array([3,4,5]))\n\nprint(stmt.compile(dialect=postgresql.dialect()))\n```", "```py\nSELECT ARRAY[%(param_1)s, %(param_2)s] ||\n    ARRAY[%(param_3)s, %(param_4)s, %(param_5)s]) AS anon_1\n```", "```py\narray(['foo', 'bar'], type_=CHAR)\n```", "```py\nstmt = select(\n    array([\n        array([1, 2]), array([3, 4]), array([column('q'), column('x')])\n    ])\n)\nprint(stmt.compile(dialect=postgresql.dialect()))\n```", "```py\nSELECT ARRAY[ARRAY[%(param_1)s, %(param_2)s],\nARRAY[%(param_3)s, %(param_4)s], ARRAY[q, x]] AS anon_1\n```", "```py\nfunction sqlalchemy.dialects.postgresql.array_agg(*arg, **kw)\n```", "```py\nfunction sqlalchemy.dialects.postgresql.Any(other, arrexpr, operator=<built-in function eq>)\n```", "```py\nfunction sqlalchemy.dialects.postgresql.All(other, arrexpr, operator=<built-in function eq>)\n```", "```py\nclass sqlalchemy.dialects.postgresql.hstore\n```", "```py\nfrom sqlalchemy.dialects.postgresql import array, hstore\n\nselect(hstore('key1', 'value1'))\n\nselect(\n    hstore(\n        array(['key1', 'key2', 'key3']),\n        array(['value1', 'value2', 'value3'])\n    )\n)\n```", "```py\nattribute inherit_cache: bool | None = True\n```", "```py\nattribute type\n```", "```py\nclass sqlalchemy.dialects.postgresql.to_tsvector\n```", "```py\nclass sqlalchemy.dialects.postgresql.to_tsquery\n```", "```py\nclass sqlalchemy.dialects.postgresql.plainto_tsquery\n```", "```py\nclass sqlalchemy.dialects.postgresql.phraseto_tsquery\n```", "```py\nclass sqlalchemy.dialects.postgresql.websearch_to_tsquery\n```", "```py\nclass sqlalchemy.dialects.postgresql.ts_headline\n```", "```py\nclass sqlalchemy.dialects.postgresql.ExcludeConstraint\n```", "```py\nmethod __init__(*elements, **kw)\n```", "```py\nconst = ExcludeConstraint(\n    (Column('period'), '&&'),\n    (Column('group'), '='),\n    where=(Column('group') != 'some group'),\n    ops={'group': 'my_operator_class'}\n)\n```", "```py\nsome_table = Table(\n    'some_table', metadata,\n    Column('id', Integer, primary_key=True),\n    Column('period', TSRANGE()),\n    Column('group', String)\n)\n\nsome_table.append_constraint(\n    ExcludeConstraint(\n        (some_table.c.period, '&&'),\n        (some_table.c.group, '='),\n        where=some_table.c.group != 'some group',\n        name='some_table_excl_const',\n        ops={'group': 'my_operator_class'}\n    )\n)\n```", "```py\nfrom sqlalchemy.dialects.postgresql import ExcludeConstraint, TSRANGE\n\nclass RoomBooking(Base):\n    __tablename__ = \"room_booking\"\n\n    room = Column(Integer(), primary_key=True)\n    during = Column(TSRANGE())\n\n    __table_args__ = (ExcludeConstraint((\"room\", \"=\"), (\"during\", \"&&\")),)\n```", "```py\nfunction sqlalchemy.dialects.postgresql.insert(table: _DMLTableArgument) \u2192 Insert\n```", "```py\nclass sqlalchemy.dialects.postgresql.Insert\n```", "```py\nattribute excluded\n```", "```py\nattribute inherit_cache: bool | None = False\n```", "```py\nmethod on_conflict_do_nothing(constraint: _OnConflictConstraintT = None, index_elements: _OnConflictIndexElementsT = None, index_where: _OnConflictIndexWhereT = None) \u2192 Self\n```", "```py\nmethod on_conflict_do_update(constraint: _OnConflictConstraintT = None, index_elements: _OnConflictIndexElementsT = None, index_where: _OnConflictIndexWhereT = None, set_: _OnConflictSetT = None, where: _OnConflictWhereT = None) \u2192 Self\n```", "```py\npostgresql+psycopg2://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\nengine = create_engine(\n    \"postgresql+psycopg2://scott:tiger@localhost/test\",\n    isolation_level=\"SERIALIZABLE\",\n)\n```", "```py\nengine = sa.create_engine(\n    \"postgresql+psycopg2://scott:tiger@192.168.0.199:5432/test?sslmode=require\"\n)\n```", "```py\ncreate_engine(\"postgresql+psycopg2://user:password@/dbname\")\n```", "```py\ncreate_engine(\"postgresql+psycopg2://user:password@/dbname?host=/var/lib/postgresql\")\n```", "```py\nengine = create_engine(\"postgresql+psycopg2://user:password@myhost1/dbname?host=myhost2\")\n```", "```py\ncreate_engine(\n    \"postgresql+psycopg2://user:password@/dbname?host=HostA:PortA&host=HostB&host=HostC:PortC\"\n)\n```", "```py\ncreate_engine(\n    \"postgresql+psycopg2://user:password@/dbname?host=HostA,HostB,HostC&port=PortA,,PortC\"\n)\n```", "```py\ncreate_engine(\n    \"postgresql+psycopg2://user:password@/dbname?host=HostA:PortA&host=HostB&host=HostC:PortC&target_session_attrs=primary\"\n)\n```", "```py\nengine = create_engine('postgresql+psycopg2://')\n```", "```py\nengine = create_engine(\n    \"postgresql+psycopg2://scott:tiger@host/dbname\",\n    executemany_mode='values_plus_batch')\n```", "```py\nengine = create_engine(\n    \"postgresql+psycopg2://scott:tiger@host/dbname\",\n    executemany_mode='values_plus_batch',\n    insertmanyvalues_page_size=5000, executemany_batch_page_size=500)\n```", "```py\n    engine = create_engine(\"postgresql+psycopg2://user:pass@host/dbname?client_encoding=utf8\")\n    ```", "```py\n    engine = create_engine(\n        \"postgresql+psycopg2://user:pass@host/dbname\",\n        connect_args={'client_encoding': 'utf8'}\n    )\n    ```", "```py\n    engine = create_engine(\n        \"postgresql+psycopg2://user:pass@host/dbname\",\n        client_encoding=\"utf8\"\n    )\n    ```", "```py\n    # postgresql.conf file\n\n    # client_encoding = sql_ascii # actually, defaults to database\n                                 # encoding\n    client_encoding = utf8\n    ```", "```py\nimport logging\n\nlogging.getLogger('sqlalchemy.dialects.postgresql').setLevel(logging.INFO)\n```", "```py\nimport logging\n\nlogging.basicConfig()   # log messages to stdout\nlogging.getLogger('sqlalchemy.dialects.postgresql').setLevel(logging.INFO)\n```", "```py\nengine = create_engine(\"postgresql+psycopg2://scott:tiger@localhost/test\",\n            use_native_hstore=False)\n```", "```py\npostgresql+psycopg://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\n    from sqlalchemy import create_engine\n    sync_engine = create_engine(\"postgresql+psycopg://scott:tiger@localhost/test\")\n    ```", "```py\n    from sqlalchemy.ext.asyncio import create_async_engine\n    asyncio_engine = create_async_engine(\"postgresql+psycopg://scott:tiger@localhost/test\")\n    ```", "```py\nfrom sqlalchemy.ext.asyncio import create_async_engine\nasyncio_engine = create_async_engine(\"postgresql+psycopg_async://scott:tiger@localhost/test\")\n```", "```py\nfrom psycopg import ClientCursor\n\nclient_side_engine = create_engine(\n    \"postgresql+psycopg://...\",\n    connect_args={\"cursor_factory\": ClientCursor},\n)\n```", "```py\nfrom psycopg import AsyncClientCursor\n\nclient_side_engine = create_async_engine(\n    \"postgresql+psycopg://...\",\n    connect_args={\"cursor_factory\": AsyncClientCursor},\n)\n```", "```py\npostgresql+pg8000://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\n#client_encoding = sql_ascii # actually, defaults to database\n                             # encoding\nclient_encoding = utf8\n```", "```py\nengine = create_engine(\n    \"postgresql+pg8000://user:pass@host/dbname\", client_encoding='utf8')\n```", "```py\nimport ssl\nssl_context = ssl.create_default_context()\nengine = sa.create_engine(\n    \"postgresql+pg8000://scott:tiger@192.168.0.199/test\",\n    connect_args={\"ssl_context\": ssl_context},\n)\n```", "```py\nimport ssl\nssl_context = ssl.create_default_context()\nssl_context.check_hostname = False\nssl_context.verify_mode = ssl.CERT_NONE\nengine = sa.create_engine(\n    \"postgresql+pg8000://scott:tiger@192.168.0.199/test\",\n    connect_args={\"ssl_context\": ssl_context},\n)\n```", "```py\npostgresql+asyncpg://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\nfrom sqlalchemy.ext.asyncio import create_async_engine\nengine = create_async_engine(\"postgresql+asyncpg://user:pass@hostname/dbname\")\n```", "```py\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:password@/dbname?host=HostA:5432&host=HostB:5432&host=HostC:5432\"\n)\n```", "```py\nengine = create_async_engine(\"postgresql+asyncpg://user:pass@hostname/dbname?prepared_statement_cache_size=500\")\n```", "```py\nengine = create_async_engine(\"postgresql+asyncpg://user:pass@hostname/dbname?prepared_statement_cache_size=0\")\n```", "```py\nfrom uuid import uuid4\n\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:pass@somepgbouncer/dbname\",\n    poolclass=NullPool,\n    connect_args={\n        'prepared_statement_name_func': lambda:  f'__asyncpg_{uuid4()}__',\n    },\n)\n```", "```py\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:password@localhost/tmp\",\n    connect_args={\"server_settings\": {\"jit\": \"off\"}},\n)\n```", "```py\npostgresql+psycopg2cffi://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\nTable(\n    \"sometable\",\n    metadata,\n    Column(\n        \"id\", Integer, Sequence(\"some_id_seq\", start=1), primary_key=True\n    )\n)\n```", "```py\nfrom sqlalchemy import Table, Column, MetaData, Integer, Computed\n\nmetadata = MetaData()\n\ndata = Table(\n    \"data\",\n    metadata,\n    Column(\n        'id', Integer, Identity(start=42, cycle=True), primary_key=True\n    ),\n    Column('data', String)\n)\n```", "```py\nCREATE  TABLE  data  (\n  id  INTEGER  GENERATED  BY  DEFAULT  AS  IDENTITY  (START  WITH  42  CYCLE),\n  data  VARCHAR,\n  PRIMARY  KEY  (id)\n)\n```", "```py\nfrom sqlalchemy.schema import CreateColumn\nfrom sqlalchemy.ext.compiler import compiles\n\n@compiles(CreateColumn, 'postgresql')\ndef use_identity(element, compiler, **kw):\n    text = compiler.visit_create_column(element, **kw)\n    text = text.replace(\n        \"SERIAL\", \"INT GENERATED BY DEFAULT AS IDENTITY\"\n     )\n    return text\n```", "```py\nt = Table(\n    't', m,\n    Column('id', Integer, primary_key=True),\n    Column('data', String)\n)\n```", "```py\nCREATE TABLE t (\n    id INT GENERATED BY DEFAULT AS IDENTITY,\n    data VARCHAR,\n    PRIMARY KEY (id)\n)\n```", "```py\nfrom sqlalchemy import Table, Column, MetaData, Integer, Computed\n\nmetadata = MetaData()\n\ndata = Table(\n    \"data\",\n    metadata,\n    Column(\n        'id', Integer, Identity(start=42, cycle=True), primary_key=True\n    ),\n    Column('data', String)\n)\n```", "```py\nCREATE  TABLE  data  (\n  id  INTEGER  GENERATED  BY  DEFAULT  AS  IDENTITY  (START  WITH  42  CYCLE),\n  data  VARCHAR,\n  PRIMARY  KEY  (id)\n)\n```", "```py\nfrom sqlalchemy.schema import CreateColumn\nfrom sqlalchemy.ext.compiler import compiles\n\n@compiles(CreateColumn, 'postgresql')\ndef use_identity(element, compiler, **kw):\n    text = compiler.visit_create_column(element, **kw)\n    text = text.replace(\n        \"SERIAL\", \"INT GENERATED BY DEFAULT AS IDENTITY\"\n     )\n    return text\n```", "```py\nt = Table(\n    't', m,\n    Column('id', Integer, primary_key=True),\n    Column('data', String)\n)\n```", "```py\nCREATE TABLE t (\n    id INT GENERATED BY DEFAULT AS IDENTITY,\n    data VARCHAR,\n    PRIMARY KEY (id)\n)\n```", "```py\nwith engine.connect() as conn:\n    result = conn.execution_options(stream_results=True).execute(text(\"select * from table\"))\n```", "```py\nengine = create_engine(\n    \"postgresql+pg8000://scott:tiger@localhost/test\",\n    isolation_level = \"REPEATABLE READ\"\n)\n```", "```py\nwith engine.connect() as conn:\n    conn = conn.execution_options(\n        isolation_level=\"REPEATABLE READ\"\n    )\n    with conn.begin():\n        # ... work with transaction\n```", "```py\nwith engine.connect() as conn:\n    conn = conn.execution_options(\n        isolation_level=\"SERIALIZABLE\",\n        postgresql_readonly=True,\n        postgresql_deferrable=True\n    )\n    with conn.begin():\n        #  ... work with transaction\n```", "```py\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import event\n\npostgresql_engine = create_engine(\n    \"postgresql+pyscopg2://scott:tiger@hostname/dbname\",\n\n    # disable default reset-on-return scheme\n    pool_reset_on_return=None,\n)\n\n@event.listens_for(postgresql_engine, \"reset\")\ndef _reset_postgresql(dbapi_connection, connection_record, reset_state):\n    if not reset_state.terminate_only:\n        dbapi_connection.execute(\"CLOSE ALL\")\n        dbapi_connection.execute(\"RESET ALL\")\n        dbapi_connection.execute(\"DISCARD TEMP\")\n\n    # so that the DBAPI itself knows that the connection has been\n    # reset\n    dbapi_connection.rollback()\n```", "```py\nfrom sqlalchemy import event\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"postgresql+psycopg2://scott:tiger@host/dbname\")\n\n@event.listens_for(engine, \"connect\", insert=True)\ndef set_search_path(dbapi_connection, connection_record):\n    existing_autocommit = dbapi_connection.autocommit\n    dbapi_connection.autocommit = True\n    cursor = dbapi_connection.cursor()\n    cursor.execute(\"SET SESSION search_path='%s'\" % schema_name)\n    cursor.close()\n    dbapi_connection.autocommit = existing_autocommit\n```", "```py\ntest=> select current_schema();\ncurrent_schema\n----------------\npublic\n(1 row)\n```", "```py\ntest=> select current_schema();\ncurrent_schema\n----------------\npublic\n(1 row)\n\ntest=> create schema scott;\nCREATE SCHEMA\ntest=> select current_schema();\ncurrent_schema\n----------------\nscott\n(1 row)\n```", "```py\ntest=> show search_path;\nsearch_path\n-----------------\n\"$user\", public\n(1 row)\n```", "```py\ntest=> CREATE TABLE test_schema.referred(id INTEGER PRIMARY KEY);\nCREATE TABLE\ntest=> CREATE TABLE referring(\ntest(>         id INTEGER PRIMARY KEY,\ntest(>         referred_id INTEGER REFERENCES test_schema.referred(id));\nCREATE TABLE\ntest=> SET search_path TO public, test_schema;\ntest=> SELECT pg_catalog.pg_get_constraintdef(r.oid, true) FROM\ntest-> pg_catalog.pg_class c JOIN pg_catalog.pg_namespace n\ntest-> ON n.oid = c.relnamespace\ntest-> JOIN pg_catalog.pg_constraint r  ON c.oid = r.conrelid\ntest-> WHERE c.relname='referring' AND r.contype = 'f'\ntest-> ;\n               pg_get_constraintdef\n---------------------------------------------------\n FOREIGN KEY (referred_id) REFERENCES referred(id)\n(1 row)\n```", "```py\ntest=> SET search_path TO public;\nSET\n```", "```py\ntest=> SELECT pg_catalog.pg_get_constraintdef(r.oid, true) FROM\ntest-> pg_catalog.pg_class c JOIN pg_catalog.pg_namespace n\ntest-> ON n.oid = c.relnamespace\ntest-> JOIN pg_catalog.pg_constraint r  ON c.oid = r.conrelid\ntest-> WHERE c.relname='referring' AND r.contype = 'f';\n                     pg_get_constraintdef\n---------------------------------------------------------------\n FOREIGN KEY (referred_id) REFERENCES test_schema.referred(id)\n(1 row)\n```", "```py\n>>> from sqlalchemy import Table, MetaData, create_engine, text\n>>> engine = create_engine(\"postgresql+psycopg2://scott:tiger@localhost/test\")\n>>> with engine.connect() as conn:\n...     conn.execute(text(\"SET search_path TO test_schema, public\"))\n...     metadata_obj = MetaData()\n...     referring = Table('referring', metadata_obj,\n...                       autoload_with=conn)\n...\n<sqlalchemy.engine.result.CursorResult object at 0x101612ed0>\n```", "```py\n>>> metadata_obj.tables['referred'].schema is None\nTrue\n```", "```py\n>>> with engine.connect() as conn:\n...     conn.execute(text(\"SET search_path TO test_schema, public\"))\n...     metadata_obj = MetaData()\n...     referring = Table('referring', metadata_obj,\n...                       autoload_with=conn,\n...                       postgresql_ignore_search_path=True)\n...\n<sqlalchemy.engine.result.CursorResult object at 0x1016126d0>\n```", "```py\n>>> metadata_obj.tables['test_schema.referred'].schema\n'test_schema'\n```", "```py\n# INSERT..RETURNING\nresult = table.insert().returning(table.c.col1, table.c.col2).\\\n    values(name='foo')\nprint(result.fetchall())\n\n# UPDATE..RETURNING\nresult = table.update().returning(table.c.col1, table.c.col2).\\\n    where(table.c.name=='foo').values(name='bar')\nprint(result.fetchall())\n\n# DELETE..RETURNING\nresult = table.delete().returning(table.c.col1, table.c.col2).\\\n    where(table.c.name=='foo')\nprint(result.fetchall())\n```", "```py\n>>> from sqlalchemy.dialects.postgresql import insert\n>>> insert_stmt = insert(my_table).values(\n...     id='some_existing_id',\n...     data='inserted value')\n>>> do_nothing_stmt = insert_stmt.on_conflict_do_nothing(\n...     index_elements=['id']\n... )\n>>> print(do_nothing_stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  (id)  DO  NOTHING\n>>> do_update_stmt = insert_stmt.on_conflict_do_update(\n...     constraint='pk_my_table',\n...     set_=dict(data='updated value')\n... )\n>>> print(do_update_stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  ON  CONSTRAINT  pk_my_table  DO  UPDATE  SET  data  =  %(param_1)s \n```", "```py\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     index_elements=['id'],\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     index_elements=[my_table.c.id],\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s \n    ```", "```py\n    >>> stmt = insert(my_table).values(user_email='a@b.com', data='inserted data')\n    >>> stmt = stmt.on_conflict_do_update(\n    ...     index_elements=[my_table.c.user_email],\n    ...     index_where=my_table.c.user_email.like('%@gmail.com'),\n    ...     set_=dict(data=stmt.excluded.data)\n    ... )\n    >>> print(stmt)\n    INSERT  INTO  my_table  (data,  user_email)\n    VALUES  (%(data)s,  %(user_email)s)  ON  CONFLICT  (user_email)\n    WHERE  user_email  LIKE  %(user_email_1)s  DO  UPDATE  SET  data  =  excluded.data \n    ```", "```py\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     constraint='my_table_idx_1',\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  ON  CONSTRAINT  my_table_idx_1  DO  UPDATE  SET  data  =  %(param_1)s\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     constraint='my_table_pk',\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  ON  CONSTRAINT  my_table_pk  DO  UPDATE  SET  data  =  %(param_1)s \n    ```", "```py\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     constraint=my_table.primary_key,\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s \n    ```", "```py\n>>> stmt = insert(my_table).values(id='some_id', data='inserted value')\n>>> do_update_stmt = stmt.on_conflict_do_update(\n...     index_elements=['id'],\n...     set_=dict(data='updated value')\n... )\n>>> print(do_update_stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s \n```", "```py\n>>> stmt = insert(my_table).values(\n...     id='some_id',\n...     data='inserted value',\n...     author='jlh'\n... )\n>>> do_update_stmt = stmt.on_conflict_do_update(\n...     index_elements=['id'],\n...     set_=dict(data='updated value', author=stmt.excluded.author)\n... )\n>>> print(do_update_stmt)\nINSERT  INTO  my_table  (id,  data,  author)\nVALUES  (%(id)s,  %(data)s,  %(author)s)\nON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s,  author  =  excluded.author \n```", "```py\n>>> stmt = insert(my_table).values(\n...     id='some_id',\n...     data='inserted value',\n...     author='jlh'\n... )\n>>> on_update_stmt = stmt.on_conflict_do_update(\n...     index_elements=['id'],\n...     set_=dict(data='updated value', author=stmt.excluded.author),\n...     where=(my_table.c.status == 2)\n... )\n>>> print(on_update_stmt)\nINSERT  INTO  my_table  (id,  data,  author)\nVALUES  (%(id)s,  %(data)s,  %(author)s)\nON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s,  author  =  excluded.author\nWHERE  my_table.status  =  %(status_1)s \n```", "```py\n>>> stmt = insert(my_table).values(id='some_id', data='inserted value')\n>>> stmt = stmt.on_conflict_do_nothing(index_elements=['id'])\n>>> print(stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  (id)  DO  NOTHING \n```", "```py\n>>> stmt = insert(my_table).values(id='some_id', data='inserted value')\n>>> stmt = stmt.on_conflict_do_nothing()\n>>> print(stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  DO  NOTHING \n```", "```py\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     index_elements=['id'],\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     index_elements=[my_table.c.id],\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s \n    ```", "```py\n    >>> stmt = insert(my_table).values(user_email='a@b.com', data='inserted data')\n    >>> stmt = stmt.on_conflict_do_update(\n    ...     index_elements=[my_table.c.user_email],\n    ...     index_where=my_table.c.user_email.like('%@gmail.com'),\n    ...     set_=dict(data=stmt.excluded.data)\n    ... )\n    >>> print(stmt)\n    INSERT  INTO  my_table  (data,  user_email)\n    VALUES  (%(data)s,  %(user_email)s)  ON  CONFLICT  (user_email)\n    WHERE  user_email  LIKE  %(user_email_1)s  DO  UPDATE  SET  data  =  excluded.data \n    ```", "```py\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     constraint='my_table_idx_1',\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  ON  CONSTRAINT  my_table_idx_1  DO  UPDATE  SET  data  =  %(param_1)s\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     constraint='my_table_pk',\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  ON  CONSTRAINT  my_table_pk  DO  UPDATE  SET  data  =  %(param_1)s \n    ```", "```py\n    >>> do_update_stmt = insert_stmt.on_conflict_do_update(\n    ...     constraint=my_table.primary_key,\n    ...     set_=dict(data='updated value')\n    ... )\n    >>> print(do_update_stmt)\n    INSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\n    ON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s \n    ```", "```py\n>>> stmt = insert(my_table).values(id='some_id', data='inserted value')\n>>> do_update_stmt = stmt.on_conflict_do_update(\n...     index_elements=['id'],\n...     set_=dict(data='updated value')\n... )\n>>> print(do_update_stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s \n```", "```py\n>>> stmt = insert(my_table).values(\n...     id='some_id',\n...     data='inserted value',\n...     author='jlh'\n... )\n>>> do_update_stmt = stmt.on_conflict_do_update(\n...     index_elements=['id'],\n...     set_=dict(data='updated value', author=stmt.excluded.author)\n... )\n>>> print(do_update_stmt)\nINSERT  INTO  my_table  (id,  data,  author)\nVALUES  (%(id)s,  %(data)s,  %(author)s)\nON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s,  author  =  excluded.author \n```", "```py\n>>> stmt = insert(my_table).values(\n...     id='some_id',\n...     data='inserted value',\n...     author='jlh'\n... )\n>>> on_update_stmt = stmt.on_conflict_do_update(\n...     index_elements=['id'],\n...     set_=dict(data='updated value', author=stmt.excluded.author),\n...     where=(my_table.c.status == 2)\n... )\n>>> print(on_update_stmt)\nINSERT  INTO  my_table  (id,  data,  author)\nVALUES  (%(id)s,  %(data)s,  %(author)s)\nON  CONFLICT  (id)  DO  UPDATE  SET  data  =  %(param_1)s,  author  =  excluded.author\nWHERE  my_table.status  =  %(status_1)s \n```", "```py\n>>> stmt = insert(my_table).values(id='some_id', data='inserted value')\n>>> stmt = stmt.on_conflict_do_nothing(index_elements=['id'])\n>>> print(stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  (id)  DO  NOTHING \n```", "```py\n>>> stmt = insert(my_table).values(id='some_id', data='inserted value')\n>>> stmt = stmt.on_conflict_do_nothing()\n>>> print(stmt)\nINSERT  INTO  my_table  (id,  data)  VALUES  (%(id)s,  %(data)s)\nON  CONFLICT  DO  NOTHING \n```", "```py\nselect(sometable.c.text.match(\"search string\"))\n```", "```py\nSELECT text @@ plainto_tsquery('search string') FROM table\n```", "```py\nfrom sqlalchemy import func\n\nselect(\n    sometable.c.text.bool_op(\"@@\")(func.to_tsquery(\"search string\"))\n)\n```", "```py\nSELECT text @@ to_tsquery('search string') FROM table\n```", "```py\nselect(\n    func.to_tsquery('cat').bool_op(\"@>\")(func.to_tsquery('cat & rat'))\n)\n```", "```py\nSELECT  to_tsquery('cat')  @>  to_tsquery('cat & rat')\n```", "```py\nfrom sqlalchemy.dialects.postgresql import TSVECTOR\nfrom sqlalchemy import select, cast\nselect(cast(\"some text\", TSVECTOR))\n```", "```py\nSELECT CAST('some text' AS TSVECTOR) AS anon_1\n```", "```py\nselect(mytable.c.id).where(\n    mytable.c.title.match('somestring', postgresql_regconfig='english')\n)\n```", "```py\nSELECT mytable.id FROM mytable\nWHERE mytable.title @@ plainto_tsquery('english', 'somestring')\n```", "```py\nselect(mytable.c.id).where(\n    func.to_tsvector(\"english\", mytable.c.title).bool_op(\"@@\")(\n        func.to_tsquery(\"english\", \"somestring\")\n    )\n)\n```", "```py\nSELECT mytable.id FROM mytable\nWHERE to_tsvector('english', mytable.title) @@\n    to_tsquery('english', 'somestring')\n```", "```py\nselect(sometable.c.text.match(\"search string\"))\n```", "```py\nSELECT text @@ plainto_tsquery('search string') FROM table\n```", "```py\nfrom sqlalchemy import func\n\nselect(\n    sometable.c.text.bool_op(\"@@\")(func.to_tsquery(\"search string\"))\n)\n```", "```py\nSELECT text @@ to_tsquery('search string') FROM table\n```", "```py\nselect(\n    func.to_tsquery('cat').bool_op(\"@>\")(func.to_tsquery('cat & rat'))\n)\n```", "```py\nSELECT  to_tsquery('cat')  @>  to_tsquery('cat & rat')\n```", "```py\nfrom sqlalchemy.dialects.postgresql import TSVECTOR\nfrom sqlalchemy import select, cast\nselect(cast(\"some text\", TSVECTOR))\n```", "```py\nSELECT CAST('some text' AS TSVECTOR) AS anon_1\n```", "```py\nselect(mytable.c.id).where(\n    mytable.c.title.match('somestring', postgresql_regconfig='english')\n)\n```", "```py\nSELECT mytable.id FROM mytable\nWHERE mytable.title @@ plainto_tsquery('english', 'somestring')\n```", "```py\nselect(mytable.c.id).where(\n    func.to_tsvector(\"english\", mytable.c.title).bool_op(\"@@\")(\n        func.to_tsquery(\"english\", \"somestring\")\n    )\n)\n```", "```py\nSELECT mytable.id FROM mytable\nWHERE to_tsvector('english', mytable.title) @@\n    to_tsquery('english', 'somestring')\n```", "```py\n# SELECT ... FROM ONLY ...\nresult = table.select().with_hint(table, 'ONLY', 'postgresql')\nprint(result.fetchall())\n\n# UPDATE ONLY ...\ntable.update(values=dict(foo='bar')).with_hint('ONLY',\n                                               dialect_name='postgresql')\n\n# DELETE FROM ONLY ...\ntable.delete().with_hint('ONLY', dialect_name='postgresql')\n```", "```py\nIndex(\"my_index\", table.c.x, postgresql_include=['y'])\n```", "```py\nIndex('my_index', my_table.c.id, postgresql_where=my_table.c.value > 10)\n```", "```py\nIndex(\n    'my_index', my_table.c.id, my_table.c.data,\n    postgresql_ops={\n        'data': 'text_pattern_ops',\n        'id': 'int4_ops'\n    })\n```", "```py\nIndex(\n    'my_index', my_table.c.id,\n    func.lower(my_table.c.data).label('data_lower'),\n    postgresql_ops={\n        'data_lower': 'text_pattern_ops',\n        'id': 'int4_ops'\n    })\n```", "```py\nIndex('my_index', my_table.c.data, postgresql_using='gin')\n```", "```py\nIndex('my_index', my_table.c.data, postgresql_with={\"fillfactor\": 50})\n```", "```py\nIndex('my_index', my_table.c.data, postgresql_tablespace='my_tablespace')\n```", "```py\ntbl = Table('testtbl', m, Column('data', Integer))\n\nidx1 = Index('test_idx1', tbl.c.data, postgresql_concurrently=True)\n```", "```py\nCREATE INDEX CONCURRENTLY test_idx1 ON testtbl (data)\n```", "```py\nDROP INDEX CONCURRENTLY test_idx1\n```", "```py\nmetadata = MetaData()\ntable = Table(\n    \"foo\", metadata,\n    Column(\"id\", String))\nindex = Index(\n    \"foo_idx\", table.c.id, postgresql_concurrently=True)\n\nwith engine.connect() as conn:\n    with conn.execution_options(isolation_level='AUTOCOMMIT'):\n        table.create(conn)\n```", "```py\nIndex(\"my_index\", table.c.x, postgresql_include=['y'])\n```", "```py\nIndex('my_index', my_table.c.id, postgresql_where=my_table.c.value > 10)\n```", "```py\nIndex(\n    'my_index', my_table.c.id, my_table.c.data,\n    postgresql_ops={\n        'data': 'text_pattern_ops',\n        'id': 'int4_ops'\n    })\n```", "```py\nIndex(\n    'my_index', my_table.c.id,\n    func.lower(my_table.c.data).label('data_lower'),\n    postgresql_ops={\n        'data_lower': 'text_pattern_ops',\n        'id': 'int4_ops'\n    })\n```", "```py\nIndex('my_index', my_table.c.data, postgresql_using='gin')\n```", "```py\nIndex('my_index', my_table.c.data, postgresql_with={\"fillfactor\": 50})\n```", "```py\nIndex('my_index', my_table.c.data, postgresql_tablespace='my_tablespace')\n```", "```py\ntbl = Table('testtbl', m, Column('data', Integer))\n\nidx1 = Index('test_idx1', tbl.c.data, postgresql_concurrently=True)\n```", "```py\nCREATE INDEX CONCURRENTLY test_idx1 ON testtbl (data)\n```", "```py\nDROP INDEX CONCURRENTLY test_idx1\n```", "```py\nmetadata = MetaData()\ntable = Table(\n    \"foo\", metadata,\n    Column(\"id\", String))\nindex = Index(\n    \"foo_idx\", table.c.id, postgresql_concurrently=True)\n\nwith engine.connect() as conn:\n    with conn.execution_options(isolation_level='AUTOCOMMIT'):\n        table.create(conn)\n```", "```py\nfrom sqlalchemy import create_engine, inspect\n\nengine = create_engine(\"postgresql+psycopg2://localhost/test\")\ninsp = inspect(engine)  # will be a PGInspector\n\nprint(insp.get_enums())\n```", "```py\nclass sqlalchemy.dialects.postgresql.base.PGInspector\n```", "```py\nmethod get_domains(schema: str | None = None) \u2192 List[ReflectedDomain]\n```", "```py\nmethod get_enums(schema: str | None = None) \u2192 List[ReflectedEnum]\n```", "```py\nmethod get_foreign_table_names(schema: str | None = None) \u2192 List[str]\n```", "```py\nmethod get_table_oid(table_name: str, schema: str | None = None) \u2192 int\n```", "```py\nmethod has_type(type_name: str, schema: str | None = None, **kw: Any) \u2192 bool\n```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_inherits=\"some_supertable\")\n\n    Table(\"some_table\", metadata, ..., postgresql_inherits=(\"t1\", \"t2\", ...))\n    ```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_on_commit='PRESERVE ROWS')\n    ```", "```py\n    Table(\"some_table\", metadata, ...,\n          postgresql_partition_by='LIST (part_column)')\n\n    .. versionadded:: 1.2.6\n    ```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_tablespace='some_tablespace')\n    ```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_using='heap')\n\n    .. versionadded:: 2.0.26\n    ```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_with_oids=True)\n    ```", "```py\n    Table(\"some_table\", metadata, ..., postgresql_with_oids=False)\n    ```", "```py\n    def update():\n        op.create_foreign_key(\n            \"fk_user_address\",\n            \"address\",\n            \"user\",\n            [\"user_id\"],\n            [\"id\"],\n            postgresql_not_valid=True\n        )\n    ```", "```py\n    CheckConstraint(\"some_field IS NOT NULL\", postgresql_not_valid=True)\n\n    ForeignKeyConstraint([\"some_id\"], [\"some_table.some_id\"], postgresql_not_valid=True)\n    ```", "```py\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(func.json_each('{\"a\":\"foo\", \"b\":\"bar\"}').table_valued(\"key\", \"value\"))\n    >>> print(stmt)\n    SELECT  anon_1.key,  anon_1.value\n    FROM  json_each(:json_each_1)  AS  anon_1 \n    ```", "```py\n    >>> from sqlalchemy import select, func, literal_column\n    >>> stmt = select(\n    ...     func.json_populate_record(\n    ...         literal_column(\"null::myrowtype\"),\n    ...         '{\"a\":1,\"b\":2}'\n    ...     ).table_valued(\"a\", \"b\", name=\"x\")\n    ... )\n    >>> print(stmt)\n    SELECT  x.a,  x.b\n    FROM  json_populate_record(null::myrowtype,  :json_populate_record_1)  AS  x \n    ```", "```py\n    >>> from sqlalchemy import select, func, column, Integer, Text\n    >>> stmt = select(\n    ...     func.json_to_record('{\"a\":1,\"b\":[1,2,3],\"c\":\"bar\"}').table_valued(\n    ...         column(\"a\", Integer), column(\"b\", Text), column(\"d\", Text),\n    ...     ).render_derived(name=\"x\", with_types=True)\n    ... )\n    >>> print(stmt)\n    SELECT  x.a,  x.b,  x.d\n    FROM  json_to_record(:json_to_record_1)  AS  x(a  INTEGER,  b  TEXT,  d  TEXT) \n    ```", "```py\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(\n    ...     func.generate_series(4, 1, -1).\n    ...     table_valued(\"value\", with_ordinality=\"ordinality\").\n    ...     render_derived()\n    ... )\n    >>> print(stmt)\n    SELECT  anon_1.value,  anon_1.ordinality\n    FROM  generate_series(:generate_series_1,  :generate_series_2,  :generate_series_3)\n    WITH  ORDINALITY  AS  anon_1(value,  ordinality) \n    ```", "```py\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(func.json_array_elements('[\"one\", \"two\"]').column_valued(\"x\"))\n    >>> print(stmt)\n    SELECT  x\n    FROM  json_array_elements(:json_array_elements_1)  AS  x \n    ```", "```py\n    >>> from sqlalchemy.dialects.postgresql import array\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(func.unnest(array([1, 2])).column_valued())\n    >>> print(stmt)\n    SELECT  anon_1\n    FROM  unnest(ARRAY[%(param_1)s,  %(param_2)s])  AS  anon_1 \n    ```", "```py\n    >>> from sqlalchemy import table, column, ARRAY, Integer\n    >>> from sqlalchemy import select, func\n    >>> t = table(\"t\", column('value', ARRAY(Integer)))\n    >>> stmt = select(func.unnest(t.c.value).column_valued(\"unnested_value\"))\n    >>> print(stmt)\n    SELECT  unnested_value\n    FROM  unnest(t.value)  AS  unnested_value \n    ```", "```py\n>>> from sqlalchemy import table, column, func, tuple_\n>>> t = table(\"t\", column(\"id\"), column(\"fk\"))\n>>> stmt = t.select().where(\n...     tuple_(t.c.id, t.c.fk) > (1,2)\n... ).where(\n...     func.ROW(t.c.id, t.c.fk) < func.ROW(3, 7)\n... )\n>>> print(stmt)\nSELECT  t.id,  t.fk\nFROM  t\nWHERE  (t.id,  t.fk)  >  (:param_1,  :param_2)  AND  ROW(t.id,  t.fk)  <  ROW(:ROW_1,  :ROW_2) \n```", "```py\n>>> from sqlalchemy import table, column, func, select\n>>> a = table( \"a\", column(\"id\"), column(\"x\"), column(\"y\"))\n>>> stmt = select(func.row_to_json(a.table_valued()))\n>>> print(stmt)\nSELECT  row_to_json(a)  AS  row_to_json_1\nFROM  a \n```", "```py\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(func.json_each('{\"a\":\"foo\", \"b\":\"bar\"}').table_valued(\"key\", \"value\"))\n    >>> print(stmt)\n    SELECT  anon_1.key,  anon_1.value\n    FROM  json_each(:json_each_1)  AS  anon_1 \n    ```", "```py\n    >>> from sqlalchemy import select, func, literal_column\n    >>> stmt = select(\n    ...     func.json_populate_record(\n    ...         literal_column(\"null::myrowtype\"),\n    ...         '{\"a\":1,\"b\":2}'\n    ...     ).table_valued(\"a\", \"b\", name=\"x\")\n    ... )\n    >>> print(stmt)\n    SELECT  x.a,  x.b\n    FROM  json_populate_record(null::myrowtype,  :json_populate_record_1)  AS  x \n    ```", "```py\n    >>> from sqlalchemy import select, func, column, Integer, Text\n    >>> stmt = select(\n    ...     func.json_to_record('{\"a\":1,\"b\":[1,2,3],\"c\":\"bar\"}').table_valued(\n    ...         column(\"a\", Integer), column(\"b\", Text), column(\"d\", Text),\n    ...     ).render_derived(name=\"x\", with_types=True)\n    ... )\n    >>> print(stmt)\n    SELECT  x.a,  x.b,  x.d\n    FROM  json_to_record(:json_to_record_1)  AS  x(a  INTEGER,  b  TEXT,  d  TEXT) \n    ```", "```py\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(\n    ...     func.generate_series(4, 1, -1).\n    ...     table_valued(\"value\", with_ordinality=\"ordinality\").\n    ...     render_derived()\n    ... )\n    >>> print(stmt)\n    SELECT  anon_1.value,  anon_1.ordinality\n    FROM  generate_series(:generate_series_1,  :generate_series_2,  :generate_series_3)\n    WITH  ORDINALITY  AS  anon_1(value,  ordinality) \n    ```", "```py\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(func.json_array_elements('[\"one\", \"two\"]').column_valued(\"x\"))\n    >>> print(stmt)\n    SELECT  x\n    FROM  json_array_elements(:json_array_elements_1)  AS  x \n    ```", "```py\n    >>> from sqlalchemy.dialects.postgresql import array\n    >>> from sqlalchemy import select, func\n    >>> stmt = select(func.unnest(array([1, 2])).column_valued())\n    >>> print(stmt)\n    SELECT  anon_1\n    FROM  unnest(ARRAY[%(param_1)s,  %(param_2)s])  AS  anon_1 \n    ```", "```py\n    >>> from sqlalchemy import table, column, ARRAY, Integer\n    >>> from sqlalchemy import select, func\n    >>> t = table(\"t\", column('value', ARRAY(Integer)))\n    >>> stmt = select(func.unnest(t.c.value).column_valued(\"unnested_value\"))\n    >>> print(stmt)\n    SELECT  unnested_value\n    FROM  unnest(t.value)  AS  unnested_value \n    ```", "```py\n>>> from sqlalchemy import table, column, func, tuple_\n>>> t = table(\"t\", column(\"id\"), column(\"fk\"))\n>>> stmt = t.select().where(\n...     tuple_(t.c.id, t.c.fk) > (1,2)\n... ).where(\n...     func.ROW(t.c.id, t.c.fk) < func.ROW(3, 7)\n... )\n>>> print(stmt)\nSELECT  t.id,  t.fk\nFROM  t\nWHERE  (t.id,  t.fk)  >  (:param_1,  :param_2)  AND  ROW(t.id,  t.fk)  <  ROW(:ROW_1,  :ROW_2) \n```", "```py\n>>> from sqlalchemy import table, column, func, select\n>>> a = table( \"a\", column(\"id\"), column(\"x\"), column(\"y\"))\n>>> stmt = select(func.row_to_json(a.table_valued()))\n>>> print(stmt)\nSELECT  row_to_json(a)  AS  row_to_json_1\nFROM  a \n```", "```py\nfrom sqlalchemy import TypeDecorator\nfrom sqlalchemy.dialects.postgresql import ARRAY\n\nclass ArrayOfEnum(TypeDecorator):\n    impl = ARRAY\n\n    def bind_expression(self, bindvalue):\n        return sa.cast(bindvalue, self)\n\n    def result_processor(self, dialect, coltype):\n        super_rp = super(ArrayOfEnum, self).result_processor(dialect, coltype)\n\n        def handle_raw_string(value):\n            inner = re.match(r\"^{(.*)}$\", value).group(1)\n            return inner.split(\",\") if inner else []\n\n        def process(value):\n            if value is None:\n                return None\n            return super_rp(handle_raw_string(value))\n\n        return process\n```", "```py\nTable(\n    \"mydata\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"data\", ArrayOfEnum(ENUM(\"a\", \"b\", \"c\", name=\"myenum\"))),\n)\n```", "```py\nclass CastingArray(ARRAY):\n    def bind_expression(self, bindvalue):\n        return sa.cast(bindvalue, self)\n```", "```py\nTable(\n    \"mydata\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"data\", CastingArray(JSONB)),\n)\n```", "```py\nfrom sqlalchemy import TypeDecorator\nfrom sqlalchemy.dialects.postgresql import ARRAY\n\nclass ArrayOfEnum(TypeDecorator):\n    impl = ARRAY\n\n    def bind_expression(self, bindvalue):\n        return sa.cast(bindvalue, self)\n\n    def result_processor(self, dialect, coltype):\n        super_rp = super(ArrayOfEnum, self).result_processor(dialect, coltype)\n\n        def handle_raw_string(value):\n            inner = re.match(r\"^{(.*)}$\", value).group(1)\n            return inner.split(\",\") if inner else []\n\n        def process(value):\n            if value is None:\n                return None\n            return super_rp(handle_raw_string(value))\n\n        return process\n```", "```py\nTable(\n    \"mydata\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"data\", ArrayOfEnum(ENUM(\"a\", \"b\", \"c\", name=\"myenum\"))),\n)\n```", "```py\nclass CastingArray(ARRAY):\n    def bind_expression(self, bindvalue):\n        return sa.cast(bindvalue, self)\n```", "```py\nTable(\n    \"mydata\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"data\", CastingArray(JSONB)),\n)\n```", "```py\nfrom datetime import datetime\n\nfrom sqlalchemy.dialects.postgresql import Range\nfrom sqlalchemy.dialects.postgresql import TSRANGE\nfrom sqlalchemy.orm import DeclarativeBase\nfrom sqlalchemy.orm import Mapped\nfrom sqlalchemy.orm import mapped_column\n\nclass Base(DeclarativeBase):\n    pass\n\nclass RoomBooking(Base):\n    __tablename__ = \"room_booking\"\n\n    id: Mapped[int] = mapped_column(primary_key=True)\n    room: Mapped[str]\n    during: Mapped[Range[datetime]] = mapped_column(TSRANGE)\n```", "```py\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import Session\n\nengine = create_engine(\"postgresql+psycopg://scott:tiger@pg14/dbname\")\n\nBase.metadata.create_all(engine)\n\nwith Session(engine) as session:\n    booking = RoomBooking(\n        room=\"101\", during=Range(datetime(2013, 3, 23), datetime(2013, 3, 25))\n    )\n    session.add(booking)\n    session.commit()\n```", "```py\nfrom sqlalchemy import select\n\nwith Session(engine) as session:\n    for row in session.execute(select(RoomBooking.during)):\n        print(row)\n```", "```py\nclass sqlalchemy.dialects.postgresql.Range\n```", "```py\nr = Range(10, 50, bounds=\"()\")\n```", "```py\nmethod __eq__(other: Any) \u2192 bool\n```", "```py\nmethod adjacent_to(other: Range[_T]) \u2192 bool\n```", "```py\nmethod contained_by(other: Range[_T]) \u2192 bool\n```", "```py\nmethod contains(value: _T | Range[_T]) \u2192 bool\n```", "```py\nmethod difference(other: Range[_T]) \u2192 Range[_T]\n```", "```py\nmethod intersection(other: Range[_T]) \u2192 Range[_T]\n```", "```py\nattribute is_empty\n```", "```py\nattribute isempty\n```", "```py\nattribute lower: _T | None\n```", "```py\nattribute lower_inc\n```", "```py\nattribute lower_inf\n```", "```py\nmethod not_extend_left_of(other: Range[_T]) \u2192 bool\n```", "```py\nmethod not_extend_right_of(other: Range[_T]) \u2192 bool\n```", "```py\nmethod overlaps(other: Range[_T]) \u2192 bool\n```", "```py\nmethod strictly_left_of(other: Range[_T]) \u2192 bool\n```", "```py\nmethod strictly_right_of(other: Range[_T]) \u2192 bool\n```", "```py\nmethod union(other: Range[_T]) \u2192 Range[_T]\n```", "```py\nattribute upper: _T | None\n```", "```py\nattribute upper_inc\n```", "```py\nattribute upper_inf\n```", "```py\nfrom datetime import datetime\nfrom typing import List\n\nfrom sqlalchemy.dialects.postgresql import Range\nfrom sqlalchemy.dialects.postgresql import TSMULTIRANGE\nfrom sqlalchemy.orm import DeclarativeBase\nfrom sqlalchemy.orm import Mapped\nfrom sqlalchemy.orm import mapped_column\n\nclass Base(DeclarativeBase):\n    pass\n\nclass EventCalendar(Base):\n    __tablename__ = \"event_calendar\"\n\n    id: Mapped[int] = mapped_column(primary_key=True)\n    event_name: Mapped[str]\n    added: Mapped[datetime]\n    in_session_periods: Mapped[List[Range[datetime]]] = mapped_column(TSMULTIRANGE)\n```", "```py\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import select\nfrom sqlalchemy.orm import Session\n\nengine = create_engine(\"postgresql+psycopg://scott:tiger@pg14/test\")\n\nBase.metadata.create_all(engine)\n\nwith Session(engine) as session:\n    calendar = EventCalendar(\n        event_name=\"SQLAlchemy Tutorial Sessions\",\n        in_session_periods=[\n            Range(datetime(2013, 3, 23), datetime(2013, 3, 25)),\n            Range(datetime(2013, 4, 12), datetime(2013, 4, 15)),\n            Range(datetime(2013, 5, 9), datetime(2013, 5, 12)),\n        ],\n    )\n    session.add(calendar)\n    session.commit()\n\n    for multirange in session.scalars(select(EventCalendar.in_session_periods)):\n        for range_ in multirange:\n            print(f\"Start: {range_.lower} End: {range_.upper}\")\n```", "```py\nfrom sqlalchemy import literal\nfrom sqlalchemy.dialects.postgresql import MultiRange\n\nwith Session(engine) as session:\n    stmt = select(EventCalendar).where(\n        EventCalendar.added.op(\"<@\")(\n            MultiRange(\n                [\n                    Range(datetime(2023, 1, 1), datetime(2013, 3, 31)),\n                    Range(datetime(2023, 7, 1), datetime(2013, 9, 30)),\n                ]\n            )\n        )\n    )\n    in_range = session.execute(stmt).all()\n\nwith engine.connect() as conn:\n    row = conn.scalar(select(literal(MultiRange([Range(2, 4)]))))\n    print(f\"{row.lower} -> {row.upper}\")\n```", "```py\nfrom datetime import datetime\nfrom typing import List\n\nfrom sqlalchemy.dialects.postgresql import Range\nfrom sqlalchemy.dialects.postgresql import TSMULTIRANGE\nfrom sqlalchemy.orm import DeclarativeBase\nfrom sqlalchemy.orm import Mapped\nfrom sqlalchemy.orm import mapped_column\n\nclass Base(DeclarativeBase):\n    pass\n\nclass EventCalendar(Base):\n    __tablename__ = \"event_calendar\"\n\n    id: Mapped[int] = mapped_column(primary_key=True)\n    event_name: Mapped[str]\n    added: Mapped[datetime]\n    in_session_periods: Mapped[List[Range[datetime]]] = mapped_column(TSMULTIRANGE)\n```", "```py\nfrom sqlalchemy import create_engine\nfrom sqlalchemy import select\nfrom sqlalchemy.orm import Session\n\nengine = create_engine(\"postgresql+psycopg://scott:tiger@pg14/test\")\n\nBase.metadata.create_all(engine)\n\nwith Session(engine) as session:\n    calendar = EventCalendar(\n        event_name=\"SQLAlchemy Tutorial Sessions\",\n        in_session_periods=[\n            Range(datetime(2013, 3, 23), datetime(2013, 3, 25)),\n            Range(datetime(2013, 4, 12), datetime(2013, 4, 15)),\n            Range(datetime(2013, 5, 9), datetime(2013, 5, 12)),\n        ],\n    )\n    session.add(calendar)\n    session.commit()\n\n    for multirange in session.scalars(select(EventCalendar.in_session_periods)):\n        for range_ in multirange:\n            print(f\"Start: {range_.lower} End: {range_.upper}\")\n```", "```py\nfrom sqlalchemy import literal\nfrom sqlalchemy.dialects.postgresql import MultiRange\n\nwith Session(engine) as session:\n    stmt = select(EventCalendar).where(\n        EventCalendar.added.op(\"<@\")(\n            MultiRange(\n                [\n                    Range(datetime(2023, 1, 1), datetime(2013, 3, 31)),\n                    Range(datetime(2023, 7, 1), datetime(2013, 9, 30)),\n                ]\n            )\n        )\n    )\n    in_range = session.execute(stmt).all()\n\nwith engine.connect() as conn:\n    row = conn.scalar(select(literal(MultiRange([Range(2, 4)]))))\n    print(f\"{row.lower} -> {row.upper}\")\n```", "```py\nfrom sqlalchemy import literal\nfrom sqlalchemy.dialects.postgresql import MultiRange\n\nwith Session(engine) as session:\n    stmt = select(EventCalendar).where(\n        EventCalendar.added.op(\"<@\")(\n            MultiRange(\n                [\n                    Range(datetime(2023, 1, 1), datetime(2013, 3, 31)),\n                    Range(datetime(2023, 7, 1), datetime(2013, 9, 30)),\n                ]\n            )\n        )\n    )\n    in_range = session.execute(stmt).all()\n\nwith engine.connect() as conn:\n    row = conn.scalar(select(literal(MultiRange([Range(2, 4)]))))\n    print(f\"{row.lower} -> {row.upper}\")\n```", "```py\ne = create_engine(\n    \"postgresql+psycopg://scott:tiger@host/dbname\", native_inet_types=False\n)\n```", "```py\nfrom sqlalchemy.dialects.postgresql import (\n    ARRAY,\n    BIGINT,\n    BIT,\n    BOOLEAN,\n    BYTEA,\n    CHAR,\n    CIDR,\n    CITEXT,\n    DATE,\n    DATEMULTIRANGE,\n    DATERANGE,\n    DOMAIN,\n    DOUBLE_PRECISION,\n    ENUM,\n    FLOAT,\n    HSTORE,\n    INET,\n    INT4MULTIRANGE,\n    INT4RANGE,\n    INT8MULTIRANGE,\n    INT8RANGE,\n    INTEGER,\n    INTERVAL,\n    JSON,\n    JSONB,\n    JSONPATH,\n    MACADDR,\n    MACADDR8,\n    MONEY,\n    NUMERIC,\n    NUMMULTIRANGE,\n    NUMRANGE,\n    OID,\n    REAL,\n    REGCLASS,\n    REGCONFIG,\n    SMALLINT,\n    TEXT,\n    TIME,\n    TIMESTAMP,\n    TSMULTIRANGE,\n    TSQUERY,\n    TSRANGE,\n    TSTZMULTIRANGE,\n    TSTZRANGE,\n    TSVECTOR,\n    UUID,\n    VARCHAR,\n)\n```", "```py\nclass sqlalchemy.dialects.postgresql.AbstractRange\n```", "```py\nclass comparator_factory\n```", "```py\nmethod adjacent_to(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod contained_by(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod contains(other: Any, **kw: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod difference(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod intersection(other: Any) \u2192 ColumnElement[Range[_T]]\n```", "```py\nmethod not_extend_left_of(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod not_extend_right_of(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod overlaps(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod strictly_left_of(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod strictly_right_of(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nmethod union(other: Any) \u2192 ColumnElement[bool]\n```", "```py\nclass sqlalchemy.dialects.postgresql.AbstractSingleRange\n```", "```py\nclass sqlalchemy.dialects.postgresql.AbstractMultiRange\n```", "```py\nclass sqlalchemy.dialects.postgresql.ARRAY\n```", "```py\nfrom sqlalchemy.dialects import postgresql\n\nmytable = Table(\"mytable\", metadata,\n        Column(\"data\", postgresql.ARRAY(Integer, dimensions=2))\n    )\n```", "```py\nmytable.c.data.contains([1, 2])\n```", "```py\nfrom sqlalchemy.dialects.postgresql import ARRAY\nfrom sqlalchemy.ext.mutable import MutableList\n\nclass SomeOrmClass(Base):\n    # ...\n\n    data = Column(MutableList.as_mutable(ARRAY(Integer)))\n```", "```py\nmethod __init__(item_type: _TypeEngineArgument[Any], as_tuple: bool = False, dimensions: int | None = None, zero_indexes: bool = False)\n```", "```py\nColumn('myarray', ARRAY(Integer))\n```", "```py\nclass Comparator\n```", "```py\nmethod contains(other, **kwargs)\n```", "```py\nmethod contained_by(other)\n```", "```py\nmethod overlap(other)\n```", "```py\nclass sqlalchemy.dialects.postgresql.BIT\n```", "```py\nclass sqlalchemy.dialects.postgresql.BYTEA\n```", "```py\nmethod __init__(length: int | None = None)\n```", "```py\nclass sqlalchemy.dialects.postgresql.CIDR\n```", "```py\nclass sqlalchemy.dialects.postgresql.CITEXT\n```", "```py\nmethod __init__(length: int | None = None, collation: str | None = None)\n```", "```py\n    >>> from sqlalchemy import cast, select, String\n    >>> print(select(cast('some string', String(collation='utf8'))))\n    SELECT  CAST(:param_1  AS  VARCHAR  COLLATE  utf8)  AS  anon_1 \n    ```", "```py\nclass sqlalchemy.dialects.postgresql.DOMAIN\n```", "```py\nPositiveInt = DOMAIN(\n    \"pos_int\", Integer, check=\"VALUE > 0\", not_null=True\n)\n\nUsPostalCode = DOMAIN(\n    \"us_postal_code\",\n    Text,\n    check=\"VALUE ~ '^\\d{5}$' OR VALUE ~ '^\\d{5}-\\d{4}$'\"\n)\n```", "```py\nmethod __init__(name: str, data_type: _TypeEngineArgument[Any], *, collation: str | None = None, default: elements.TextClause | str | None = None, constraint_name: str | None = None, not_null: bool | None = None, check: elements.TextClause | str | None = None, create_type: bool = True, **kw: Any)\n```", "```py\nmethod create(bind, checkfirst=True, **kw)\n```", "```py\nmethod drop(bind, checkfirst=True, **kw)\n```", "```py\nclass sqlalchemy.dialects.postgresql.DOUBLE_PRECISION\n```", "```py\nmethod __init__(precision: int | None = None, asdecimal: bool = False, decimal_return_scale: int | None = None)\n```", "```py\n    from sqlalchemy import Column\n    from sqlalchemy import Float\n    from sqlalchemy.dialects import oracle\n\n    Column(\n        \"float_data\",\n        Float(5).with_variant(oracle.FLOAT(binary_precision=16), \"oracle\")\n    )\n    ```", "```py\nclass sqlalchemy.dialects.postgresql.ENUM\n```", "```py\ntable = Table('sometable', metadata,\n    Column('some_enum', ENUM('a', 'b', 'c', name='myenum'))\n)\n\ntable.create(engine)  # will emit CREATE ENUM and CREATE TABLE\ntable.drop(engine)  # will emit DROP TABLE and DROP ENUM\n```", "```py\nmy_enum = ENUM('a', 'b', 'c', name='myenum', metadata=metadata)\n\nt1 = Table('sometable_one', metadata,\n    Column('some_enum', myenum)\n)\n\nt2 = Table('sometable_two', metadata,\n    Column('some_enum', myenum)\n)\n```", "```py\nt1.create(engine) # will fail: no such type 'myenum'\n```", "```py\n# will check if enum exists, and emit CREATE TYPE if not\nt1.create(engine, checkfirst=True)\n```", "```py\nmetadata.create_all(engine)  # will emit CREATE TYPE\nmetadata.drop_all(engine)  # will emit DROP TYPE\n```", "```py\nmy_enum.create(engine)\nmy_enum.drop(engine)\n```", "```py\nmethod __init__(*enums, name: str | _NoArg | None = _NoArg.NO_ARG, create_type: bool = True, **kw)\n```", "```py\nmethod create(bind=None, checkfirst=True)\n```", "```py\nmethod drop(bind=None, checkfirst=True)\n```", "```py\nclass sqlalchemy.dialects.postgresql.HSTORE\n```", "```py\ndata_table = Table('data_table', metadata,\n    Column('id', Integer, primary_key=True),\n    Column('data', HSTORE)\n)\n\nwith engine.connect() as conn:\n    conn.execute(\n        data_table.insert(),\n        data = {\"key1\": \"value1\", \"key2\": \"value2\"}\n    )\n```", "```py\n    data_table.c.data['some key'] == 'some value'\n    ```", "```py\n    data_table.c.data.has_key('some key')\n\n    data_table.c.data.has_all(['one', 'two', 'three'])\n    ```", "```py\n    data_table.c.data + {\"k1\": \"v1\"}\n    ```", "```py\nfrom sqlalchemy.ext.mutable import MutableDict\n\nclass MyClass(Base):\n    __tablename__ = 'data_table'\n\n    id = Column(Integer, primary_key=True)\n    data = Column(MutableDict.as_mutable(HSTORE))\n\nmy_object = session.query(MyClass).one()\n\n# in-place mutation, requires Mutable extension\n# in order for the ORM to detect\nmy_object.data['some_key'] = 'some value'\n\nsession.commit()\n```", "```py\nclass Comparator\n```", "```py\nmethod array()\n```", "```py\nmethod contained_by(other)\n```", "```py\nmethod contains(other, **kwargs)\n```", "```py\nmethod defined(key)\n```", "```py\nmethod delete(key)\n```", "```py\nmethod has_all(other)\n```", "```py\nmethod has_any(other)\n```", "```py\nmethod has_key(other)\n```", "```py\nmethod keys()\n```", "```py\nmethod matrix()\n```", "```py\nmethod slice(array)\n```", "```py\nmethod vals()\n```", "```py\nmethod __init__(text_type=None)\n```", "```py\nmethod bind_processor(dialect)\n```", "```py\nattribute comparator_factory\n```", "```py\nattribute hashable = False\n```", "```py\nmethod result_processor(dialect, coltype)\n```", "```py\nclass sqlalchemy.dialects.postgresql.INET\n```", "```py\nclass sqlalchemy.dialects.postgresql.INTERVAL\n```", "```py\nmethod __init__(precision: int | None = None, fields: str | None = None) \u2192 None\n```", "```py\nclass sqlalchemy.dialects.postgresql.JSON\n```", "```py\n    data_table.c.data['some key']\n\n    data_table.c.data[5]\n    ```", "```py\n    data_table.c.data['some key'].astext == 'some value'\n    ```", "```py\n    data_table.c.data['some key'].astext.cast(Integer) == 5\n    ```", "```py\n    data_table.c.data[('key_1', 'key_2', 5, ..., 'key_n')]\n    ```", "```py\n    data_table.c.data[('key_1', 'key_2', 5, ..., 'key_n')].astext == 'some value'\n    ```", "```py\nengine = create_engine(\"postgresql+psycopg2://scott:tiger@localhost/test\",\n                        json_serializer=my_serialize_fn,\n                        json_deserializer=my_deserialize_fn\n                )\n```", "```py\nclass Comparator\n```", "```py\nattribute astext\n```", "```py\nselect(data_table.c.data['some key'].astext)\n```", "```py\nmethod __init__(none_as_null=False, astext_type=None)\n```", "```py\n    from sqlalchemy import null\n    conn.execute(table.insert(), {\"data\": null()})\n    ```", "```py\nattribute comparator_factory\n```", "```py\nclass sqlalchemy.dialects.postgresql.JSONB\n```", "```py\ndata_table = Table('data_table', metadata,\n    Column('id', Integer, primary_key=True),\n    Column('data', JSONB)\n)\n\nwith engine.connect() as conn:\n    conn.execute(\n        data_table.insert(),\n        data = {\"key1\": \"value1\", \"key2\": \"value2\"}\n    )\n```", "```py\nclass Comparator\n```", "```py\nmethod contained_by(other)\n```", "```py\nmethod contains(other, **kwargs)\n```", "```py\nmethod delete_path(array)\n```", "```py\nmethod has_all(other)\n```", "```py\nmethod has_any(other)\n```", "```py\nmethod has_key(other)\n```", "```py\nmethod path_exists(other)\n```", "```py\nmethod path_match(other)\n```", "```py\nattribute comparator_factory\n```", "```py\nclass sqlalchemy.dialects.postgresql.JSONPATH\n```", "```py\nstmt = sa.select(\n    sa.func.jsonb_path_query_array(\n        table.c.jsonb_col, cast(\"$.address.id\", JSONPATH)\n    )\n)\n```", "```py\nclass sqlalchemy.dialects.postgresql.MACADDR\n```", "```py\nclass sqlalchemy.dialects.postgresql.MACADDR8\n```", "```py\nclass sqlalchemy.dialects.postgresql.MONEY\n```", "```py\nimport re\nimport decimal\nfrom sqlalchemy import Dialect\nfrom sqlalchemy import TypeDecorator\n\nclass NumericMoney(TypeDecorator):\n    impl = MONEY\n\n    def process_result_value(\n        self, value: Any, dialect: Dialect\n    ) -> None:\n        if value is not None:\n            # adjust this for the currency and numeric\n            m = re.match(r\"\\$([\\d.]+)\", value)\n            if m:\n                value = decimal.Decimal(m.group(1))\n        return value\n```", "```py\nimport decimal\nfrom sqlalchemy import cast\nfrom sqlalchemy import TypeDecorator\n\nclass NumericMoney(TypeDecorator):\n    impl = MONEY\n\n    def column_expression(self, column: Any):\n        return cast(column, Numeric())\n```", "```py\nclass sqlalchemy.dialects.postgresql.OID\n```", "```py\nclass sqlalchemy.dialects.postgresql.REAL\n```", "```py\nmethod __init__(precision: int | None = None, asdecimal: bool = False, decimal_return_scale: int | None = None)\n```", "```py\n    from sqlalchemy import Column\n    from sqlalchemy import Float\n    from sqlalchemy.dialects import oracle\n\n    Column(\n        \"float_data\",\n        Float(5).with_variant(oracle.FLOAT(binary_precision=16), \"oracle\")\n    )\n    ```", "```py\nclass sqlalchemy.dialects.postgresql.REGCONFIG\n```", "```py\nclass sqlalchemy.dialects.postgresql.REGCLASS\n```", "```py\nclass sqlalchemy.dialects.postgresql.TIMESTAMP\n```", "```py\nmethod __init__(timezone: bool = False, precision: int | None = None) \u2192 None\n```", "```py\nclass sqlalchemy.dialects.postgresql.TIME\n```", "```py\nmethod __init__(timezone: bool = False, precision: int | None = None) \u2192 None\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSQUERY\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSVECTOR\n```", "```py\nclass sqlalchemy.dialects.postgresql.UUID\n```", "```py\nmethod __init__(as_uuid: bool = True)\n```", "```py\nclass sqlalchemy.dialects.postgresql.INT4RANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.INT8RANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.NUMRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.DATERANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSTZRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.INT4MULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.INT8MULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.NUMMULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.DATEMULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSMULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.TSTZMULTIRANGE\n```", "```py\nclass sqlalchemy.dialects.postgresql.MultiRange\n```", "```py\nimport sqlalchemy as sa\nfrom sqlalchemy.dialects.postgresql import MultiRange, Range\n\nvalue = literal(MultiRange([Range(2, 4)]))\n\nselect(tbl).where(tbl.c.value.op(\"@\")(MultiRange([Range(-3, 7)])))\n```", "```py\nclass sqlalchemy.dialects.postgresql.aggregate_order_by\n```", "```py\nfrom sqlalchemy.dialects.postgresql import aggregate_order_by\nexpr = func.array_agg(aggregate_order_by(table.c.a, table.c.b.desc()))\nstmt = select(expr)\n```", "```py\nSELECT array_agg(a ORDER BY b DESC) FROM table;\n```", "```py\nexpr = func.string_agg(\n    table.c.a,\n    aggregate_order_by(literal_column(\"','\"), table.c.a)\n)\nstmt = select(expr)\n```", "```py\nSELECT string_agg(a, ',' ORDER BY a) FROM table;\n```", "```py\nclass sqlalchemy.dialects.postgresql.array\n```", "```py\nfrom sqlalchemy.dialects.postgresql import array\nfrom sqlalchemy.dialects import postgresql\nfrom sqlalchemy import select, func\n\nstmt = select(array([1,2]) + array([3,4,5]))\n\nprint(stmt.compile(dialect=postgresql.dialect()))\n```", "```py\nSELECT ARRAY[%(param_1)s, %(param_2)s] ||\n    ARRAY[%(param_3)s, %(param_4)s, %(param_5)s]) AS anon_1\n```", "```py\narray(['foo', 'bar'], type_=CHAR)\n```", "```py\nstmt = select(\n    array([\n        array([1, 2]), array([3, 4]), array([column('q'), column('x')])\n    ])\n)\nprint(stmt.compile(dialect=postgresql.dialect()))\n```", "```py\nSELECT ARRAY[ARRAY[%(param_1)s, %(param_2)s],\nARRAY[%(param_3)s, %(param_4)s], ARRAY[q, x]] AS anon_1\n```", "```py\nfunction sqlalchemy.dialects.postgresql.array_agg(*arg, **kw)\n```", "```py\nfunction sqlalchemy.dialects.postgresql.Any(other, arrexpr, operator=<built-in function eq>)\n```", "```py\nfunction sqlalchemy.dialects.postgresql.All(other, arrexpr, operator=<built-in function eq>)\n```", "```py\nclass sqlalchemy.dialects.postgresql.hstore\n```", "```py\nfrom sqlalchemy.dialects.postgresql import array, hstore\n\nselect(hstore('key1', 'value1'))\n\nselect(\n    hstore(\n        array(['key1', 'key2', 'key3']),\n        array(['value1', 'value2', 'value3'])\n    )\n)\n```", "```py\nattribute inherit_cache: bool | None = True\n```", "```py\nattribute type\n```", "```py\nclass sqlalchemy.dialects.postgresql.to_tsvector\n```", "```py\nclass sqlalchemy.dialects.postgresql.to_tsquery\n```", "```py\nclass sqlalchemy.dialects.postgresql.plainto_tsquery\n```", "```py\nclass sqlalchemy.dialects.postgresql.phraseto_tsquery\n```", "```py\nclass sqlalchemy.dialects.postgresql.websearch_to_tsquery\n```", "```py\nclass sqlalchemy.dialects.postgresql.ts_headline\n```", "```py\nclass sqlalchemy.dialects.postgresql.ExcludeConstraint\n```", "```py\nmethod __init__(*elements, **kw)\n```", "```py\nconst = ExcludeConstraint(\n    (Column('period'), '&&'),\n    (Column('group'), '='),\n    where=(Column('group') != 'some group'),\n    ops={'group': 'my_operator_class'}\n)\n```", "```py\nsome_table = Table(\n    'some_table', metadata,\n    Column('id', Integer, primary_key=True),\n    Column('period', TSRANGE()),\n    Column('group', String)\n)\n\nsome_table.append_constraint(\n    ExcludeConstraint(\n        (some_table.c.period, '&&'),\n        (some_table.c.group, '='),\n        where=some_table.c.group != 'some group',\n        name='some_table_excl_const',\n        ops={'group': 'my_operator_class'}\n    )\n)\n```", "```py\nfrom sqlalchemy.dialects.postgresql import ExcludeConstraint, TSRANGE\n\nclass RoomBooking(Base):\n    __tablename__ = \"room_booking\"\n\n    room = Column(Integer(), primary_key=True)\n    during = Column(TSRANGE())\n\n    __table_args__ = (ExcludeConstraint((\"room\", \"=\"), (\"during\", \"&&\")),)\n```", "```py\nfunction sqlalchemy.dialects.postgresql.insert(table: _DMLTableArgument) \u2192 Insert\n```", "```py\nclass sqlalchemy.dialects.postgresql.Insert\n```", "```py\nattribute excluded\n```", "```py\nattribute inherit_cache: bool | None = False\n```", "```py\nmethod on_conflict_do_nothing(constraint: _OnConflictConstraintT = None, index_elements: _OnConflictIndexElementsT = None, index_where: _OnConflictIndexWhereT = None) \u2192 Self\n```", "```py\nmethod on_conflict_do_update(constraint: _OnConflictConstraintT = None, index_elements: _OnConflictIndexElementsT = None, index_where: _OnConflictIndexWhereT = None, set_: _OnConflictSetT = None, where: _OnConflictWhereT = None) \u2192 Self\n```", "```py\npostgresql+psycopg2://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\nengine = create_engine(\n    \"postgresql+psycopg2://scott:tiger@localhost/test\",\n    isolation_level=\"SERIALIZABLE\",\n)\n```", "```py\nengine = sa.create_engine(\n    \"postgresql+psycopg2://scott:tiger@192.168.0.199:5432/test?sslmode=require\"\n)\n```", "```py\ncreate_engine(\"postgresql+psycopg2://user:password@/dbname\")\n```", "```py\ncreate_engine(\"postgresql+psycopg2://user:password@/dbname?host=/var/lib/postgresql\")\n```", "```py\nengine = create_engine(\"postgresql+psycopg2://user:password@myhost1/dbname?host=myhost2\")\n```", "```py\ncreate_engine(\n    \"postgresql+psycopg2://user:password@/dbname?host=HostA:PortA&host=HostB&host=HostC:PortC\"\n)\n```", "```py\ncreate_engine(\n    \"postgresql+psycopg2://user:password@/dbname?host=HostA,HostB,HostC&port=PortA,,PortC\"\n)\n```", "```py\ncreate_engine(\n    \"postgresql+psycopg2://user:password@/dbname?host=HostA:PortA&host=HostB&host=HostC:PortC&target_session_attrs=primary\"\n)\n```", "```py\nengine = create_engine('postgresql+psycopg2://')\n```", "```py\nengine = create_engine(\n    \"postgresql+psycopg2://scott:tiger@host/dbname\",\n    executemany_mode='values_plus_batch')\n```", "```py\nengine = create_engine(\n    \"postgresql+psycopg2://scott:tiger@host/dbname\",\n    executemany_mode='values_plus_batch',\n    insertmanyvalues_page_size=5000, executemany_batch_page_size=500)\n```", "```py\n    engine = create_engine(\"postgresql+psycopg2://user:pass@host/dbname?client_encoding=utf8\")\n    ```", "```py\n    engine = create_engine(\n        \"postgresql+psycopg2://user:pass@host/dbname\",\n        connect_args={'client_encoding': 'utf8'}\n    )\n    ```", "```py\n    engine = create_engine(\n        \"postgresql+psycopg2://user:pass@host/dbname\",\n        client_encoding=\"utf8\"\n    )\n    ```", "```py\n    # postgresql.conf file\n\n    # client_encoding = sql_ascii # actually, defaults to database\n                                 # encoding\n    client_encoding = utf8\n    ```", "```py\nimport logging\n\nlogging.getLogger('sqlalchemy.dialects.postgresql').setLevel(logging.INFO)\n```", "```py\nimport logging\n\nlogging.basicConfig()   # log messages to stdout\nlogging.getLogger('sqlalchemy.dialects.postgresql').setLevel(logging.INFO)\n```", "```py\nengine = create_engine(\"postgresql+psycopg2://scott:tiger@localhost/test\",\n            use_native_hstore=False)\n```", "```py\npostgresql+psycopg2://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\nengine = create_engine(\n    \"postgresql+psycopg2://scott:tiger@localhost/test\",\n    isolation_level=\"SERIALIZABLE\",\n)\n```", "```py\nengine = sa.create_engine(\n    \"postgresql+psycopg2://scott:tiger@192.168.0.199:5432/test?sslmode=require\"\n)\n```", "```py\ncreate_engine(\"postgresql+psycopg2://user:password@/dbname\")\n```", "```py\ncreate_engine(\"postgresql+psycopg2://user:password@/dbname?host=/var/lib/postgresql\")\n```", "```py\nengine = create_engine(\"postgresql+psycopg2://user:password@myhost1/dbname?host=myhost2\")\n```", "```py\ncreate_engine(\n    \"postgresql+psycopg2://user:password@/dbname?host=HostA:PortA&host=HostB&host=HostC:PortC\"\n)\n```", "```py\ncreate_engine(\n    \"postgresql+psycopg2://user:password@/dbname?host=HostA,HostB,HostC&port=PortA,,PortC\"\n)\n```", "```py\ncreate_engine(\n    \"postgresql+psycopg2://user:password@/dbname?host=HostA:PortA&host=HostB&host=HostC:PortC&target_session_attrs=primary\"\n)\n```", "```py\nengine = create_engine('postgresql+psycopg2://')\n```", "```py\nengine = create_engine(\n    \"postgresql+psycopg2://scott:tiger@host/dbname\",\n    executemany_mode='values_plus_batch')\n```", "```py\nengine = create_engine(\n    \"postgresql+psycopg2://scott:tiger@host/dbname\",\n    executemany_mode='values_plus_batch',\n    insertmanyvalues_page_size=5000, executemany_batch_page_size=500)\n```", "```py\n    engine = create_engine(\"postgresql+psycopg2://user:pass@host/dbname?client_encoding=utf8\")\n    ```", "```py\n    engine = create_engine(\n        \"postgresql+psycopg2://user:pass@host/dbname\",\n        connect_args={'client_encoding': 'utf8'}\n    )\n    ```", "```py\n    engine = create_engine(\n        \"postgresql+psycopg2://user:pass@host/dbname\",\n        client_encoding=\"utf8\"\n    )\n    ```", "```py\n    # postgresql.conf file\n\n    # client_encoding = sql_ascii # actually, defaults to database\n                                 # encoding\n    client_encoding = utf8\n    ```", "```py\nimport logging\n\nlogging.getLogger('sqlalchemy.dialects.postgresql').setLevel(logging.INFO)\n```", "```py\nimport logging\n\nlogging.basicConfig()   # log messages to stdout\nlogging.getLogger('sqlalchemy.dialects.postgresql').setLevel(logging.INFO)\n```", "```py\nengine = create_engine(\"postgresql+psycopg2://scott:tiger@localhost/test\",\n            use_native_hstore=False)\n```", "```py\npostgresql+psycopg://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\n    from sqlalchemy import create_engine\n    sync_engine = create_engine(\"postgresql+psycopg://scott:tiger@localhost/test\")\n    ```", "```py\n    from sqlalchemy.ext.asyncio import create_async_engine\n    asyncio_engine = create_async_engine(\"postgresql+psycopg://scott:tiger@localhost/test\")\n    ```", "```py\nfrom sqlalchemy.ext.asyncio import create_async_engine\nasyncio_engine = create_async_engine(\"postgresql+psycopg_async://scott:tiger@localhost/test\")\n```", "```py\nfrom psycopg import ClientCursor\n\nclient_side_engine = create_engine(\n    \"postgresql+psycopg://...\",\n    connect_args={\"cursor_factory\": ClientCursor},\n)\n```", "```py\nfrom psycopg import AsyncClientCursor\n\nclient_side_engine = create_async_engine(\n    \"postgresql+psycopg://...\",\n    connect_args={\"cursor_factory\": AsyncClientCursor},\n)\n```", "```py\npostgresql+psycopg://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\nfrom psycopg import ClientCursor\n\nclient_side_engine = create_engine(\n    \"postgresql+psycopg://...\",\n    connect_args={\"cursor_factory\": ClientCursor},\n)\n```", "```py\nfrom psycopg import AsyncClientCursor\n\nclient_side_engine = create_async_engine(\n    \"postgresql+psycopg://...\",\n    connect_args={\"cursor_factory\": AsyncClientCursor},\n)\n```", "```py\npostgresql+pg8000://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\n#client_encoding = sql_ascii # actually, defaults to database\n                             # encoding\nclient_encoding = utf8\n```", "```py\nengine = create_engine(\n    \"postgresql+pg8000://user:pass@host/dbname\", client_encoding='utf8')\n```", "```py\nimport ssl\nssl_context = ssl.create_default_context()\nengine = sa.create_engine(\n    \"postgresql+pg8000://scott:tiger@192.168.0.199/test\",\n    connect_args={\"ssl_context\": ssl_context},\n)\n```", "```py\nimport ssl\nssl_context = ssl.create_default_context()\nssl_context.check_hostname = False\nssl_context.verify_mode = ssl.CERT_NONE\nengine = sa.create_engine(\n    \"postgresql+pg8000://scott:tiger@192.168.0.199/test\",\n    connect_args={\"ssl_context\": ssl_context},\n)\n```", "```py\npostgresql+pg8000://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\n#client_encoding = sql_ascii # actually, defaults to database\n                             # encoding\nclient_encoding = utf8\n```", "```py\nengine = create_engine(\n    \"postgresql+pg8000://user:pass@host/dbname\", client_encoding='utf8')\n```", "```py\nimport ssl\nssl_context = ssl.create_default_context()\nengine = sa.create_engine(\n    \"postgresql+pg8000://scott:tiger@192.168.0.199/test\",\n    connect_args={\"ssl_context\": ssl_context},\n)\n```", "```py\nimport ssl\nssl_context = ssl.create_default_context()\nssl_context.check_hostname = False\nssl_context.verify_mode = ssl.CERT_NONE\nengine = sa.create_engine(\n    \"postgresql+pg8000://scott:tiger@192.168.0.199/test\",\n    connect_args={\"ssl_context\": ssl_context},\n)\n```", "```py\npostgresql+asyncpg://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\nfrom sqlalchemy.ext.asyncio import create_async_engine\nengine = create_async_engine(\"postgresql+asyncpg://user:pass@hostname/dbname\")\n```", "```py\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:password@/dbname?host=HostA:5432&host=HostB:5432&host=HostC:5432\"\n)\n```", "```py\nengine = create_async_engine(\"postgresql+asyncpg://user:pass@hostname/dbname?prepared_statement_cache_size=500\")\n```", "```py\nengine = create_async_engine(\"postgresql+asyncpg://user:pass@hostname/dbname?prepared_statement_cache_size=0\")\n```", "```py\nfrom uuid import uuid4\n\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:pass@somepgbouncer/dbname\",\n    poolclass=NullPool,\n    connect_args={\n        'prepared_statement_name_func': lambda:  f'__asyncpg_{uuid4()}__',\n    },\n)\n```", "```py\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:password@localhost/tmp\",\n    connect_args={\"server_settings\": {\"jit\": \"off\"}},\n)\n```", "```py\npostgresql+asyncpg://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:password@/dbname?host=HostA:5432&host=HostB:5432&host=HostC:5432\"\n)\n```", "```py\nengine = create_async_engine(\"postgresql+asyncpg://user:pass@hostname/dbname?prepared_statement_cache_size=500\")\n```", "```py\nengine = create_async_engine(\"postgresql+asyncpg://user:pass@hostname/dbname?prepared_statement_cache_size=0\")\n```", "```py\nfrom uuid import uuid4\n\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:pass@somepgbouncer/dbname\",\n    poolclass=NullPool,\n    connect_args={\n        'prepared_statement_name_func': lambda:  f'__asyncpg_{uuid4()}__',\n    },\n)\n```", "```py\nengine = create_async_engine(\n    \"postgresql+asyncpg://user:password@localhost/tmp\",\n    connect_args={\"server_settings\": {\"jit\": \"off\"}},\n)\n```", "```py\npostgresql+psycopg2cffi://user:password@host:port/dbname[?key=value&key=value...]\n```", "```py\npostgresql+psycopg2cffi://user:password@host:port/dbname[?key=value&key=value...]\n```"]