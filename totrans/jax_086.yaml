- en: Asynchronous dispatch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`jax.readthedocs.io/en/latest/async_dispatch.html`](https://jax.readthedocs.io/en/latest/async_dispatch.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'JAX uses asynchronous dispatch to hide Python overheads. Consider the following
    program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: When an operation such as `jnp.dot(x, x)` is executed, JAX does not wait for
    the operation to complete before returning control to the Python program. Instead,
    JAX returns a `jax.Array` value, which is a future, i.e., a value that will be
    produced in the future on an accelerator device but isn’t necessarily available
    immediately. We can inspect the shape or type of a `jax.Array` without waiting
    for the computation that produced it to complete, and we can even pass it to another
    JAX computation, as we do with the addition operation here. Only if we actually
    inspect the value of the array from the host, for example by printing it or by
    converting it into a plain old [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray
    "(in NumPy v2.0)") will JAX force the Python code to wait for the computation
    to complete.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous dispatch is useful since it allows Python code to “run ahead” of
    an accelerator device, keeping Python code out of the critical path. Provided
    the Python code enqueues work on the device faster than it can be executed, and
    provided that the Python code does not actually need to inspect the output of
    a computation on the host, then a Python program can enqueue arbitrary amounts
    of work and avoid having the accelerator wait.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous dispatch has a slightly surprising consequence for microbenchmarks.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 269µs is a surprisingly small time for a 1000x1000 matrix multiplication on
    CPU! However it turns out that asynchronous dispatch is misleading us and we are
    not timing the execution of the matrix multiplication, only the time to dispatch
    the work. To measure the true cost of the operation we must either read the value
    on the host (e.g., convert it to a plain old host-side numpy array), or use the
    `block_until_ready()` method on a `jax.Array` value to wait for the computation
    that produced it to complete.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Blocking without transferring the result back to Python is usually faster, and
    is often the best choice when writing microbenchmarks of computation times.
  prefs: []
  type: TYPE_NORMAL
