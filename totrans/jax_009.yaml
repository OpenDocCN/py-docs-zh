- en: Automatic vectorization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`jax.readthedocs.io/en/latest/automatic-vectorization.html`](https://jax.readthedocs.io/en/latest/automatic-vectorization.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In the previous section we discussed JIT compilation via the `jax.jit()` function.
    This notebook discusses another of JAX’s transforms: vectorization via `jax.vmap()`.'
  prefs: []
  type: TYPE_NORMAL
- en: Manual vectorization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Consider the following simple code that computes the convolution of two one-dimensional
    vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Suppose we would like to apply this function to a batch of weights `w` to a
    batch of vectors `x`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The most naive option would be to simply loop over the batch in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This produces the correct result, however it is not very efficient.
  prefs: []
  type: TYPE_NORMAL
- en: In order to batch the computation efficiently, you would normally have to rewrite
    the function manually to ensure it is done in vectorized form. This is not particularly
    difficult to implement, but does involve changing how the function treats indices,
    axes, and other parts of the input.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, we could manually rewrite `convolve()` to support vectorized computation
    across the batch dimension as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Such re-implementation can be messy and error-prone as the complexity of a function
    increases; fortunately JAX provides another way.
  prefs: []
  type: TYPE_NORMAL
- en: Automatic vectorization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In JAX, the `jax.vmap()` transformation is designed to generate such a vectorized
    implementation of a function automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: It does this by tracing the function similarly to `jax.jit()`, and automatically
    adding batch axes at the beginning of each input.
  prefs: []
  type: TYPE_NORMAL
- en: If the batch dimension is not the first, you may use the `in_axes` and `out_axes`
    arguments to specify the location of the batch dimension in inputs and outputs.
    These may be an integer if the batch axis is the same for all inputs and outputs,
    or lists, otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '`jax.vmap()` also supports the case where only one of the arguments is batched:
    for example, if you would like to convolve to a single set of weights `w` with
    a batch of vectors `x`; in this case the `in_axes` argument can be set to `None`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Combining transformations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As with all JAX transformations, `jax.jit()` and `jax.vmap()` are designed
    to be composable, which means you can wrap a vmapped function with `jit`, or a
    jitted function with `vmap`, and everything will work correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
