["```py\nimport matplotlib.pyplot as plt\n\nfrom jax import random\nimport jax.numpy as jnp\nimport numpy as np\n\nkey = random.key(1701)\n\nx = jnp.linspace(0, 10, 500)\ny = jnp.sin(x) + 0.2 * random.normal(key, shape=(500,))\n\nwindow = jnp.ones(10) / 10\ny_smooth = jnp.convolve(y, window, mode='same')\n\nplt.plot(x, y, 'lightgray')\nplt.plot(x, y_smooth, 'black'); \n```", "```py\nfrom scipy import misc\nimport jax.scipy as jsp\n\nfig, ax = plt.subplots(1, 3, figsize=(12, 5))\n\n# Load a sample image; compute mean() to convert from RGB to grayscale.\nimage = jnp.array(misc.face().mean(-1))\nax[0].imshow(image, cmap='binary_r')\nax[0].set_title('original')\n\n# Create a noisy version by adding random Gaussian noise\nkey = random.key(1701)\nnoisy_image = image + 50 * random.normal(key, image.shape)\nax[1].imshow(noisy_image, cmap='binary_r')\nax[1].set_title('noisy')\n\n# Smooth the noisy image with a 2D Gaussian smoothing kernel.\nx = jnp.linspace(-3, 3, 7)\nwindow = jsp.stats.norm.pdf(x) * jsp.stats.norm.pdf(x[:, None])\nsmooth_image = jsp.signal.convolve(noisy_image, window, mode='same')\nax[2].imshow(smooth_image, cmap='binary_r')\nax[2].set_title('smoothed'); \n```", "```py\n/tmp/ipykernel_1464/4118182506.py:7: DeprecationWarning: scipy.misc.face has been deprecated in SciPy v1.10.0; and will be completely removed in SciPy v1.12.0\\. Dataset methods have moved into the scipy.datasets module. Use scipy.datasets.face instead.\n  image = jnp.array(misc.face().mean(-1)) \n```", "```py\n# 2D kernel - HWIO layout\nkernel = jnp.zeros((3, 3, 3, 3), dtype=jnp.float32)\nkernel += jnp.array([[1, 1, 0],\n                     [1, 0,-1],\n                     [0,-1,-1]])[:, :, jnp.newaxis, jnp.newaxis]\n\nprint(\"Edge Conv kernel:\")\nplt.imshow(kernel[:, :, 0, 0]); \n```", "```py\nEdge Conv kernel: \n```", "```py\n# NHWC layout\nimg = jnp.zeros((1, 200, 198, 3), dtype=jnp.float32)\nfor k in range(3):\n  x = 30 + 60*k\n  y = 20 + 60*k\n  img = img.at[0, x:x+10, y:y+10, k].set(1.0)\n\nprint(\"Original Image:\")\nplt.imshow(img[0]); \n```", "```py\nOriginal Image: \n```", "```py\nfrom jax import lax\nout = lax.conv(jnp.transpose(img,[0,3,1,2]),    # lhs = NCHW image tensor\n               jnp.transpose(kernel,[3,2,0,1]), # rhs = OIHW conv kernel tensor\n               (1, 1),  # window strides\n               'SAME') # padding mode\nprint(\"out shape: \", out.shape)\nprint(\"First output channel:\")\nplt.figure(figsize=(10,10))\nplt.imshow(np.array(out)[0,0,:,:]); \n```", "```py\nout shape:  (1, 3, 200, 198)\nFirst output channel: \n```", "```py\nout = lax.conv_with_general_padding(\n  jnp.transpose(img,[0,3,1,2]),    # lhs = NCHW image tensor\n  jnp.transpose(kernel,[2,3,0,1]), # rhs = IOHW conv kernel tensor\n  (1, 1),  # window strides\n  ((2,2),(2,2)), # general padding 2x2\n  (1,1),  # lhs/image dilation\n  (1,1))  # rhs/kernel dilation\nprint(\"out shape: \", out.shape)\nprint(\"First output channel:\")\nplt.figure(figsize=(10,10))\nplt.imshow(np.array(out)[0,0,:,:]); \n```", "```py\nout shape:  (1, 3, 202, 200)\nFirst output channel: \n```", "```py\ndn = lax.conv_dimension_numbers(img.shape,     # only ndim matters, not shape\n                                kernel.shape,  # only ndim matters, not shape \n                                ('NHWC', 'HWIO', 'NHWC'))  # the important bit\nprint(dn) \n```", "```py\nConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) \n```", "```py\nout = lax.conv_general_dilated(img,    # lhs = image tensor\n                               kernel, # rhs = conv kernel tensor\n                               (1,1),  # window strides\n                               'SAME', # padding mode\n                               (1,1),  # lhs/image dilation\n                               (1,1),  # rhs/kernel dilation\n                               dn)     # dimension_numbers = lhs, rhs, out dimension permutation\nprint(\"out shape: \", out.shape)\nprint(\"First output channel:\")\nplt.figure(figsize=(10,10))\nplt.imshow(np.array(out)[0,:,:,0]); \n```", "```py\nout shape:  (1, 200, 198, 3)\nFirst output channel: \n```", "```py\nout = lax.conv_general_dilated(img,     # lhs = image tensor\n                               kernel,  # rhs = conv kernel tensor\n                               (1,1),   # window strides\n                               'VALID', # padding mode\n                               (1,1),   # lhs/image dilation\n                               (1,1),   # rhs/kernel dilation\n                               dn)      # dimension_numbers = lhs, rhs, out dimension permutation\nprint(\"out shape: \", out.shape, \"DIFFERENT from above!\")\nprint(\"First output channel:\")\nplt.figure(figsize=(10,10))\nplt.imshow(np.array(out)[0,:,:,0]); \n```", "```py\nout shape:  (1, 198, 196, 3) DIFFERENT from above!\nFirst output channel: \n```", "```py\nout = lax.conv_general_dilated(img,    # lhs = image tensor\n                               kernel, # rhs = conv kernel tensor\n                               (2,2),  # window strides\n                               'SAME', # padding mode\n                               (1,1),  # lhs/image dilation\n                               (1,1),  # rhs/kernel dilation\n                               dn)     # dimension_numbers = lhs, rhs, out dimension permutation\nprint(\"out shape: \", out.shape, \" <-- half the size of above\")\nplt.figure(figsize=(10,10))\nprint(\"First output channel:\")\nplt.imshow(np.array(out)[0,:,:,0]); \n```", "```py\nout shape:  (1, 100, 99, 3)  <-- half the size of above\nFirst output channel: \n```", "```py\nout = lax.conv_general_dilated(img,     # lhs = image tensor\n                               kernel,  # rhs = conv kernel tensor\n                               (1,1),   # window strides\n                               'VALID', # padding mode\n                               (1,1),   # lhs/image dilation\n                               (12,12), # rhs/kernel dilation\n                               dn)      # dimension_numbers = lhs, rhs, out dimension permutation\nprint(\"out shape: \", out.shape)\nplt.figure(figsize=(10,10))\nprint(\"First output channel:\")\nplt.imshow(np.array(out)[0,:,:,0]); \n```", "```py\nout shape:  (1, 176, 174, 3)\nFirst output channel: \n```", "```py\nout = lax.conv_general_dilated(img,               # lhs = image tensor\n                               kernel,            # rhs = conv kernel tensor\n                               (1,1),             # window strides\n                               ((0, 0), (0, 0)),  # padding mode\n                               (2,2),             # lhs/image dilation\n                               (1,1),             # rhs/kernel dilation\n                               dn)                # dimension_numbers = lhs, rhs, out dimension permutation\nprint(\"out shape: \", out.shape, \"<-- larger than original!\")\nplt.figure(figsize=(10,10))\nprint(\"First output channel:\")\nplt.imshow(np.array(out)[0,:,:,0]); \n```", "```py\nout shape:  (1, 397, 393, 3) <-- larger than original!\nFirst output channel: \n```", "```py\n# The following is equivalent to tensorflow:\n# N,H,W,C = img.shape\n# out = tf.nn.conv2d_transpose(img, kernel, (N,2*H,2*W,C), (1,2,2,1))\n\n# transposed conv = 180deg kernel rotation plus LHS dilation\n# rotate kernel 180deg:\nkernel_rot = jnp.rot90(jnp.rot90(kernel, axes=(0,1)), axes=(0,1))\n# need a custom output padding:\npadding = ((2, 1), (2, 1))\nout = lax.conv_general_dilated(img,     # lhs = image tensor\n                               kernel_rot,  # rhs = conv kernel tensor\n                               (1,1),   # window strides\n                               padding, # padding mode\n                               (2,2),   # lhs/image dilation\n                               (1,1),   # rhs/kernel dilation\n                               dn)      # dimension_numbers = lhs, rhs, out dimension permutation\nprint(\"out shape: \", out.shape, \"<-- transposed_conv\")\nplt.figure(figsize=(10,10))\nprint(\"First output channel:\")\nplt.imshow(np.array(out)[0,:,:,0]); \n```", "```py\nout shape:  (1, 400, 396, 3) <-- transposed_conv\nFirst output channel: \n```", "```py\n# 1D kernel - WIO layout\nkernel = jnp.array([[[1, 0, -1], [-1,  0,  1]], \n                    [[1, 1,  1], [-1, -1, -1]]], \n                    dtype=jnp.float32).transpose([2,1,0])\n# 1D data - NWC layout\ndata = np.zeros((1, 200, 2), dtype=jnp.float32)\nfor i in range(2):\n  for k in range(2):\n      x = 35*i + 30 + 60*k\n      data[0, x:x+30, k] = 1.0\n\nprint(\"in shapes:\", data.shape, kernel.shape)\n\nplt.figure(figsize=(10,5))\nplt.plot(data[0]);\ndn = lax.conv_dimension_numbers(data.shape, kernel.shape,\n                                ('NWC', 'WIO', 'NWC'))\nprint(dn)\n\nout = lax.conv_general_dilated(data,   # lhs = image tensor\n                               kernel, # rhs = conv kernel tensor\n                               (1,),   # window strides\n                               'SAME', # padding mode\n                               (1,),   # lhs/image dilation\n                               (1,),   # rhs/kernel dilation\n                               dn)     # dimension_numbers = lhs, rhs, out dimension permutation\nprint(\"out shape: \", out.shape)\nplt.figure(figsize=(10,5))\nplt.plot(out[0]); \n```", "```py\nin shapes: (1, 200, 2) (3, 2, 2)\nConvDimensionNumbers(lhs_spec=(0, 2, 1), rhs_spec=(2, 1, 0), out_spec=(0, 2, 1))\nout shape:  (1, 200, 2) \n```", "```py\nimport matplotlib as mpl\n\n# Random 3D kernel - HWDIO layout\nkernel = jnp.array([\n  [[0, 0,  0], [0,  1,  0], [0,  0,   0]],\n  [[0, -1, 0], [-1, 0, -1], [0,  -1,  0]], \n  [[0, 0,  0], [0,  1,  0], [0,  0,   0]]], \n  dtype=jnp.float32)[:, :, :, jnp.newaxis, jnp.newaxis]\n\n# 3D data - NHWDC layout\ndata = jnp.zeros((1, 30, 30, 30, 1), dtype=jnp.float32)\nx, y, z = np.mgrid[0:1:30j, 0:1:30j, 0:1:30j]\ndata += (jnp.sin(2*x*jnp.pi)*jnp.cos(2*y*jnp.pi)*jnp.cos(2*z*jnp.pi))[None,:,:,:,None]\n\nprint(\"in shapes:\", data.shape, kernel.shape)\ndn = lax.conv_dimension_numbers(data.shape, kernel.shape,\n                                ('NHWDC', 'HWDIO', 'NHWDC'))\nprint(dn)\n\nout = lax.conv_general_dilated(data,    # lhs = image tensor\n                               kernel,  # rhs = conv kernel tensor\n                               (1,1,1), # window strides\n                               'SAME',  # padding mode\n                               (1,1,1), # lhs/image dilation\n                               (1,1,1), # rhs/kernel dilation\n                               dn)      # dimension_numbers\nprint(\"out shape: \", out.shape)\n\n# Make some simple 3d density plots:\nfrom mpl_toolkits.mplot3d import Axes3D\ndef make_alpha(cmap):\n  my_cmap = cmap(jnp.arange(cmap.N))\n  my_cmap[:,-1] = jnp.linspace(0, 1, cmap.N)**3\n  return mpl.colors.ListedColormap(my_cmap)\nmy_cmap = make_alpha(plt.cm.viridis)\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\nax.scatter(x.ravel(), y.ravel(), z.ravel(), c=data.ravel(), cmap=my_cmap)\nax.axis('off')\nax.set_title('input')\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\nax.scatter(x.ravel(), y.ravel(), z.ravel(), c=out.ravel(), cmap=my_cmap)\nax.axis('off')\nax.set_title('3D conv output'); \n```", "```py\nin shapes: (1, 30, 30, 30, 1) (3, 3, 3, 1, 1)\nConvDimensionNumbers(lhs_spec=(0, 4, 1, 2, 3), rhs_spec=(4, 3, 0, 1, 2), out_spec=(0, 4, 1, 2, 3))\nout shape:  (1, 30, 30, 30, 1) \n```"]