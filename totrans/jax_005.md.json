["```py\ny = 0\n\n# @jit   # Different behavior with jit\ndef impure_func(x):\n  print(\"Inside:\", y)\n  return x + y\n\nfor y in range(3):\n  print(\"Result:\", impure_func(y)) \n```", "```py\nInside: 0\nResult: 0\nInside: 1\nResult: 2\nInside: 2\nResult: 4 \n```", "```py\nInside: 0\nResult: 0\nResult: 1\nResult: 2 \n```", "```py\n>>> from jax import jit\n>>> import jax.numpy as jnp\n>>> def f(x):\n...   return jnp.log(jnp.sqrt(x))\n>>> x = jnp.pi\n>>> print(f(x))\n0.572365 \n```", "```py\n>>> print(jit(f)(x))\n0.5723649 \n```", "```py\n>>> def f(x):\n...   return jnp.log(jnp.exp(x))\n>>> x = 100.0\n>>> print(f(x))\ninf \n```", "```py\n>>> print(jit(f)(x))\n100.0 \n```", "```py\n>>> import jax.numpy as jnp\n>>> from jax import jit\n\n>>> class CustomClass:\n...   def __init__(self, x: jnp.ndarray, mul: bool):\n...     self.x = x\n...     self.mul = mul\n...\n...   @jit  # <---- How to do this correctly?\n...   def calc(self, y):\n...     if self.mul:\n...       return self.x * y\n...     return y \n```", "```py\n>>> c = CustomClass(2, True)\n>>> c.calc(3)  \n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n  File \"<stdin>\", line 1, in <module\nTypeError: Argument '<CustomClass object at 0x7f7dd4125890>' of type <class 'CustomClass'> is not a valid JAX type. \n```", "```py\n>>> from functools import partial\n\n>>> class CustomClass:\n...   def __init__(self, x: jnp.ndarray, mul: bool):\n...     self.x = x\n...     self.mul = mul\n...\n...   def calc(self, y):\n...     return _calc(self.mul, self.x, y)\n\n>>> @partial(jit, static_argnums=0)\n... def _calc(mul, x, y):\n...   if mul:\n...     return x * y\n...   return y \n```", "```py\n>>> c = CustomClass(2, True)\n>>> print(c.calc(3))\n6 \n```", "```py\n>>> class CustomClass:\n...   def __init__(self, x: jnp.ndarray, mul: bool):\n...     self.x = x\n...     self.mul = mul\n...\n...   # WARNING: this example is broken, as we'll see below. Don't copy & paste!\n...   @partial(jit, static_argnums=0)\n...   def calc(self, y):\n...     if self.mul:\n...       return self.x * y\n...     return y \n```", "```py\n>>> c = CustomClass(2, True)\n>>> print(c.calc(3))\n6 \n```", "```py\n>>> c.mul = False\n>>> print(c.calc(3))  # Should print 3\n6 \n```", "```py\n>>> class CustomClass:\n...   def __init__(self, x: jnp.ndarray, mul: bool):\n...     self.x = x\n...     self.mul = mul\n...\n...   @partial(jit, static_argnums=0)\n...   def calc(self, y):\n...     if self.mul:\n...       return self.x * y\n...     return y\n...\n...   def __hash__(self):\n...     return hash((self.x, self.mul))\n...\n...   def __eq__(self, other):\n...     return (isinstance(other, CustomClass) and\n...             (self.x, self.mul) == (other.x, other.mul)) \n```", "```py\n>>> class CustomClass:\n...   def __init__(self, x: jnp.ndarray, mul: bool):\n...     self.x = x\n...     self.mul = mul\n...\n...   @jit\n...   def calc(self, y):\n...     if self.mul:\n...       return self.x * y\n...     return y\n...\n...   def _tree_flatten(self):\n...     children = (self.x,)  # arrays / dynamic values\n...     aux_data = {'mul': self.mul}  # static values\n...     return (children, aux_data)\n...\n...   @classmethod\n...   def _tree_unflatten(cls, aux_data, children):\n...     return cls(*children, **aux_data)\n\n>>> from jax import tree_util\n>>> tree_util.register_pytree_node(CustomClass,\n...                                CustomClass._tree_flatten,\n...                                CustomClass._tree_unflatten) \n```", "```py\n>>> c = CustomClass(2, True)\n>>> print(c.calc(3))\n6\n\n>>> c.mul = False  # mutation is detected\n>>> print(c.calc(3))\n3\n\n>>> c = CustomClass(jnp.array(2), True)  # non-hashable x is supported\n>>> print(c.calc(3))\n6 \n```", "```py\n>>> from jax import numpy as jnp\n>>> print(jnp.ones(3).devices())  \n{CudaDevice(id=0)} \n```", "```py\n>>> import jax\n>>> from jax import device_put\n>>> arr = device_put(1, jax.devices()[2])  \n>>> print(arr.devices())  \n{CudaDevice(id=2)} \n```", "```py\nimport numpy as np\nimport jax.numpy as jnp\nimport jax\n\ndef f(x):  # function we're benchmarking (works in both NumPy & JAX)\n  return x.T @ (x - x.mean(axis=0))\n\nx_np = np.ones((1000, 1000), dtype=np.float32)  # same as JAX default dtype\n%timeit f(x_np)  # measure NumPy runtime\n\n%time x_jax = jax.device_put(x_np)  # measure JAX device transfer time\nf_jit = jax.jit(f)\n%time f_jit(x_jax).block_until_ready()  # measure JAX compilation time\n%timeit f_jit(x_jax).block_until_ready()  # measure JAX runtime \n```", "```py\ndef func(x):\n  print(x)\n  return jnp.cos(x)\n\nres = jax.jit(func)(0.) \n```", "```py\ndef divide(x, y):\n  return x / y if y >= 1. else 0. \n```", "```py\nparams, state = jax.pmap(update_fn, donate_argnums=(0, 1))(params, state) \n```", "```py\ndef add(x, y):\n  return x + y\n\nx = jax.device_put(np.ones((2, 3)))\ny = jax.device_put(np.ones((2, 3)))\n# Execute `add` with donation of the buffer for `y`. The result has\n# the same shape and type as `y`, so it will share its buffer.\nz = jax.jit(add, donate_argnums=(1,))(x, y) \n```", "```py\nparams, state = jax.pmap(update_fn, donate_argnums=(0, 1))(params=params, state=state) \n```", "```py\ndef add_ones(xs: List[Array]):\n  return [x + 1 for x in xs]\n\nxs = [jax.device_put(np.ones((2, 3))), jax.device_put(np.ones((3, 4)))]\n# Execute `add_ones` with donation of all the buffers for `xs`.\n# The outputs have the same shape and type as the elements of `xs`,\n# so they will share those buffers.\nz = jax.jit(add_ones, donate_argnums=0)(xs) \n```", "```py\n# Donate the buffer for `y`\nz = jax.jit(add, donate_argnums=(1,))(x, y)\nw = y + 1  # Reuses `y` whose buffer was donated above\n# >> RuntimeError: Invalid argument: CopyToHostAsync() called on invalid buffer \n```", "```py\n# Execute `add` with donation of the buffers for both `x` and `y`.\n# One of those buffers will be used for the result, but the other will\n# not be used.\nz = jax.jit(add, donate_argnums=(0, 1))(x, y)\n# >> UserWarning: Some donated buffers were not usable: f32[2,3]{1,0} \n```", "```py\ny = jax.device_put(np.ones((1, 3)))  # `y` has different shape than the output\n# Execute `add` with donation of the buffer for `y`.\nz = jax.jit(add, donate_argnums=(1,))(x, y)\n# >> UserWarning: Some donated buffers were not usable: f32[1,3]{1,0} \n```", "```py\ndef my_log(x):\n  return jnp.where(x > 0., jnp.log(x), 0.)\n\nmy_log(0.) ==> 0.  # Ok\njax.grad(my_log)(0.)  ==> NaN \n```", "```py\ndef safe_for_grad_log(x):\n  return jnp.log(jnp.where(x > 0., x, 1.))\n\nsafe_for_grad_log(0.) ==> 0.  # Ok\njax.grad(safe_for_grad_log)(0.)  ==> 0.  # Ok \n```", "```py\ndef my_log_or_y(x, y):\n  \"\"\"Return log(x) if x > 0 or y\"\"\"\n  return jnp.where(x > 0., jnp.log(jnp.where(x > 0., x, 1.)), y) \n```", "```py\nimport jax\nimport numpy as np\nimport jax.numpy as jnp\n\ndef f(x):\n  return (x > 0).astype(float)\n\ndf = jax.vmap(jax.grad(f))\n\nx = jnp.array([-1.0, -0.5, 0.0, 0.5, 1.0])\n\nprint(f\"f(x)  = {f(x)}\")\n# f(x)  = [0\\. 0\\. 0\\. 1\\. 1.]\n\nprint(f\"df(x) = {df(x)}\")\n# df(x) = [0\\. 0\\. 0\\. 0\\. 0.] \n```", "```py\ndef g(x):\n  return jax.nn.sigmoid(x)\n\ndg = jax.vmap(jax.grad(g))\n\nx = jnp.array([-10.0, -1.0, 0.0, 1.0, 10.0])\n\nwith np.printoptions(suppress=True, precision=2):\n  print(f\"g(x)  = {g(x)}\")\n  # g(x)  = [0\\.   0.27 0.5  0.73 1\\.  ]\n\n  print(f\"dg(x) = {dg(x)}\")\n  # dg(x) = [0\\.   0.2  0.25 0.2  0\\.  ] \n```", "```py\n@jax.jit\ndef f(x):\n  print(type(x))\n  return x\n\nf(jnp.arange(5)) \n```", "```py\n<class 'jax.interpreters.partial_eval.DynamicJaxprTracer'> \n```"]