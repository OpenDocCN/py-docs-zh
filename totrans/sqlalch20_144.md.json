["```py\n>>> obj = MyObj()\n>>> obj.some_value\nNone\n```", "```py\n>>> obj = MyObj()\n>>> obj.some_value\n\"my default\"\n```", "```py\nresult = (\n    session.query(func.substr(A.some_thing, 0, 4), A).options(joinedload(A.bs)).all()\n)\n\nusers = (\n    session.query(\n        func.date(User.date_created, \"start of month\").label(\"month\"),\n        User,\n    )\n    .options(joinedload(User.orders))\n    .all()\n)\n```", "```py\nresult = (\n    session.query(func.substr(A.some_thing, 0, 4, type_=String), A)\n    .options(joinedload(A.bs))\n    .all()\n)\n\nusers = (\n    session.query(\n        func.date(User.date_created, \"start of month\", type_=DateTime).label(\"month\"),\n        User,\n    )\n    .options(joinedload(User.orders))\n    .all()\n)\n```", "```py\n>>> some_user = User()\n>>> q = s.query(User).filter(User.name == some_user)\nsqlalchemy.exc.ArgumentError: Object <__main__.User object at 0x103167e90> is not legal as a SQL literal value\n```", "```py\n>>> # Address.user refers to the User mapper, so\n>>> # this is of course still OK!\n>>> q = s.query(Address).filter(Address.user == some_user)\n```", "```py\nclass Person(Base):\n    __tablename__ = \"person\"\n\n    id = Column(Integer, primary_key=True)\n    data = Column(JSON)\n\n    name = index_property(\"data\", \"name\")\n```", "```py\n>>> person = Person(name=\"foobar\")\n>>> person.name\nfoobar\n```", "```py\nclass Widget(Base):\n    __tablename__ = \"widget\"\n    id = Column(Integer, primary_key=True)\n    type = Column(String)\n    data = Column(String)\n    __mapper_args__ = {\"polymorphic_on\": type}\n\nclass FooWidget(Widget):\n    __mapper_args__ = {\"polymorphic_identity\": \"foo\"}\n\nq = session.query(FooWidget).filter(FooWidget.data == \"bar\").exists()\n\nsession.query(q).all()\n```", "```py\nSELECT  EXISTS  (SELECT  1\nFROM  widget\nWHERE  widget.data  =  :data_1  AND  widget.type  IN  (:type_1))  AS  anon_1\n```", "```py\ns = Session()\ns.begin_nested()\n\ns.add(SomeObject())\n\ntry:\n    # assume the flush fails, flush goes to rollback to the\n    # savepoint and that also fails\n    s.flush()\nexcept Exception as err:\n    print(\"Something broke, and our SAVEPOINT vanished too\")\n\n# this is the SAVEPOINT transaction, marked as\n# DEACTIVE so the rollback() call succeeds\ns.rollback()\n\n# this is the outermost transaction, remains ACTIVE\n# so rollback() or commit() can succeed\ns.rollback()\n```", "```py\nfrom sqlalchemy import Column, create_engine\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\ne = create_engine(\"sqlite://\", echo=True)\nBase.metadata.create_all(e)\n\ns = Session(e)\n\n# persist an object\ns.add(A(id=1))\ns.flush()\n\n# rollback buffer loses reference to A\n\n# load it again, rollback buffer knows nothing\n# about it\na1 = s.query(A).first()\n\n# roll back the transaction; all state is expired but the\n# \"a1\" reference remains\ns.rollback()\n\n# previous \"a1\" conflicts with the new one because we aren't\n# checking that it never got committed\ns.add(A(id=1))\ns.commit()\n```", "```py\nFlushError: New instance <User at 0x7f0287eca4d0> with identity key\n(<class 'test.orm.test_transaction.User'>, ('u1',)) conflicts\nwith persistent instance <User at 0x7f02889c70d0>\n```", "```py\nBEGIN  (implicit)\n\nINSERT  INTO  a  (id)  VALUES  (?)\n(1,)\n\nSELECT  a.id  AS  a_id  FROM  a  LIMIT  ?  OFFSET  ?\n(1,  0)\n\nROLLBACK\n\nBEGIN  (implicit)\n\nSELECT  a.id  AS  a_id  FROM  a  WHERE  a.id  =  ?\n(1,)\n\nINSERT  INTO  a  (id)  VALUES  (?)\n(1,)\n\nCOMMIT\n```", "```py\nfrom sqlalchemy import Column, Integer, String, ForeignKey, create_engine\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(\"id\", Integer, primary_key=True)\n    type = Column(String)\n\n    __mapper_args__ = {\n        \"polymorphic_on\": type,\n        \"polymorphic_identity\": \"a\",\n        \"passive_deletes\": True,\n    }\n\nclass B(A):\n    __tablename__ = \"b\"\n    b_table_id = Column(\"b_table_id\", Integer, primary_key=True)\n    bid = Column(\"bid\", Integer, ForeignKey(\"a.id\", ondelete=\"CASCADE\"))\n    data = Column(\"data\", String)\n\n    __mapper_args__ = {\"polymorphic_identity\": \"b\"}\n```", "```py\nsession.delete(some_b)\nsession.commit()\n```", "```py\nDELETE  FROM  a  WHERE  a.id  =  %(id)s\n-- {'id': 1}\nCOMMIT\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n    b = relationship(\"B\", foreign_keys=\"B.a_id\", backref=\"a\")\n\nclass A1(A):\n    __tablename__ = \"a1\"\n    id = Column(Integer, primary_key=True)\n    b = relationship(\"B\", foreign_keys=\"B.a1_id\", backref=\"a1\")\n    __mapper_args__ = {\"concrete\": True}\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n\n    a_id = Column(ForeignKey(\"a.id\"))\n    a1_id = Column(ForeignKey(\"a1.id\"))\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\nclass A1(A):\n    __tablename__ = \"a1\"\n    id = Column(Integer, primary_key=True)\n    __mapper_args__ = {\"concrete\": True}\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n\n    a_id = Column(ForeignKey(\"a.id\"))\n    a1_id = Column(ForeignKey(\"a1.id\"))\n\n    a = relationship(\"A\", backref=\"b\")\n    a1 = relationship(\"A1\", backref=\"b\")\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n    bs = relationship(\"B\")\n\nclass ASub(A):\n    __tablename__ = \"a_sub\"\n    id = Column(Integer, ForeignKey(\"a.id\"), primary_key=True)\n    bs = relationship(\"B\")\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n    a_id = Column(ForeignKey(\"a.id\"))\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\n    name = Column(String)\n\n    @hybrid_property\n    def some_name(self):\n  \"\"\"The name field\"\"\"\n        return self.name\n```", "```py\n>>> A.some_name.__doc__\nThe name field\n```", "```py\n>>> assert A.name is A.some_name\n```", "```py\n>>> A.some_name\n<sqlalchemy.orm.attributes.hybrid_propertyProxy object at 0x7fde03888230>\n```", "```py\n>>> A.some_name.info[\"foo\"] = \"bar\"\n>>> from sqlalchemy import inspect\n>>> inspect(A).all_orm_descriptors[\"some_name\"].info\n{'foo': 'bar'}\n```", "```py\nu1 = User(id=7, name=\"x\")\nu1.orders = [\n    Order(description=\"o1\", address=Address(id=1, email_address=\"a\")),\n    Order(description=\"o2\", address=Address(id=1, email_address=\"b\")),\n    Order(description=\"o3\", address=Address(id=1, email_address=\"c\")),\n]\n\nsess = Session()\nsess.merge(u1)\n```", "```py\nsome_object = SomeClass()\nsession.add(some_object)\nsome_object.parent_id = some_parent.id\nsome_object.parent = some_parent\n```", "```py\n# before the fix\nassert some_object not in some_parent.items\n```", "```py\n# after the fix, backref fired off for some_object.parent = some_parent\nassert some_object in some_parent.items\n```", "```py\nsess.query(Person.name).filter(\n    sess.query(Company.name)\n    .filter(Company.company_id == Person.company_id)\n    .correlate(Person)\n    .as_scalar()\n    == \"Elbonia, Inc.\"\n)\n```", "```py\nSELECT  people.name  AS  people_name\nFROM  people\nLEFT  OUTER  JOIN  engineers  ON  people.person_id  =  engineers.person_id\nLEFT  OUTER  JOIN  managers  ON  people.person_id  =  managers.person_id\nWHERE  (SELECT  companies.name\nFROM  companies\nWHERE  companies.company_id  =  people.company_id)  =  ?\n```", "```py\n-- old, incorrect query\nSELECT  people.name  AS  people_name\nFROM  people\nLEFT  OUTER  JOIN  engineers  ON  people.person_id  =  engineers.person_id\nLEFT  OUTER  JOIN  managers  ON  people.person_id  =  managers.person_id\nWHERE  (SELECT  companies.name\nFROM  companies,  people\nWHERE  companies.company_id  =  people.company_id)  =  ?\n```", "```py\n# works with all SQLAlchemy versions and all types of polymorphic\n# aliasing.\n\npaliased = aliased(Person)\nsess.query(paliased.name).filter(\n    sess.query(Company.name)\n    .filter(Company.company_id == paliased.company_id)\n    .correlate(paliased)\n    .as_scalar()\n    == \"Elbonia, Inc.\"\n)\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n    b_id = Column(ForeignKey(\"b.id\"))\n    c_id = Column(ForeignKey(\"c.id\"))\n\n    b = relationship(\"B\")\n    c = relationship(\"C\")\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n    c_id = Column(ForeignKey(\"c.id\"))\n\n    c = relationship(\"C\")\n\nclass C(Base):\n    __tablename__ = \"c\"\n    id = Column(Integer, primary_key=True)\n    d_id = Column(ForeignKey(\"d.id\"))\n    d = relationship(\"D\")\n\nclass D(Base):\n    __tablename__ = \"d\"\n    id = Column(Integer, primary_key=True)\n\nc_alias_1 = aliased(C)\nc_alias_2 = aliased(C)\n\nq = s.query(A)\nq = q.join(A.b).join(c_alias_1, B.c).join(c_alias_1.d)\nq = q.options(\n    contains_eager(A.b).contains_eager(B.c, alias=c_alias_1).contains_eager(C.d)\n)\nq = q.join(c_alias_2, A.c)\nq = q.options(contains_eager(A.c, alias=c_alias_2))\n```", "```py\nSELECT\n  d.id  AS  d_id,\n  c_1.id  AS  c_1_id,  c_1.d_id  AS  c_1_d_id,\n  b.id  AS  b_id,  b.c_id  AS  b_c_id,\n  c_2.id  AS  c_2_id,  c_2.d_id  AS  c_2_d_id,\n  a.id  AS  a_id,  a.b_id  AS  a_b_id,  a.c_id  AS  a_c_id\nFROM\n  a\n  JOIN  b  ON  b.id  =  a.b_id\n  JOIN  c  AS  c_1  ON  c_1.id  =  b.c_id\n  JOIN  d  ON  d.id  =  c_1.d_id\n  JOIN  c  AS  c_2  ON  c_2.id  =  a.c_id\n```", "```py\n>>> from sqlalchemy.orm import raiseload\n>>> a1 = s.query(A).options(raiseload(A.some_b)).first()\n>>> a1.some_b\nTraceback (most recent call last):\n...\nsqlalchemy.exc.InvalidRequestError: 'A.some_b' is not available due to lazy='raise'\n```", "```py\n>>> from sqlalchemy.orm import raiseload\n>>> a1 = s.query(A).options(raiseload(A.some_b, sql_only=True)).first()\n>>> a1.some_b\nTraceback (most recent call last):\n...\nsqlalchemy.exc.InvalidRequestError: 'A.bs' is not available due to lazy='raise_on_sql'\n```", "```py\nengine = create_engine(\"postgresql+psycopg2://\")\n\n@event.listens_for(engine, \"handle_error\")\ndef cancel_disconnect(ctx):\n    if isinstance(ctx.original_exception, KeyboardInterrupt):\n        ctx.is_disconnect = False\n```", "```py\n>>> from sqlalchemy import table, column, select, literal, exists\n>>> orders = table(\n...     \"orders\",\n...     column(\"region\"),\n...     column(\"amount\"),\n...     column(\"product\"),\n...     column(\"quantity\"),\n... )\n>>>\n>>> upsert = (\n...     orders.update()\n...     .where(orders.c.region == \"Region1\")\n...     .values(amount=1.0, product=\"Product1\", quantity=1)\n...     .returning(*(orders.c._all_columns))\n...     .cte(\"upsert\")\n... )\n>>>\n>>> insert = orders.insert().from_select(\n...     orders.c.keys(),\n...     select([literal(\"Region1\"), literal(1.0), literal(\"Product1\"), literal(1)]).where(\n...         ~exists(upsert.select())\n...     ),\n... )\n>>>\n>>> print(insert)  # Note: formatting added for clarity\nWITH  upsert  AS\n(UPDATE  orders  SET  amount=:amount,  product=:product,  quantity=:quantity\n  WHERE  orders.region  =  :region_1\n  RETURNING  orders.region,  orders.amount,  orders.product,  orders.quantity\n)\nINSERT  INTO  orders  (region,  amount,  product,  quantity)\nSELECT\n  :param_1  AS  anon_1,  :param_2  AS  anon_2,\n  :param_3  AS  anon_3,  :param_4  AS  anon_4\nWHERE  NOT  (\n  EXISTS  (\n  SELECT  upsert.region,  upsert.amount,\n  upsert.product,  upsert.quantity\n  FROM  upsert)) \n```", "```py\n>>> from sqlalchemy import func\n\n>>> print(func.row_number().over(order_by=\"x\", range_=(-5, 10)))\nrow_number()  OVER  (ORDER  BY  x  RANGE  BETWEEN  :param_1  PRECEDING  AND  :param_2  FOLLOWING)\n>>> print(func.row_number().over(order_by=\"x\", rows=(None, 0)))\nrow_number()  OVER  (ORDER  BY  x  ROWS  BETWEEN  UNBOUNDED  PRECEDING  AND  CURRENT  ROW)\n>>> print(func.row_number().over(order_by=\"x\", range_=(-2, None)))\nrow_number()  OVER  (ORDER  BY  x  RANGE  BETWEEN  :param_1  PRECEDING  AND  UNBOUNDED  FOLLOWING) \n```", "```py\n>>> from sqlalchemy import table, column, select, true\n>>> people = table(\"people\", column(\"people_id\"), column(\"age\"), column(\"name\"))\n>>> books = table(\"books\", column(\"book_id\"), column(\"owner_id\"))\n>>> subq = (\n...     select([books.c.book_id])\n...     .where(books.c.owner_id == people.c.people_id)\n...     .lateral(\"book_subq\")\n... )\n>>> print(select([people]).select_from(people.join(subq, true())))\nSELECT  people.people_id,  people.age,  people.name\nFROM  people  JOIN  LATERAL  (SELECT  books.book_id  AS  book_id\nFROM  books  WHERE  books.owner_id  =  people.people_id)\nAS  book_subq  ON  true \n```", "```py\nfrom sqlalchemy import func\n\nselectable = people.tablesample(func.bernoulli(1), name=\"alias\", seed=func.random())\nstmt = select([selectable.c.people_id])\n```", "```py\nSELECT  alias.people_id  FROM\npeople  AS  alias  TABLESAMPLE  bernoulli(:bernoulli_1)\nREPEATABLE  (random())\n```", "```py\nTable(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True),\n)\n```", "```py\n# old way\nTable(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True, autoincrement=False),\n    Column(\"y\", Integer, primary_key=True, autoincrement=False),\n)\n```", "```py\n# column 'y' will be SERIAL/AUTO_INCREMENT/ auto-generating\nTable(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n)\n```", "```py\nTable(\n    \"b\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True),\n)\n```", "```py\nSAWarning: Column 'b.x' is marked as a member of the primary\nkey for table 'b', but has no Python-side or server-side default\ngenerator indicated, nor does it indicate 'autoincrement=True',\nand no explicit value is passed.  Primary key columns may not\nstore NULL. Note that as of SQLAlchemy 1.1, 'autoincrement=True'\nmust be indicated explicitly for composite (e.g. multicolumn)\nprimary keys if AUTO_INCREMENT/SERIAL/IDENTITY behavior is\nexpected for one of the columns in the primary key. CREATE TABLE\nstatements are impacted by this change as well on most backends.\n```", "```py\nTable(\n    \"b\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True, server_default=FetchedValue()),\n    Column(\"y\", Integer, primary_key=True, server_default=FetchedValue()),\n)\n```", "```py\nTable(\n    \"b\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, nullable=True),\n)\n```", "```py\n>>> print(column(\"x\").is_distinct_from(None))\nx  IS  DISTINCT  FROM  NULL \n```", "```py\n>>> print(column(\"x\").isnot_distinct_from(False))\nx  IS  NOT  DISTINCT  FROM  false \n```", "```py\n>>> from sqlalchemy.dialects import sqlite\n>>> print(column(\"x\").is_distinct_from(None).compile(dialect=sqlite.dialect()))\nx  IS  NOT  NULL \n```", "```py\nstmt = select([t1]).select_from(t1.outerjoin(t2, full=True))\n```", "```py\nq = session.query(MyClass).outerjoin(MyOtherClass, full=True)\n```", "```py\nfrom sqlalchemy import text\n\nstmt = text(\n    \"SELECT users.id, addresses.id, users.id, \"\n    \"users.name, addresses.email_address AS email \"\n    \"FROM users JOIN addresses ON users.id=addresses.user_id \"\n    \"WHERE users.id = 1\"\n).columns(User.id, Address.id, Address.user_id, User.name, Address.email_address)\n\nquery = session.query(User).from_statement(stmt).options(contains_eager(User.addresses))\nresult = query.all()\n```", "```py\nua = users.alias(\"ua\")\nstmt = select([users.c.user_id, ua.c.user_id])\n```", "```py\nSELECT  users.user_id,  ua.user_id  FROM  users,  users  AS  ua\n```", "```py\nresult = conn.execute(stmt)\nrow = result.first()\n\n# these both match positionally, so no error\nuser_id = row[users.c.user_id]\nua_id = row[ua.c.user_id]\n\n# this still raises, however\nuser_id = row[\"user_id\"]\n```", "```py\nimport enum\nfrom sqlalchemy import Table, MetaData, Column, Enum, create_engine\n\nclass MyEnum(enum.Enum):\n    one = 1\n    two = 2\n    three = 3\n\nt = Table(\"data\", MetaData(), Column(\"value\", Enum(MyEnum)))\n\ne = create_engine(\"sqlite://\")\nt.create(e)\n\ne.execute(t.insert(), {\"value\": MyEnum.two})\nassert e.scalar(t.select()) is MyEnum.two\n```", "```py\n>>> from sqlalchemy import create_engine\n>>> e = create_engine(\"sqlite://\")\n>>> row = e.execute(\"select 1, 2, 3\").first()\n>>> row[-1], row[-2], row[1], row[-2:2]\n3 2 2 (2,)\n```", "```py\n>>> from sqlalchemy import Table, MetaData, Column, Enum, create_engine\n>>> t = Table(\n...     \"data\",\n...     MetaData(),\n...     Column(\"value\", Enum(\"one\", \"two\", \"three\", validate_strings=True)),\n... )\n>>> e = create_engine(\"sqlite://\")\n>>> t.create(e)\n>>> e.execute(t.insert(), {\"value\": \"four\"})\nTraceback (most recent call last):\n  ...\nsqlalchemy.exc.StatementError: (exceptions.LookupError)\n\"four\" is not among the defined enum values\n[SQL: u'INSERT INTO data (value) VALUES (?)']\n[parameters: [{'value': 'four'}]]\n```", "```py\n>>> from sqlalchemy import create_engine\n>>> import random\n>>> e = create_engine(\"sqlite://\", echo=\"debug\")\n>>> some_value = \"\".join(chr(random.randint(52, 85)) for i in range(5000))\n>>> row = e.execute(\"select ?\", [some_value]).first()\n... # (lines are wrapped for clarity) ...\n2016-02-17 13:23:03,027 INFO sqlalchemy.engine.base.Engine select ?\n2016-02-17 13:23:03,027 INFO sqlalchemy.engine.base.Engine\n('E6@?>9HPOJB<<BHR:@=TS:5ILU=;JLM<4?B9<S48PTNG9>:=TSTLA;9K;9FPM4M8M@;NM6GU\nLUAEBT9QGHNHTHR5EP75@OER4?SKC;D:TFUMD:M>;C6U:JLM6R67GEK<A6@S@C@J7>4=4:P\nGJ7HQ6 ... (4702 characters truncated) ... J6IK546AJMB4N6S9L;;9AKI;=RJP\nHDSSOTNBUEEC9@Q:RCL:I@5?FO<9K>KJAGAO@E6@A7JI8O:J7B69T6<8;F:S;4BEIJS9HM\nK:;5OLPM@JR;R:J6<SOTTT=>Q>7T@I::OTDC:CC<=NGP6C>BC8N',)\n2016-02-17 13:23:03,027 DEBUG sqlalchemy.engine.base.Engine Col ('?',)\n2016-02-17 13:23:03,027 DEBUG sqlalchemy.engine.base.Engine\nRow (u'E6@?>9HPOJB<<BHR:@=TS:5ILU=;JLM<4?B9<S48PTNG9>:=TSTLA;9K;9FPM4M8M@;\nNM6GULUAEBT9QGHNHTHR5EP75@OER4?SKC;D:TFUMD:M>;C6U:JLM6R67GEK<A6@S@C@J7\n>4=4:PGJ7HQ ... (4703 characters truncated) ... J6IK546AJMB4N6S9L;;9AKI;=\nRJPHDSSOTNBUEEC9@Q:RCL:I@5?FO<9K>KJAGAO@E6@A7JI8O:J7B69T6<8;F:S;4BEIJS9HM\nK:;5OLPM@JR;R:J6<SOTTT=>Q>7T@I::OTDC:CC<=NGP6C>BC8N',)\n>>> print(row)\n(u'E6@?>9HPOJB<<BHR:@=TS:5ILU=;JLM<4?B9<S48PTNG9>:=TSTLA;9K;9FPM4M8M@;NM6\nGULUAEBT9QGHNHTHR5EP75@OER4?SKC;D:TFUMD:M>;C6U:JLM6R67GEK<A6@S@C@J7>4\n=4:PGJ7HQ ... (4703 characters truncated) ... J6IK546AJMB4N6S9L;;9AKI;\n=RJPHDSSOTNBUEEC9@Q:RCL:I@5?FO<9K>KJAGAO@E6@A7JI8O:J7B69T6<8;F:S;4BEIJS9H\nMK:;5OLPM@JR;R:J6<SOTTT=>Q>7T@I::OTDC:CC<=NGP6C>BC8N',)\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    json_value = Column(JSON(none_as_null=False), default=\"some default\")\n\n# would insert \"some default\" instead of \"'null'\",\n# now will insert \"'null'\"\nobj = MyObject(json_value=None)\nsession.add(obj)\nsession.commit()\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    some_other_value = Column(String(50))\n    json_value = Column(JSON(none_as_null=False))\n\n# would result in NULL for some_other_value,\n# but json \"'null'\" for json_value.  Now results in NULL for both\n# (the json_value is omitted from the INSERT)\nobj = MyObject()\nsession.add(obj)\nsession.commit()\n```", "```py\n# would insert SQL NULL and/or trigger defaults,\n# now inserts \"'null'\"\nsession.bulk_insert_mappings(MyObject, [{\"json_value\": None}])\n```", "```py\nfrom sqlalchemy import null\nfrom sqlalchemy.dialects.postgresql import JSON\n\nobj1 = MyObject(json_value=null())  # will *always* insert SQL NULL\nobj2 = MyObject(json_value=JSON.NULL)  # will *always* insert JSON string \"null\"\n\nsession.add_all([obj1, obj2])\nsession.commit()\n```", "```py\nmytable = Table(\"mytable\", metadata, Column(\"data\", ARRAY(Integer, dimensions=2)))\n\nexpr = mytable.c.data[5][6]\n\nexpr = mytable.c.data[5].any(12)\n```", "```py\nfrom sqlalchemy import any_, all_\n\nselect([mytable]).where(12 == any_(mytable.c.data[5]))\n```", "```py\nfrom sqlalchemy import any_, all_\n\nsubq = select([mytable.c.value])\nselect([mytable]).where(12 > any_(subq))\n```", "```py\nfrom sqlalchemy import func\n\nstmt = select([func.array_agg(table.c.value)])\n```", "```py\nfrom sqlalchemy.dialects.postgresql import aggregate_order_by\n\nexpr = func.array_agg(aggregate_order_by(table.c.a, table.c.b.desc()))\nstmt = select([expr])\n```", "```py\nSELECT  array_agg(table1.a  ORDER  BY  table1.b  DESC)  AS  array_agg_1  FROM  table1\n```", "```py\nfrom sqlalchemy.dialects.postgresql import array_agg\n\nstmt = select([array_agg(table.c.value).contains(\"foo\")])\n```", "```py\nfrom sqlalchemy import func\n\nstmt = select(\n    [\n        department.c.id,\n        func.percentile_cont(0.5).within_group(department.c.salary.desc()),\n    ]\n)\n```", "```py\nSELECT  department.id,  percentile_cont(0.5)\nWITHIN  GROUP  (ORDER  BY  department.salary  DESC)\n```", "```py\n# old way\nclass MyEnum(TypeDecorator, SchemaType):\n    impl = postgresql.ENUM(\"one\", \"two\", \"three\", name=\"myenum\")\n\n    def _set_table(self, table):\n        self.impl._set_table(table)\n```", "```py\n# new way\nclass MyEnum(TypeDecorator):\n    impl = postgresql.ENUM(\"one\", \"two\", \"three\", name=\"myenum\")\n```", "```py\nclass User(Base):\n    __tablename__ = \"user\"\n    id = Column(Integer, primary_key=True)\n\n    __table_args__ = {\"schema\": \"per_user\"}\n```", "```py\nsession = Session()\nsession.connection(\n    execution_options={\"schema_translate_map\": {\"per_user\": \"account_one\"}}\n)\n\n# will query from the ``account_one.user`` table\nsession.query(User).get(5)\n```", "```py\n>>> from sqlalchemy import table, column\nt>>> t = table('x', column('a'), column('b'))\n>>> print(t.insert().returning(t.c.a, t.c.b))\nINSERT  INTO  x  (a,  b)  VALUES  (:a,  :b)  RETURNING  x.a,  x.b \n```", "```py\nclass StringAsInt(TypeDecorator):\n    impl = String\n\n    def column_expression(self, col):\n        return cast(col, Integer)\n\n    def bind_expression(self, value):\n        return cast(value, String)\n```", "```py\nclass Person(Base):\n    __tablename__ = \"person\"\n    id = Column(StringAsInt, primary_key=True)\n\n    pets = relationship(\n        \"Pets\",\n        primaryjoin=(\n            \"foreign(Pets.person_id)==cast(type_coerce(Person.id, Integer), Integer)\"\n        ),\n    )\n\nclass Pets(Base):\n    __tablename__ = \"pets\"\n    id = Column(\"id\", Integer, primary_key=True)\n    person_id = Column(\"person_id\", Integer)\n```", "```py\nSELECT  person.id  AS  person_id,  pets_1.id  AS  pets_1_id,\n  pets_1.person_id  AS  pets_1_person_id\nFROM  person\nLEFT  OUTER  JOIN  pets  AS  pets_1\nON  pets_1.person_id  =  CAST(person.id  AS  INTEGER)\n```", "```py\nSELECT  pets.id  AS  pets_id,  pets.person_id  AS  pets_person_id\nFROM  pets\nWHERE  pets.person_id  =  CAST(CAST(%(param_1)s  AS  VARCHAR)  AS  INTEGER)\n-- {'param_1': 5}\n```", "```py\nSELECT  pets.id  AS  pets_id,  pets.person_id  AS  pets_person_id\nFROM  pets\nWHERE  pets.person_id  =  CAST(%(param_1)s  AS  INTEGER)\n-- {'param_1': 5}\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    json_value = Column(JSON(none_as_null=False), nullable=False)\n```", "```py\nobj = MyObject()  # note no json_value\nsession.add(obj)\nsession.commit()  # will fail with integrity error\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    json_value = Column(JSON(none_as_null=False), nullable=False, default=JSON.NULL)\n```", "```py\nobj = MyObject(json_value=None)\nsession.add(obj)\nsession.commit()  # will insert JSON NULL\n```", "```py\n# default=None is the same as omitting it entirely, does not apply JSON NULL\njson_value = Column(JSON(none_as_null=False), nullable=False, default=None)\n```", "```py\nq = (\n    session.query(User.id, User.name.label(\"name\"))\n    .distinct()\n    .order_by(User.id, User.name, User.fullname)\n)\n```", "```py\nSELECT  DISTINCT  user.id  AS  a_id,  user.name  AS  name,\n  user.fullname  AS  a_fullname\nFROM  a  ORDER  BY  user.id,  user.name,  user.fullname\n```", "```py\nSELECT  DISTINCT  user.id  AS  a_id,  user.name  AS  name,  user.name  AS  a_name,\n  user.fullname  AS  a_fullname\nFROM  a  ORDER  BY  user.id,  user.name,  user.fullname\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\n    data = Column(String)\n\n    @validates(\"data\")\n    def _validate_data_one(self):\n        assert \"x\" in data\n\n    @validates(\"data\")\n    def _validate_data_two(self):\n        assert \"y\" in data\n\nconfigure_mappers()\n```", "```py\nsqlalchemy.exc.InvalidRequestError: A validation function for mapped attribute 'data'\non mapper Mapper|A|a already exists.\n```", "```py\nstmt = text(\"SELECT id, name, description FROM table\")\n\n# no longer matches by name\nstmt = stmt.columns(my_table.c.name, my_table.c.description, my_table.c.id)\n```", "```py\n# correct version\nstmt = stmt.columns(my_table.c.id, my_table.c.name, my_table.c.description)\n```", "```py\nstmt = text(\"SELECT * FROM table\")\nstmt = stmt.columns(my_table.c.id, my_table.c.name, my_table.c.description)\n```", "```py\n>>> from sqlalchemy.schema import MetaData, Table, Column, CreateTable\n>>> from sqlalchemy.types import String\n>>> t = Table(\"t\", MetaData(), Column(\"x\", String(), server_default=\"hi ' there\"))\n>>> print(CreateTable(t))\nCREATE  TABLE  t  (\n  x  VARCHAR  DEFAULT  'hi '' there'\n) \n```", "```py\n(SELECT  x  FROM  table1  ORDER  BY  y  LIMIT  1)  UNION\n(SELECT  x  FROM  table2  ORDER  BY  y  LIMIT  2)\n```", "```py\nstmt1 = select([table1.c.x]).order_by(table1.c.y).limit(1)\nstmt2 = select([table1.c.x]).order_by(table2.c.y).limit(2)\n\nstmt = union(stmt1, stmt2)\n```", "```py\nstmt1 = select([table1.c.x]).order_by(table1.c.y).limit(1).alias().select()\nstmt2 = select([table2.c.x]).order_by(table2.c.y).limit(2).alias().select()\n\nstmt = union(stmt1, stmt2)\n```", "```py\nstmt1 = session.query(Model1).order_by(Model1.y).limit(1).subquery().select()\nstmt2 = session.query(Model2).order_by(Model2.y).limit(1).subquery().select()\n\nstmt = session.query(Model1).from_statement(stmt1.union(stmt2))\n```", "```py\nfrom sqlalchemy.dialects.postgresql import insert\n\ninsert_stmt = insert(my_table).values(id=\"some_id\", data=\"some data to insert\")\n\ndo_update_stmt = insert_stmt.on_conflict_do_update(\n    index_elements=[my_table.c.id], set_=dict(data=\"some data to update\")\n)\n\nconn.execute(do_update_stmt)\n```", "```py\nINSERT  INTO  my_table  (id,  data)\nVALUES  (:id,  :data)\nON  CONFLICT  id  DO  UPDATE  SET  data=:data_2\n```", "```py\n    int_expr = col[5][6][7]  # returns an Integer expression object\n    ```", "```py\n    json_expr = json_col[\"key1\"][\"attr1\"][5]\n    ```", "```py\nexpr = json_col[\"somekey\"].cast(Integer)\n```", "```py\nexpr = json_col[\"somekey\"].astext.cast(Integer)\n```", "```py\nenum = Enum(\n    \"manager\",\n    \"place_admin\",\n    \"carwash_admin\",\n    \"parking_admin\",\n    \"service_admin\",\n    \"tire_admin\",\n    \"mechanic\",\n    \"carwasher\",\n    \"tire_mechanic\",\n    name=\"work_place_roles\",\n)\n\nclass WorkPlacement(Base):\n    __tablename__ = \"work_placement\"\n    id = Column(Integer, primary_key=True)\n    roles = Column(ARRAY(enum))\n\ne = create_engine(\"postgresql://scott:tiger@localhost/test\", echo=True)\nBase.metadata.create_all(e)\n```", "```py\nCREATE  TYPE  work_place_roles  AS  ENUM  (\n  'manager',  'place_admin',  'carwash_admin',  'parking_admin',\n  'service_admin',  'tire_admin',  'mechanic',  'carwasher',\n  'tire_mechanic')\n\nCREATE  TABLE  work_placement  (\n  id  SERIAL  NOT  NULL,\n  roles  work_place_roles[],\n  PRIMARY  KEY  (id)\n)\n```", "```py\nfrom sqlalchemy import inspect\n\ninsp = inspect(engine)\n\nplain_views = insp.get_view_names(include=\"plain\")\nall_views = insp.get_view_names(include=(\"plain\", \"materialized\"))\n```", "```py\n    stmt = select([table]).with_for_update(key_share=True)\n    ```", "```py\n    stmt = select([table]).with_for_update(skip_locked=True)\n    ```", "```py\n    stmt = select([table]).with_for_update(read=True, key_share=True)\n    ```", "```py\nconnection = engine.connect()\nconnection = connection.execution_options(isolation_level=\"AUTOCOMMIT\")\n```", "```py\nt = Table(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True, autoincrement=False),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n    mysql_engine=\"InnoDB\",\n)\n```", "```py\nCREATE  TABLE  some_table  (\n  x  INTEGER  NOT  NULL,\n  y  INTEGER  NOT  NULL  AUTO_INCREMENT,\n  PRIMARY  KEY  (x,  y),\n  KEY  idx_autoinc_y  (y)\n)ENGINE=InnoDB\n```", "```py\nCREATE  TABLE  some_table  (\n  x  INTEGER  NOT  NULL,\n  y  INTEGER  NOT  NULL  AUTO_INCREMENT,\n  PRIMARY  KEY  (y,  x)\n)ENGINE=InnoDB\n```", "```py\nt = Table(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n    PrimaryKeyConstraint(\"x\", \"y\"),\n    UniqueConstraint(\"y\"),\n    mysql_engine=\"InnoDB\",\n)\n```", "```py\nt = Table(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n    mysql_engine=\"InnoDB\",\n)\n```", "```py\nengine = create_engine(\n    \"mssql+pyodbc://scott:tiger@ms_2008\", isolation_level=\"REPEATABLE READ\"\n)\n```", "```py\n>>> from sqlalchemy import create_engine, inspect\n>>> engine = create_engine(\"mssql+pyodbc://scott:tiger@ms_2008\", echo=True)\n>>> engine.execute(\"create table s (x varchar(max), y varbinary(max))\")\n>>> insp = inspect(engine)\n>>> for col in insp.get_columns(\"s\"):\n...     print(col[\"type\"].__class__, col[\"type\"].length)\n<class 'sqlalchemy.sql.sqltypes.VARCHAR'> max\n<class 'sqlalchemy.dialects.mssql.base.VARBINARY'> max\n```", "```py\n>>> for col in insp.get_columns(\"s\"):\n...     print(col[\"type\"].__class__, col[\"type\"].length)\n<class 'sqlalchemy.sql.sqltypes.VARCHAR'> None\n<class 'sqlalchemy.dialects.mssql.base.VARBINARY'> None\n```", "```py\naccount_table = Table(\n    \"account\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"info\", String(100)),\n    schema=\"customer_schema\",\n)\n```", "```py\n>>> eng = create_engine(\"mssql+pymssql://mydsn\", legacy_schema_aliasing=True)\n>>> print(account_table.select().compile(eng))\nSELECT  account_1.id,  account_1.info\nFROM  customer_schema.account  AS  account_1 \n```", "```py\n>>> obj = MyObj()\n>>> obj.some_value\nNone\n```", "```py\n>>> obj = MyObj()\n>>> obj.some_value\n\"my default\"\n```", "```py\nresult = (\n    session.query(func.substr(A.some_thing, 0, 4), A).options(joinedload(A.bs)).all()\n)\n\nusers = (\n    session.query(\n        func.date(User.date_created, \"start of month\").label(\"month\"),\n        User,\n    )\n    .options(joinedload(User.orders))\n    .all()\n)\n```", "```py\nresult = (\n    session.query(func.substr(A.some_thing, 0, 4, type_=String), A)\n    .options(joinedload(A.bs))\n    .all()\n)\n\nusers = (\n    session.query(\n        func.date(User.date_created, \"start of month\", type_=DateTime).label(\"month\"),\n        User,\n    )\n    .options(joinedload(User.orders))\n    .all()\n)\n```", "```py\n>>> some_user = User()\n>>> q = s.query(User).filter(User.name == some_user)\nsqlalchemy.exc.ArgumentError: Object <__main__.User object at 0x103167e90> is not legal as a SQL literal value\n```", "```py\n>>> # Address.user refers to the User mapper, so\n>>> # this is of course still OK!\n>>> q = s.query(Address).filter(Address.user == some_user)\n```", "```py\nclass Person(Base):\n    __tablename__ = \"person\"\n\n    id = Column(Integer, primary_key=True)\n    data = Column(JSON)\n\n    name = index_property(\"data\", \"name\")\n```", "```py\n>>> person = Person(name=\"foobar\")\n>>> person.name\nfoobar\n```", "```py\nclass Widget(Base):\n    __tablename__ = \"widget\"\n    id = Column(Integer, primary_key=True)\n    type = Column(String)\n    data = Column(String)\n    __mapper_args__ = {\"polymorphic_on\": type}\n\nclass FooWidget(Widget):\n    __mapper_args__ = {\"polymorphic_identity\": \"foo\"}\n\nq = session.query(FooWidget).filter(FooWidget.data == \"bar\").exists()\n\nsession.query(q).all()\n```", "```py\nSELECT  EXISTS  (SELECT  1\nFROM  widget\nWHERE  widget.data  =  :data_1  AND  widget.type  IN  (:type_1))  AS  anon_1\n```", "```py\ns = Session()\ns.begin_nested()\n\ns.add(SomeObject())\n\ntry:\n    # assume the flush fails, flush goes to rollback to the\n    # savepoint and that also fails\n    s.flush()\nexcept Exception as err:\n    print(\"Something broke, and our SAVEPOINT vanished too\")\n\n# this is the SAVEPOINT transaction, marked as\n# DEACTIVE so the rollback() call succeeds\ns.rollback()\n\n# this is the outermost transaction, remains ACTIVE\n# so rollback() or commit() can succeed\ns.rollback()\n```", "```py\nfrom sqlalchemy import Column, create_engine\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\ne = create_engine(\"sqlite://\", echo=True)\nBase.metadata.create_all(e)\n\ns = Session(e)\n\n# persist an object\ns.add(A(id=1))\ns.flush()\n\n# rollback buffer loses reference to A\n\n# load it again, rollback buffer knows nothing\n# about it\na1 = s.query(A).first()\n\n# roll back the transaction; all state is expired but the\n# \"a1\" reference remains\ns.rollback()\n\n# previous \"a1\" conflicts with the new one because we aren't\n# checking that it never got committed\ns.add(A(id=1))\ns.commit()\n```", "```py\nFlushError: New instance <User at 0x7f0287eca4d0> with identity key\n(<class 'test.orm.test_transaction.User'>, ('u1',)) conflicts\nwith persistent instance <User at 0x7f02889c70d0>\n```", "```py\nBEGIN  (implicit)\n\nINSERT  INTO  a  (id)  VALUES  (?)\n(1,)\n\nSELECT  a.id  AS  a_id  FROM  a  LIMIT  ?  OFFSET  ?\n(1,  0)\n\nROLLBACK\n\nBEGIN  (implicit)\n\nSELECT  a.id  AS  a_id  FROM  a  WHERE  a.id  =  ?\n(1,)\n\nINSERT  INTO  a  (id)  VALUES  (?)\n(1,)\n\nCOMMIT\n```", "```py\nfrom sqlalchemy import Column, Integer, String, ForeignKey, create_engine\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(\"id\", Integer, primary_key=True)\n    type = Column(String)\n\n    __mapper_args__ = {\n        \"polymorphic_on\": type,\n        \"polymorphic_identity\": \"a\",\n        \"passive_deletes\": True,\n    }\n\nclass B(A):\n    __tablename__ = \"b\"\n    b_table_id = Column(\"b_table_id\", Integer, primary_key=True)\n    bid = Column(\"bid\", Integer, ForeignKey(\"a.id\", ondelete=\"CASCADE\"))\n    data = Column(\"data\", String)\n\n    __mapper_args__ = {\"polymorphic_identity\": \"b\"}\n```", "```py\nsession.delete(some_b)\nsession.commit()\n```", "```py\nDELETE  FROM  a  WHERE  a.id  =  %(id)s\n-- {'id': 1}\nCOMMIT\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n    b = relationship(\"B\", foreign_keys=\"B.a_id\", backref=\"a\")\n\nclass A1(A):\n    __tablename__ = \"a1\"\n    id = Column(Integer, primary_key=True)\n    b = relationship(\"B\", foreign_keys=\"B.a1_id\", backref=\"a1\")\n    __mapper_args__ = {\"concrete\": True}\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n\n    a_id = Column(ForeignKey(\"a.id\"))\n    a1_id = Column(ForeignKey(\"a1.id\"))\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\nclass A1(A):\n    __tablename__ = \"a1\"\n    id = Column(Integer, primary_key=True)\n    __mapper_args__ = {\"concrete\": True}\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n\n    a_id = Column(ForeignKey(\"a.id\"))\n    a1_id = Column(ForeignKey(\"a1.id\"))\n\n    a = relationship(\"A\", backref=\"b\")\n    a1 = relationship(\"A1\", backref=\"b\")\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n    bs = relationship(\"B\")\n\nclass ASub(A):\n    __tablename__ = \"a_sub\"\n    id = Column(Integer, ForeignKey(\"a.id\"), primary_key=True)\n    bs = relationship(\"B\")\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n    a_id = Column(ForeignKey(\"a.id\"))\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\n    name = Column(String)\n\n    @hybrid_property\n    def some_name(self):\n  \"\"\"The name field\"\"\"\n        return self.name\n```", "```py\n>>> A.some_name.__doc__\nThe name field\n```", "```py\n>>> assert A.name is A.some_name\n```", "```py\n>>> A.some_name\n<sqlalchemy.orm.attributes.hybrid_propertyProxy object at 0x7fde03888230>\n```", "```py\n>>> A.some_name.info[\"foo\"] = \"bar\"\n>>> from sqlalchemy import inspect\n>>> inspect(A).all_orm_descriptors[\"some_name\"].info\n{'foo': 'bar'}\n```", "```py\nu1 = User(id=7, name=\"x\")\nu1.orders = [\n    Order(description=\"o1\", address=Address(id=1, email_address=\"a\")),\n    Order(description=\"o2\", address=Address(id=1, email_address=\"b\")),\n    Order(description=\"o3\", address=Address(id=1, email_address=\"c\")),\n]\n\nsess = Session()\nsess.merge(u1)\n```", "```py\nsome_object = SomeClass()\nsession.add(some_object)\nsome_object.parent_id = some_parent.id\nsome_object.parent = some_parent\n```", "```py\n# before the fix\nassert some_object not in some_parent.items\n```", "```py\n# after the fix, backref fired off for some_object.parent = some_parent\nassert some_object in some_parent.items\n```", "```py\nsess.query(Person.name).filter(\n    sess.query(Company.name)\n    .filter(Company.company_id == Person.company_id)\n    .correlate(Person)\n    .as_scalar()\n    == \"Elbonia, Inc.\"\n)\n```", "```py\nSELECT  people.name  AS  people_name\nFROM  people\nLEFT  OUTER  JOIN  engineers  ON  people.person_id  =  engineers.person_id\nLEFT  OUTER  JOIN  managers  ON  people.person_id  =  managers.person_id\nWHERE  (SELECT  companies.name\nFROM  companies\nWHERE  companies.company_id  =  people.company_id)  =  ?\n```", "```py\n-- old, incorrect query\nSELECT  people.name  AS  people_name\nFROM  people\nLEFT  OUTER  JOIN  engineers  ON  people.person_id  =  engineers.person_id\nLEFT  OUTER  JOIN  managers  ON  people.person_id  =  managers.person_id\nWHERE  (SELECT  companies.name\nFROM  companies,  people\nWHERE  companies.company_id  =  people.company_id)  =  ?\n```", "```py\n# works with all SQLAlchemy versions and all types of polymorphic\n# aliasing.\n\npaliased = aliased(Person)\nsess.query(paliased.name).filter(\n    sess.query(Company.name)\n    .filter(Company.company_id == paliased.company_id)\n    .correlate(paliased)\n    .as_scalar()\n    == \"Elbonia, Inc.\"\n)\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n    b_id = Column(ForeignKey(\"b.id\"))\n    c_id = Column(ForeignKey(\"c.id\"))\n\n    b = relationship(\"B\")\n    c = relationship(\"C\")\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n    c_id = Column(ForeignKey(\"c.id\"))\n\n    c = relationship(\"C\")\n\nclass C(Base):\n    __tablename__ = \"c\"\n    id = Column(Integer, primary_key=True)\n    d_id = Column(ForeignKey(\"d.id\"))\n    d = relationship(\"D\")\n\nclass D(Base):\n    __tablename__ = \"d\"\n    id = Column(Integer, primary_key=True)\n\nc_alias_1 = aliased(C)\nc_alias_2 = aliased(C)\n\nq = s.query(A)\nq = q.join(A.b).join(c_alias_1, B.c).join(c_alias_1.d)\nq = q.options(\n    contains_eager(A.b).contains_eager(B.c, alias=c_alias_1).contains_eager(C.d)\n)\nq = q.join(c_alias_2, A.c)\nq = q.options(contains_eager(A.c, alias=c_alias_2))\n```", "```py\nSELECT\n  d.id  AS  d_id,\n  c_1.id  AS  c_1_id,  c_1.d_id  AS  c_1_d_id,\n  b.id  AS  b_id,  b.c_id  AS  b_c_id,\n  c_2.id  AS  c_2_id,  c_2.d_id  AS  c_2_d_id,\n  a.id  AS  a_id,  a.b_id  AS  a_b_id,  a.c_id  AS  a_c_id\nFROM\n  a\n  JOIN  b  ON  b.id  =  a.b_id\n  JOIN  c  AS  c_1  ON  c_1.id  =  b.c_id\n  JOIN  d  ON  d.id  =  c_1.d_id\n  JOIN  c  AS  c_2  ON  c_2.id  =  a.c_id\n```", "```py\n>>> from sqlalchemy.orm import raiseload\n>>> a1 = s.query(A).options(raiseload(A.some_b)).first()\n>>> a1.some_b\nTraceback (most recent call last):\n...\nsqlalchemy.exc.InvalidRequestError: 'A.some_b' is not available due to lazy='raise'\n```", "```py\n>>> from sqlalchemy.orm import raiseload\n>>> a1 = s.query(A).options(raiseload(A.some_b, sql_only=True)).first()\n>>> a1.some_b\nTraceback (most recent call last):\n...\nsqlalchemy.exc.InvalidRequestError: 'A.bs' is not available due to lazy='raise_on_sql'\n```", "```py\n>>> obj = MyObj()\n>>> obj.some_value\nNone\n```", "```py\n>>> obj = MyObj()\n>>> obj.some_value\n\"my default\"\n```", "```py\nresult = (\n    session.query(func.substr(A.some_thing, 0, 4), A).options(joinedload(A.bs)).all()\n)\n\nusers = (\n    session.query(\n        func.date(User.date_created, \"start of month\").label(\"month\"),\n        User,\n    )\n    .options(joinedload(User.orders))\n    .all()\n)\n```", "```py\nresult = (\n    session.query(func.substr(A.some_thing, 0, 4, type_=String), A)\n    .options(joinedload(A.bs))\n    .all()\n)\n\nusers = (\n    session.query(\n        func.date(User.date_created, \"start of month\", type_=DateTime).label(\"month\"),\n        User,\n    )\n    .options(joinedload(User.orders))\n    .all()\n)\n```", "```py\n>>> some_user = User()\n>>> q = s.query(User).filter(User.name == some_user)\nsqlalchemy.exc.ArgumentError: Object <__main__.User object at 0x103167e90> is not legal as a SQL literal value\n```", "```py\n>>> # Address.user refers to the User mapper, so\n>>> # this is of course still OK!\n>>> q = s.query(Address).filter(Address.user == some_user)\n```", "```py\nclass Person(Base):\n    __tablename__ = \"person\"\n\n    id = Column(Integer, primary_key=True)\n    data = Column(JSON)\n\n    name = index_property(\"data\", \"name\")\n```", "```py\n>>> person = Person(name=\"foobar\")\n>>> person.name\nfoobar\n```", "```py\nclass Widget(Base):\n    __tablename__ = \"widget\"\n    id = Column(Integer, primary_key=True)\n    type = Column(String)\n    data = Column(String)\n    __mapper_args__ = {\"polymorphic_on\": type}\n\nclass FooWidget(Widget):\n    __mapper_args__ = {\"polymorphic_identity\": \"foo\"}\n\nq = session.query(FooWidget).filter(FooWidget.data == \"bar\").exists()\n\nsession.query(q).all()\n```", "```py\nSELECT  EXISTS  (SELECT  1\nFROM  widget\nWHERE  widget.data  =  :data_1  AND  widget.type  IN  (:type_1))  AS  anon_1\n```", "```py\ns = Session()\ns.begin_nested()\n\ns.add(SomeObject())\n\ntry:\n    # assume the flush fails, flush goes to rollback to the\n    # savepoint and that also fails\n    s.flush()\nexcept Exception as err:\n    print(\"Something broke, and our SAVEPOINT vanished too\")\n\n# this is the SAVEPOINT transaction, marked as\n# DEACTIVE so the rollback() call succeeds\ns.rollback()\n\n# this is the outermost transaction, remains ACTIVE\n# so rollback() or commit() can succeed\ns.rollback()\n```", "```py\nfrom sqlalchemy import Column, create_engine\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\ne = create_engine(\"sqlite://\", echo=True)\nBase.metadata.create_all(e)\n\ns = Session(e)\n\n# persist an object\ns.add(A(id=1))\ns.flush()\n\n# rollback buffer loses reference to A\n\n# load it again, rollback buffer knows nothing\n# about it\na1 = s.query(A).first()\n\n# roll back the transaction; all state is expired but the\n# \"a1\" reference remains\ns.rollback()\n\n# previous \"a1\" conflicts with the new one because we aren't\n# checking that it never got committed\ns.add(A(id=1))\ns.commit()\n```", "```py\nFlushError: New instance <User at 0x7f0287eca4d0> with identity key\n(<class 'test.orm.test_transaction.User'>, ('u1',)) conflicts\nwith persistent instance <User at 0x7f02889c70d0>\n```", "```py\nBEGIN  (implicit)\n\nINSERT  INTO  a  (id)  VALUES  (?)\n(1,)\n\nSELECT  a.id  AS  a_id  FROM  a  LIMIT  ?  OFFSET  ?\n(1,  0)\n\nROLLBACK\n\nBEGIN  (implicit)\n\nSELECT  a.id  AS  a_id  FROM  a  WHERE  a.id  =  ?\n(1,)\n\nINSERT  INTO  a  (id)  VALUES  (?)\n(1,)\n\nCOMMIT\n```", "```py\nfrom sqlalchemy import Column, Integer, String, ForeignKey, create_engine\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(\"id\", Integer, primary_key=True)\n    type = Column(String)\n\n    __mapper_args__ = {\n        \"polymorphic_on\": type,\n        \"polymorphic_identity\": \"a\",\n        \"passive_deletes\": True,\n    }\n\nclass B(A):\n    __tablename__ = \"b\"\n    b_table_id = Column(\"b_table_id\", Integer, primary_key=True)\n    bid = Column(\"bid\", Integer, ForeignKey(\"a.id\", ondelete=\"CASCADE\"))\n    data = Column(\"data\", String)\n\n    __mapper_args__ = {\"polymorphic_identity\": \"b\"}\n```", "```py\nsession.delete(some_b)\nsession.commit()\n```", "```py\nDELETE  FROM  a  WHERE  a.id  =  %(id)s\n-- {'id': 1}\nCOMMIT\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n    b = relationship(\"B\", foreign_keys=\"B.a_id\", backref=\"a\")\n\nclass A1(A):\n    __tablename__ = \"a1\"\n    id = Column(Integer, primary_key=True)\n    b = relationship(\"B\", foreign_keys=\"B.a1_id\", backref=\"a1\")\n    __mapper_args__ = {\"concrete\": True}\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n\n    a_id = Column(ForeignKey(\"a.id\"))\n    a1_id = Column(ForeignKey(\"a1.id\"))\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\nclass A1(A):\n    __tablename__ = \"a1\"\n    id = Column(Integer, primary_key=True)\n    __mapper_args__ = {\"concrete\": True}\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n\n    a_id = Column(ForeignKey(\"a.id\"))\n    a1_id = Column(ForeignKey(\"a1.id\"))\n\n    a = relationship(\"A\", backref=\"b\")\n    a1 = relationship(\"A1\", backref=\"b\")\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n    bs = relationship(\"B\")\n\nclass ASub(A):\n    __tablename__ = \"a_sub\"\n    id = Column(Integer, ForeignKey(\"a.id\"), primary_key=True)\n    bs = relationship(\"B\")\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n    a_id = Column(ForeignKey(\"a.id\"))\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\n    name = Column(String)\n\n    @hybrid_property\n    def some_name(self):\n  \"\"\"The name field\"\"\"\n        return self.name\n```", "```py\n>>> A.some_name.__doc__\nThe name field\n```", "```py\n>>> assert A.name is A.some_name\n```", "```py\n>>> A.some_name\n<sqlalchemy.orm.attributes.hybrid_propertyProxy object at 0x7fde03888230>\n```", "```py\n>>> A.some_name.info[\"foo\"] = \"bar\"\n>>> from sqlalchemy import inspect\n>>> inspect(A).all_orm_descriptors[\"some_name\"].info\n{'foo': 'bar'}\n```", "```py\nu1 = User(id=7, name=\"x\")\nu1.orders = [\n    Order(description=\"o1\", address=Address(id=1, email_address=\"a\")),\n    Order(description=\"o2\", address=Address(id=1, email_address=\"b\")),\n    Order(description=\"o3\", address=Address(id=1, email_address=\"c\")),\n]\n\nsess = Session()\nsess.merge(u1)\n```", "```py\nsome_object = SomeClass()\nsession.add(some_object)\nsome_object.parent_id = some_parent.id\nsome_object.parent = some_parent\n```", "```py\n# before the fix\nassert some_object not in some_parent.items\n```", "```py\n# after the fix, backref fired off for some_object.parent = some_parent\nassert some_object in some_parent.items\n```", "```py\nsess.query(Person.name).filter(\n    sess.query(Company.name)\n    .filter(Company.company_id == Person.company_id)\n    .correlate(Person)\n    .as_scalar()\n    == \"Elbonia, Inc.\"\n)\n```", "```py\nSELECT  people.name  AS  people_name\nFROM  people\nLEFT  OUTER  JOIN  engineers  ON  people.person_id  =  engineers.person_id\nLEFT  OUTER  JOIN  managers  ON  people.person_id  =  managers.person_id\nWHERE  (SELECT  companies.name\nFROM  companies\nWHERE  companies.company_id  =  people.company_id)  =  ?\n```", "```py\n-- old, incorrect query\nSELECT  people.name  AS  people_name\nFROM  people\nLEFT  OUTER  JOIN  engineers  ON  people.person_id  =  engineers.person_id\nLEFT  OUTER  JOIN  managers  ON  people.person_id  =  managers.person_id\nWHERE  (SELECT  companies.name\nFROM  companies,  people\nWHERE  companies.company_id  =  people.company_id)  =  ?\n```", "```py\n# works with all SQLAlchemy versions and all types of polymorphic\n# aliasing.\n\npaliased = aliased(Person)\nsess.query(paliased.name).filter(\n    sess.query(Company.name)\n    .filter(Company.company_id == paliased.company_id)\n    .correlate(paliased)\n    .as_scalar()\n    == \"Elbonia, Inc.\"\n)\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n    b_id = Column(ForeignKey(\"b.id\"))\n    c_id = Column(ForeignKey(\"c.id\"))\n\n    b = relationship(\"B\")\n    c = relationship(\"C\")\n\nclass B(Base):\n    __tablename__ = \"b\"\n    id = Column(Integer, primary_key=True)\n    c_id = Column(ForeignKey(\"c.id\"))\n\n    c = relationship(\"C\")\n\nclass C(Base):\n    __tablename__ = \"c\"\n    id = Column(Integer, primary_key=True)\n    d_id = Column(ForeignKey(\"d.id\"))\n    d = relationship(\"D\")\n\nclass D(Base):\n    __tablename__ = \"d\"\n    id = Column(Integer, primary_key=True)\n\nc_alias_1 = aliased(C)\nc_alias_2 = aliased(C)\n\nq = s.query(A)\nq = q.join(A.b).join(c_alias_1, B.c).join(c_alias_1.d)\nq = q.options(\n    contains_eager(A.b).contains_eager(B.c, alias=c_alias_1).contains_eager(C.d)\n)\nq = q.join(c_alias_2, A.c)\nq = q.options(contains_eager(A.c, alias=c_alias_2))\n```", "```py\nSELECT\n  d.id  AS  d_id,\n  c_1.id  AS  c_1_id,  c_1.d_id  AS  c_1_d_id,\n  b.id  AS  b_id,  b.c_id  AS  b_c_id,\n  c_2.id  AS  c_2_id,  c_2.d_id  AS  c_2_d_id,\n  a.id  AS  a_id,  a.b_id  AS  a_b_id,  a.c_id  AS  a_c_id\nFROM\n  a\n  JOIN  b  ON  b.id  =  a.b_id\n  JOIN  c  AS  c_1  ON  c_1.id  =  b.c_id\n  JOIN  d  ON  d.id  =  c_1.d_id\n  JOIN  c  AS  c_2  ON  c_2.id  =  a.c_id\n```", "```py\n>>> from sqlalchemy.orm import raiseload\n>>> a1 = s.query(A).options(raiseload(A.some_b)).first()\n>>> a1.some_b\nTraceback (most recent call last):\n...\nsqlalchemy.exc.InvalidRequestError: 'A.some_b' is not available due to lazy='raise'\n```", "```py\n>>> from sqlalchemy.orm import raiseload\n>>> a1 = s.query(A).options(raiseload(A.some_b, sql_only=True)).first()\n>>> a1.some_b\nTraceback (most recent call last):\n...\nsqlalchemy.exc.InvalidRequestError: 'A.bs' is not available due to lazy='raise_on_sql'\n```", "```py\nengine = create_engine(\"postgresql+psycopg2://\")\n\n@event.listens_for(engine, \"handle_error\")\ndef cancel_disconnect(ctx):\n    if isinstance(ctx.original_exception, KeyboardInterrupt):\n        ctx.is_disconnect = False\n```", "```py\n>>> from sqlalchemy import table, column, select, literal, exists\n>>> orders = table(\n...     \"orders\",\n...     column(\"region\"),\n...     column(\"amount\"),\n...     column(\"product\"),\n...     column(\"quantity\"),\n... )\n>>>\n>>> upsert = (\n...     orders.update()\n...     .where(orders.c.region == \"Region1\")\n...     .values(amount=1.0, product=\"Product1\", quantity=1)\n...     .returning(*(orders.c._all_columns))\n...     .cte(\"upsert\")\n... )\n>>>\n>>> insert = orders.insert().from_select(\n...     orders.c.keys(),\n...     select([literal(\"Region1\"), literal(1.0), literal(\"Product1\"), literal(1)]).where(\n...         ~exists(upsert.select())\n...     ),\n... )\n>>>\n>>> print(insert)  # Note: formatting added for clarity\nWITH  upsert  AS\n(UPDATE  orders  SET  amount=:amount,  product=:product,  quantity=:quantity\n  WHERE  orders.region  =  :region_1\n  RETURNING  orders.region,  orders.amount,  orders.product,  orders.quantity\n)\nINSERT  INTO  orders  (region,  amount,  product,  quantity)\nSELECT\n  :param_1  AS  anon_1,  :param_2  AS  anon_2,\n  :param_3  AS  anon_3,  :param_4  AS  anon_4\nWHERE  NOT  (\n  EXISTS  (\n  SELECT  upsert.region,  upsert.amount,\n  upsert.product,  upsert.quantity\n  FROM  upsert)) \n```", "```py\n>>> from sqlalchemy import func\n\n>>> print(func.row_number().over(order_by=\"x\", range_=(-5, 10)))\nrow_number()  OVER  (ORDER  BY  x  RANGE  BETWEEN  :param_1  PRECEDING  AND  :param_2  FOLLOWING)\n>>> print(func.row_number().over(order_by=\"x\", rows=(None, 0)))\nrow_number()  OVER  (ORDER  BY  x  ROWS  BETWEEN  UNBOUNDED  PRECEDING  AND  CURRENT  ROW)\n>>> print(func.row_number().over(order_by=\"x\", range_=(-2, None)))\nrow_number()  OVER  (ORDER  BY  x  RANGE  BETWEEN  :param_1  PRECEDING  AND  UNBOUNDED  FOLLOWING) \n```", "```py\n>>> from sqlalchemy import table, column, select, true\n>>> people = table(\"people\", column(\"people_id\"), column(\"age\"), column(\"name\"))\n>>> books = table(\"books\", column(\"book_id\"), column(\"owner_id\"))\n>>> subq = (\n...     select([books.c.book_id])\n...     .where(books.c.owner_id == people.c.people_id)\n...     .lateral(\"book_subq\")\n... )\n>>> print(select([people]).select_from(people.join(subq, true())))\nSELECT  people.people_id,  people.age,  people.name\nFROM  people  JOIN  LATERAL  (SELECT  books.book_id  AS  book_id\nFROM  books  WHERE  books.owner_id  =  people.people_id)\nAS  book_subq  ON  true \n```", "```py\nfrom sqlalchemy import func\n\nselectable = people.tablesample(func.bernoulli(1), name=\"alias\", seed=func.random())\nstmt = select([selectable.c.people_id])\n```", "```py\nSELECT  alias.people_id  FROM\npeople  AS  alias  TABLESAMPLE  bernoulli(:bernoulli_1)\nREPEATABLE  (random())\n```", "```py\nTable(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True),\n)\n```", "```py\n# old way\nTable(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True, autoincrement=False),\n    Column(\"y\", Integer, primary_key=True, autoincrement=False),\n)\n```", "```py\n# column 'y' will be SERIAL/AUTO_INCREMENT/ auto-generating\nTable(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n)\n```", "```py\nTable(\n    \"b\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True),\n)\n```", "```py\nSAWarning: Column 'b.x' is marked as a member of the primary\nkey for table 'b', but has no Python-side or server-side default\ngenerator indicated, nor does it indicate 'autoincrement=True',\nand no explicit value is passed.  Primary key columns may not\nstore NULL. Note that as of SQLAlchemy 1.1, 'autoincrement=True'\nmust be indicated explicitly for composite (e.g. multicolumn)\nprimary keys if AUTO_INCREMENT/SERIAL/IDENTITY behavior is\nexpected for one of the columns in the primary key. CREATE TABLE\nstatements are impacted by this change as well on most backends.\n```", "```py\nTable(\n    \"b\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True, server_default=FetchedValue()),\n    Column(\"y\", Integer, primary_key=True, server_default=FetchedValue()),\n)\n```", "```py\nTable(\n    \"b\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, nullable=True),\n)\n```", "```py\n>>> print(column(\"x\").is_distinct_from(None))\nx  IS  DISTINCT  FROM  NULL \n```", "```py\n>>> print(column(\"x\").isnot_distinct_from(False))\nx  IS  NOT  DISTINCT  FROM  false \n```", "```py\n>>> from sqlalchemy.dialects import sqlite\n>>> print(column(\"x\").is_distinct_from(None).compile(dialect=sqlite.dialect()))\nx  IS  NOT  NULL \n```", "```py\nstmt = select([t1]).select_from(t1.outerjoin(t2, full=True))\n```", "```py\nq = session.query(MyClass).outerjoin(MyOtherClass, full=True)\n```", "```py\nfrom sqlalchemy import text\n\nstmt = text(\n    \"SELECT users.id, addresses.id, users.id, \"\n    \"users.name, addresses.email_address AS email \"\n    \"FROM users JOIN addresses ON users.id=addresses.user_id \"\n    \"WHERE users.id = 1\"\n).columns(User.id, Address.id, Address.user_id, User.name, Address.email_address)\n\nquery = session.query(User).from_statement(stmt).options(contains_eager(User.addresses))\nresult = query.all()\n```", "```py\nua = users.alias(\"ua\")\nstmt = select([users.c.user_id, ua.c.user_id])\n```", "```py\nSELECT  users.user_id,  ua.user_id  FROM  users,  users  AS  ua\n```", "```py\nresult = conn.execute(stmt)\nrow = result.first()\n\n# these both match positionally, so no error\nuser_id = row[users.c.user_id]\nua_id = row[ua.c.user_id]\n\n# this still raises, however\nuser_id = row[\"user_id\"]\n```", "```py\nimport enum\nfrom sqlalchemy import Table, MetaData, Column, Enum, create_engine\n\nclass MyEnum(enum.Enum):\n    one = 1\n    two = 2\n    three = 3\n\nt = Table(\"data\", MetaData(), Column(\"value\", Enum(MyEnum)))\n\ne = create_engine(\"sqlite://\")\nt.create(e)\n\ne.execute(t.insert(), {\"value\": MyEnum.two})\nassert e.scalar(t.select()) is MyEnum.two\n```", "```py\n>>> from sqlalchemy import create_engine\n>>> e = create_engine(\"sqlite://\")\n>>> row = e.execute(\"select 1, 2, 3\").first()\n>>> row[-1], row[-2], row[1], row[-2:2]\n3 2 2 (2,)\n```", "```py\n>>> from sqlalchemy import Table, MetaData, Column, Enum, create_engine\n>>> t = Table(\n...     \"data\",\n...     MetaData(),\n...     Column(\"value\", Enum(\"one\", \"two\", \"three\", validate_strings=True)),\n... )\n>>> e = create_engine(\"sqlite://\")\n>>> t.create(e)\n>>> e.execute(t.insert(), {\"value\": \"four\"})\nTraceback (most recent call last):\n  ...\nsqlalchemy.exc.StatementError: (exceptions.LookupError)\n\"four\" is not among the defined enum values\n[SQL: u'INSERT INTO data (value) VALUES (?)']\n[parameters: [{'value': 'four'}]]\n```", "```py\n>>> from sqlalchemy import create_engine\n>>> import random\n>>> e = create_engine(\"sqlite://\", echo=\"debug\")\n>>> some_value = \"\".join(chr(random.randint(52, 85)) for i in range(5000))\n>>> row = e.execute(\"select ?\", [some_value]).first()\n... # (lines are wrapped for clarity) ...\n2016-02-17 13:23:03,027 INFO sqlalchemy.engine.base.Engine select ?\n2016-02-17 13:23:03,027 INFO sqlalchemy.engine.base.Engine\n('E6@?>9HPOJB<<BHR:@=TS:5ILU=;JLM<4?B9<S48PTNG9>:=TSTLA;9K;9FPM4M8M@;NM6GU\nLUAEBT9QGHNHTHR5EP75@OER4?SKC;D:TFUMD:M>;C6U:JLM6R67GEK<A6@S@C@J7>4=4:P\nGJ7HQ6 ... (4702 characters truncated) ... J6IK546AJMB4N6S9L;;9AKI;=RJP\nHDSSOTNBUEEC9@Q:RCL:I@5?FO<9K>KJAGAO@E6@A7JI8O:J7B69T6<8;F:S;4BEIJS9HM\nK:;5OLPM@JR;R:J6<SOTTT=>Q>7T@I::OTDC:CC<=NGP6C>BC8N',)\n2016-02-17 13:23:03,027 DEBUG sqlalchemy.engine.base.Engine Col ('?',)\n2016-02-17 13:23:03,027 DEBUG sqlalchemy.engine.base.Engine\nRow (u'E6@?>9HPOJB<<BHR:@=TS:5ILU=;JLM<4?B9<S48PTNG9>:=TSTLA;9K;9FPM4M8M@;\nNM6GULUAEBT9QGHNHTHR5EP75@OER4?SKC;D:TFUMD:M>;C6U:JLM6R67GEK<A6@S@C@J7\n>4=4:PGJ7HQ ... (4703 characters truncated) ... J6IK546AJMB4N6S9L;;9AKI;=\nRJPHDSSOTNBUEEC9@Q:RCL:I@5?FO<9K>KJAGAO@E6@A7JI8O:J7B69T6<8;F:S;4BEIJS9HM\nK:;5OLPM@JR;R:J6<SOTTT=>Q>7T@I::OTDC:CC<=NGP6C>BC8N',)\n>>> print(row)\n(u'E6@?>9HPOJB<<BHR:@=TS:5ILU=;JLM<4?B9<S48PTNG9>:=TSTLA;9K;9FPM4M8M@;NM6\nGULUAEBT9QGHNHTHR5EP75@OER4?SKC;D:TFUMD:M>;C6U:JLM6R67GEK<A6@S@C@J7>4\n=4:PGJ7HQ ... (4703 characters truncated) ... J6IK546AJMB4N6S9L;;9AKI;\n=RJPHDSSOTNBUEEC9@Q:RCL:I@5?FO<9K>KJAGAO@E6@A7JI8O:J7B69T6<8;F:S;4BEIJS9H\nMK:;5OLPM@JR;R:J6<SOTTT=>Q>7T@I::OTDC:CC<=NGP6C>BC8N',)\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    json_value = Column(JSON(none_as_null=False), default=\"some default\")\n\n# would insert \"some default\" instead of \"'null'\",\n# now will insert \"'null'\"\nobj = MyObject(json_value=None)\nsession.add(obj)\nsession.commit()\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    some_other_value = Column(String(50))\n    json_value = Column(JSON(none_as_null=False))\n\n# would result in NULL for some_other_value,\n# but json \"'null'\" for json_value.  Now results in NULL for both\n# (the json_value is omitted from the INSERT)\nobj = MyObject()\nsession.add(obj)\nsession.commit()\n```", "```py\n# would insert SQL NULL and/or trigger defaults,\n# now inserts \"'null'\"\nsession.bulk_insert_mappings(MyObject, [{\"json_value\": None}])\n```", "```py\nfrom sqlalchemy import null\nfrom sqlalchemy.dialects.postgresql import JSON\n\nobj1 = MyObject(json_value=null())  # will *always* insert SQL NULL\nobj2 = MyObject(json_value=JSON.NULL)  # will *always* insert JSON string \"null\"\n\nsession.add_all([obj1, obj2])\nsession.commit()\n```", "```py\nmytable = Table(\"mytable\", metadata, Column(\"data\", ARRAY(Integer, dimensions=2)))\n\nexpr = mytable.c.data[5][6]\n\nexpr = mytable.c.data[5].any(12)\n```", "```py\nfrom sqlalchemy import any_, all_\n\nselect([mytable]).where(12 == any_(mytable.c.data[5]))\n```", "```py\nfrom sqlalchemy import any_, all_\n\nsubq = select([mytable.c.value])\nselect([mytable]).where(12 > any_(subq))\n```", "```py\nfrom sqlalchemy import func\n\nstmt = select([func.array_agg(table.c.value)])\n```", "```py\nfrom sqlalchemy.dialects.postgresql import aggregate_order_by\n\nexpr = func.array_agg(aggregate_order_by(table.c.a, table.c.b.desc()))\nstmt = select([expr])\n```", "```py\nSELECT  array_agg(table1.a  ORDER  BY  table1.b  DESC)  AS  array_agg_1  FROM  table1\n```", "```py\nfrom sqlalchemy.dialects.postgresql import array_agg\n\nstmt = select([array_agg(table.c.value).contains(\"foo\")])\n```", "```py\nfrom sqlalchemy import func\n\nstmt = select(\n    [\n        department.c.id,\n        func.percentile_cont(0.5).within_group(department.c.salary.desc()),\n    ]\n)\n```", "```py\nSELECT  department.id,  percentile_cont(0.5)\nWITHIN  GROUP  (ORDER  BY  department.salary  DESC)\n```", "```py\n# old way\nclass MyEnum(TypeDecorator, SchemaType):\n    impl = postgresql.ENUM(\"one\", \"two\", \"three\", name=\"myenum\")\n\n    def _set_table(self, table):\n        self.impl._set_table(table)\n```", "```py\n# new way\nclass MyEnum(TypeDecorator):\n    impl = postgresql.ENUM(\"one\", \"two\", \"three\", name=\"myenum\")\n```", "```py\nclass User(Base):\n    __tablename__ = \"user\"\n    id = Column(Integer, primary_key=True)\n\n    __table_args__ = {\"schema\": \"per_user\"}\n```", "```py\nsession = Session()\nsession.connection(\n    execution_options={\"schema_translate_map\": {\"per_user\": \"account_one\"}}\n)\n\n# will query from the ``account_one.user`` table\nsession.query(User).get(5)\n```", "```py\n>>> from sqlalchemy import table, column\nt>>> t = table('x', column('a'), column('b'))\n>>> print(t.insert().returning(t.c.a, t.c.b))\nINSERT  INTO  x  (a,  b)  VALUES  (:a,  :b)  RETURNING  x.a,  x.b \n```", "```py\nclass StringAsInt(TypeDecorator):\n    impl = String\n\n    def column_expression(self, col):\n        return cast(col, Integer)\n\n    def bind_expression(self, value):\n        return cast(value, String)\n```", "```py\nclass Person(Base):\n    __tablename__ = \"person\"\n    id = Column(StringAsInt, primary_key=True)\n\n    pets = relationship(\n        \"Pets\",\n        primaryjoin=(\n            \"foreign(Pets.person_id)==cast(type_coerce(Person.id, Integer), Integer)\"\n        ),\n    )\n\nclass Pets(Base):\n    __tablename__ = \"pets\"\n    id = Column(\"id\", Integer, primary_key=True)\n    person_id = Column(\"person_id\", Integer)\n```", "```py\nSELECT  person.id  AS  person_id,  pets_1.id  AS  pets_1_id,\n  pets_1.person_id  AS  pets_1_person_id\nFROM  person\nLEFT  OUTER  JOIN  pets  AS  pets_1\nON  pets_1.person_id  =  CAST(person.id  AS  INTEGER)\n```", "```py\nSELECT  pets.id  AS  pets_id,  pets.person_id  AS  pets_person_id\nFROM  pets\nWHERE  pets.person_id  =  CAST(CAST(%(param_1)s  AS  VARCHAR)  AS  INTEGER)\n-- {'param_1': 5}\n```", "```py\nSELECT  pets.id  AS  pets_id,  pets.person_id  AS  pets_person_id\nFROM  pets\nWHERE  pets.person_id  =  CAST(%(param_1)s  AS  INTEGER)\n-- {'param_1': 5}\n```", "```py\nengine = create_engine(\"postgresql+psycopg2://\")\n\n@event.listens_for(engine, \"handle_error\")\ndef cancel_disconnect(ctx):\n    if isinstance(ctx.original_exception, KeyboardInterrupt):\n        ctx.is_disconnect = False\n```", "```py\n>>> from sqlalchemy import table, column, select, literal, exists\n>>> orders = table(\n...     \"orders\",\n...     column(\"region\"),\n...     column(\"amount\"),\n...     column(\"product\"),\n...     column(\"quantity\"),\n... )\n>>>\n>>> upsert = (\n...     orders.update()\n...     .where(orders.c.region == \"Region1\")\n...     .values(amount=1.0, product=\"Product1\", quantity=1)\n...     .returning(*(orders.c._all_columns))\n...     .cte(\"upsert\")\n... )\n>>>\n>>> insert = orders.insert().from_select(\n...     orders.c.keys(),\n...     select([literal(\"Region1\"), literal(1.0), literal(\"Product1\"), literal(1)]).where(\n...         ~exists(upsert.select())\n...     ),\n... )\n>>>\n>>> print(insert)  # Note: formatting added for clarity\nWITH  upsert  AS\n(UPDATE  orders  SET  amount=:amount,  product=:product,  quantity=:quantity\n  WHERE  orders.region  =  :region_1\n  RETURNING  orders.region,  orders.amount,  orders.product,  orders.quantity\n)\nINSERT  INTO  orders  (region,  amount,  product,  quantity)\nSELECT\n  :param_1  AS  anon_1,  :param_2  AS  anon_2,\n  :param_3  AS  anon_3,  :param_4  AS  anon_4\nWHERE  NOT  (\n  EXISTS  (\n  SELECT  upsert.region,  upsert.amount,\n  upsert.product,  upsert.quantity\n  FROM  upsert)) \n```", "```py\n>>> from sqlalchemy import func\n\n>>> print(func.row_number().over(order_by=\"x\", range_=(-5, 10)))\nrow_number()  OVER  (ORDER  BY  x  RANGE  BETWEEN  :param_1  PRECEDING  AND  :param_2  FOLLOWING)\n>>> print(func.row_number().over(order_by=\"x\", rows=(None, 0)))\nrow_number()  OVER  (ORDER  BY  x  ROWS  BETWEEN  UNBOUNDED  PRECEDING  AND  CURRENT  ROW)\n>>> print(func.row_number().over(order_by=\"x\", range_=(-2, None)))\nrow_number()  OVER  (ORDER  BY  x  RANGE  BETWEEN  :param_1  PRECEDING  AND  UNBOUNDED  FOLLOWING) \n```", "```py\n>>> from sqlalchemy import table, column, select, true\n>>> people = table(\"people\", column(\"people_id\"), column(\"age\"), column(\"name\"))\n>>> books = table(\"books\", column(\"book_id\"), column(\"owner_id\"))\n>>> subq = (\n...     select([books.c.book_id])\n...     .where(books.c.owner_id == people.c.people_id)\n...     .lateral(\"book_subq\")\n... )\n>>> print(select([people]).select_from(people.join(subq, true())))\nSELECT  people.people_id,  people.age,  people.name\nFROM  people  JOIN  LATERAL  (SELECT  books.book_id  AS  book_id\nFROM  books  WHERE  books.owner_id  =  people.people_id)\nAS  book_subq  ON  true \n```", "```py\nfrom sqlalchemy import func\n\nselectable = people.tablesample(func.bernoulli(1), name=\"alias\", seed=func.random())\nstmt = select([selectable.c.people_id])\n```", "```py\nSELECT  alias.people_id  FROM\npeople  AS  alias  TABLESAMPLE  bernoulli(:bernoulli_1)\nREPEATABLE  (random())\n```", "```py\nTable(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True),\n)\n```", "```py\n# old way\nTable(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True, autoincrement=False),\n    Column(\"y\", Integer, primary_key=True, autoincrement=False),\n)\n```", "```py\n# column 'y' will be SERIAL/AUTO_INCREMENT/ auto-generating\nTable(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n)\n```", "```py\nTable(\n    \"b\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True),\n)\n```", "```py\nSAWarning: Column 'b.x' is marked as a member of the primary\nkey for table 'b', but has no Python-side or server-side default\ngenerator indicated, nor does it indicate 'autoincrement=True',\nand no explicit value is passed.  Primary key columns may not\nstore NULL. Note that as of SQLAlchemy 1.1, 'autoincrement=True'\nmust be indicated explicitly for composite (e.g. multicolumn)\nprimary keys if AUTO_INCREMENT/SERIAL/IDENTITY behavior is\nexpected for one of the columns in the primary key. CREATE TABLE\nstatements are impacted by this change as well on most backends.\n```", "```py\nTable(\n    \"b\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True, server_default=FetchedValue()),\n    Column(\"y\", Integer, primary_key=True, server_default=FetchedValue()),\n)\n```", "```py\nTable(\n    \"b\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, nullable=True),\n)\n```", "```py\n>>> print(column(\"x\").is_distinct_from(None))\nx  IS  DISTINCT  FROM  NULL \n```", "```py\n>>> print(column(\"x\").isnot_distinct_from(False))\nx  IS  NOT  DISTINCT  FROM  false \n```", "```py\n>>> from sqlalchemy.dialects import sqlite\n>>> print(column(\"x\").is_distinct_from(None).compile(dialect=sqlite.dialect()))\nx  IS  NOT  NULL \n```", "```py\nstmt = select([t1]).select_from(t1.outerjoin(t2, full=True))\n```", "```py\nq = session.query(MyClass).outerjoin(MyOtherClass, full=True)\n```", "```py\nfrom sqlalchemy import text\n\nstmt = text(\n    \"SELECT users.id, addresses.id, users.id, \"\n    \"users.name, addresses.email_address AS email \"\n    \"FROM users JOIN addresses ON users.id=addresses.user_id \"\n    \"WHERE users.id = 1\"\n).columns(User.id, Address.id, Address.user_id, User.name, Address.email_address)\n\nquery = session.query(User).from_statement(stmt).options(contains_eager(User.addresses))\nresult = query.all()\n```", "```py\nua = users.alias(\"ua\")\nstmt = select([users.c.user_id, ua.c.user_id])\n```", "```py\nSELECT  users.user_id,  ua.user_id  FROM  users,  users  AS  ua\n```", "```py\nresult = conn.execute(stmt)\nrow = result.first()\n\n# these both match positionally, so no error\nuser_id = row[users.c.user_id]\nua_id = row[ua.c.user_id]\n\n# this still raises, however\nuser_id = row[\"user_id\"]\n```", "```py\nfrom sqlalchemy import text\n\nstmt = text(\n    \"SELECT users.id, addresses.id, users.id, \"\n    \"users.name, addresses.email_address AS email \"\n    \"FROM users JOIN addresses ON users.id=addresses.user_id \"\n    \"WHERE users.id = 1\"\n).columns(User.id, Address.id, Address.user_id, User.name, Address.email_address)\n\nquery = session.query(User).from_statement(stmt).options(contains_eager(User.addresses))\nresult = query.all()\n```", "```py\nua = users.alias(\"ua\")\nstmt = select([users.c.user_id, ua.c.user_id])\n```", "```py\nSELECT  users.user_id,  ua.user_id  FROM  users,  users  AS  ua\n```", "```py\nresult = conn.execute(stmt)\nrow = result.first()\n\n# these both match positionally, so no error\nuser_id = row[users.c.user_id]\nua_id = row[ua.c.user_id]\n\n# this still raises, however\nuser_id = row[\"user_id\"]\n```", "```py\nimport enum\nfrom sqlalchemy import Table, MetaData, Column, Enum, create_engine\n\nclass MyEnum(enum.Enum):\n    one = 1\n    two = 2\n    three = 3\n\nt = Table(\"data\", MetaData(), Column(\"value\", Enum(MyEnum)))\n\ne = create_engine(\"sqlite://\")\nt.create(e)\n\ne.execute(t.insert(), {\"value\": MyEnum.two})\nassert e.scalar(t.select()) is MyEnum.two\n```", "```py\n>>> from sqlalchemy import create_engine\n>>> e = create_engine(\"sqlite://\")\n>>> row = e.execute(\"select 1, 2, 3\").first()\n>>> row[-1], row[-2], row[1], row[-2:2]\n3 2 2 (2,)\n```", "```py\n>>> from sqlalchemy import Table, MetaData, Column, Enum, create_engine\n>>> t = Table(\n...     \"data\",\n...     MetaData(),\n...     Column(\"value\", Enum(\"one\", \"two\", \"three\", validate_strings=True)),\n... )\n>>> e = create_engine(\"sqlite://\")\n>>> t.create(e)\n>>> e.execute(t.insert(), {\"value\": \"four\"})\nTraceback (most recent call last):\n  ...\nsqlalchemy.exc.StatementError: (exceptions.LookupError)\n\"four\" is not among the defined enum values\n[SQL: u'INSERT INTO data (value) VALUES (?)']\n[parameters: [{'value': 'four'}]]\n```", "```py\n>>> from sqlalchemy import create_engine\n>>> import random\n>>> e = create_engine(\"sqlite://\", echo=\"debug\")\n>>> some_value = \"\".join(chr(random.randint(52, 85)) for i in range(5000))\n>>> row = e.execute(\"select ?\", [some_value]).first()\n... # (lines are wrapped for clarity) ...\n2016-02-17 13:23:03,027 INFO sqlalchemy.engine.base.Engine select ?\n2016-02-17 13:23:03,027 INFO sqlalchemy.engine.base.Engine\n('E6@?>9HPOJB<<BHR:@=TS:5ILU=;JLM<4?B9<S48PTNG9>:=TSTLA;9K;9FPM4M8M@;NM6GU\nLUAEBT9QGHNHTHR5EP75@OER4?SKC;D:TFUMD:M>;C6U:JLM6R67GEK<A6@S@C@J7>4=4:P\nGJ7HQ6 ... (4702 characters truncated) ... J6IK546AJMB4N6S9L;;9AKI;=RJP\nHDSSOTNBUEEC9@Q:RCL:I@5?FO<9K>KJAGAO@E6@A7JI8O:J7B69T6<8;F:S;4BEIJS9HM\nK:;5OLPM@JR;R:J6<SOTTT=>Q>7T@I::OTDC:CC<=NGP6C>BC8N',)\n2016-02-17 13:23:03,027 DEBUG sqlalchemy.engine.base.Engine Col ('?',)\n2016-02-17 13:23:03,027 DEBUG sqlalchemy.engine.base.Engine\nRow (u'E6@?>9HPOJB<<BHR:@=TS:5ILU=;JLM<4?B9<S48PTNG9>:=TSTLA;9K;9FPM4M8M@;\nNM6GULUAEBT9QGHNHTHR5EP75@OER4?SKC;D:TFUMD:M>;C6U:JLM6R67GEK<A6@S@C@J7\n>4=4:PGJ7HQ ... (4703 characters truncated) ... J6IK546AJMB4N6S9L;;9AKI;=\nRJPHDSSOTNBUEEC9@Q:RCL:I@5?FO<9K>KJAGAO@E6@A7JI8O:J7B69T6<8;F:S;4BEIJS9HM\nK:;5OLPM@JR;R:J6<SOTTT=>Q>7T@I::OTDC:CC<=NGP6C>BC8N',)\n>>> print(row)\n(u'E6@?>9HPOJB<<BHR:@=TS:5ILU=;JLM<4?B9<S48PTNG9>:=TSTLA;9K;9FPM4M8M@;NM6\nGULUAEBT9QGHNHTHR5EP75@OER4?SKC;D:TFUMD:M>;C6U:JLM6R67GEK<A6@S@C@J7>4\n=4:PGJ7HQ ... (4703 characters truncated) ... J6IK546AJMB4N6S9L;;9AKI;\n=RJPHDSSOTNBUEEC9@Q:RCL:I@5?FO<9K>KJAGAO@E6@A7JI8O:J7B69T6<8;F:S;4BEIJS9H\nMK:;5OLPM@JR;R:J6<SOTTT=>Q>7T@I::OTDC:CC<=NGP6C>BC8N',)\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    json_value = Column(JSON(none_as_null=False), default=\"some default\")\n\n# would insert \"some default\" instead of \"'null'\",\n# now will insert \"'null'\"\nobj = MyObject(json_value=None)\nsession.add(obj)\nsession.commit()\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    some_other_value = Column(String(50))\n    json_value = Column(JSON(none_as_null=False))\n\n# would result in NULL for some_other_value,\n# but json \"'null'\" for json_value.  Now results in NULL for both\n# (the json_value is omitted from the INSERT)\nobj = MyObject()\nsession.add(obj)\nsession.commit()\n```", "```py\n# would insert SQL NULL and/or trigger defaults,\n# now inserts \"'null'\"\nsession.bulk_insert_mappings(MyObject, [{\"json_value\": None}])\n```", "```py\nfrom sqlalchemy import null\nfrom sqlalchemy.dialects.postgresql import JSON\n\nobj1 = MyObject(json_value=null())  # will *always* insert SQL NULL\nobj2 = MyObject(json_value=JSON.NULL)  # will *always* insert JSON string \"null\"\n\nsession.add_all([obj1, obj2])\nsession.commit()\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    json_value = Column(JSON(none_as_null=False), default=\"some default\")\n\n# would insert \"some default\" instead of \"'null'\",\n# now will insert \"'null'\"\nobj = MyObject(json_value=None)\nsession.add(obj)\nsession.commit()\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    some_other_value = Column(String(50))\n    json_value = Column(JSON(none_as_null=False))\n\n# would result in NULL for some_other_value,\n# but json \"'null'\" for json_value.  Now results in NULL for both\n# (the json_value is omitted from the INSERT)\nobj = MyObject()\nsession.add(obj)\nsession.commit()\n```", "```py\n# would insert SQL NULL and/or trigger defaults,\n# now inserts \"'null'\"\nsession.bulk_insert_mappings(MyObject, [{\"json_value\": None}])\n```", "```py\nfrom sqlalchemy import null\nfrom sqlalchemy.dialects.postgresql import JSON\n\nobj1 = MyObject(json_value=null())  # will *always* insert SQL NULL\nobj2 = MyObject(json_value=JSON.NULL)  # will *always* insert JSON string \"null\"\n\nsession.add_all([obj1, obj2])\nsession.commit()\n```", "```py\nmytable = Table(\"mytable\", metadata, Column(\"data\", ARRAY(Integer, dimensions=2)))\n\nexpr = mytable.c.data[5][6]\n\nexpr = mytable.c.data[5].any(12)\n```", "```py\nfrom sqlalchemy import any_, all_\n\nselect([mytable]).where(12 == any_(mytable.c.data[5]))\n```", "```py\nfrom sqlalchemy import any_, all_\n\nsubq = select([mytable.c.value])\nselect([mytable]).where(12 > any_(subq))\n```", "```py\nfrom sqlalchemy import func\n\nstmt = select([func.array_agg(table.c.value)])\n```", "```py\nfrom sqlalchemy.dialects.postgresql import aggregate_order_by\n\nexpr = func.array_agg(aggregate_order_by(table.c.a, table.c.b.desc()))\nstmt = select([expr])\n```", "```py\nSELECT  array_agg(table1.a  ORDER  BY  table1.b  DESC)  AS  array_agg_1  FROM  table1\n```", "```py\nfrom sqlalchemy.dialects.postgresql import array_agg\n\nstmt = select([array_agg(table.c.value).contains(\"foo\")])\n```", "```py\nfrom sqlalchemy import func\n\nstmt = select(\n    [\n        department.c.id,\n        func.percentile_cont(0.5).within_group(department.c.salary.desc()),\n    ]\n)\n```", "```py\nSELECT  department.id,  percentile_cont(0.5)\nWITHIN  GROUP  (ORDER  BY  department.salary  DESC)\n```", "```py\n# old way\nclass MyEnum(TypeDecorator, SchemaType):\n    impl = postgresql.ENUM(\"one\", \"two\", \"three\", name=\"myenum\")\n\n    def _set_table(self, table):\n        self.impl._set_table(table)\n```", "```py\n# new way\nclass MyEnum(TypeDecorator):\n    impl = postgresql.ENUM(\"one\", \"two\", \"three\", name=\"myenum\")\n```", "```py\nclass User(Base):\n    __tablename__ = \"user\"\n    id = Column(Integer, primary_key=True)\n\n    __table_args__ = {\"schema\": \"per_user\"}\n```", "```py\nsession = Session()\nsession.connection(\n    execution_options={\"schema_translate_map\": {\"per_user\": \"account_one\"}}\n)\n\n# will query from the ``account_one.user`` table\nsession.query(User).get(5)\n```", "```py\n>>> from sqlalchemy import table, column\nt>>> t = table('x', column('a'), column('b'))\n>>> print(t.insert().returning(t.c.a, t.c.b))\nINSERT  INTO  x  (a,  b)  VALUES  (:a,  :b)  RETURNING  x.a,  x.b \n```", "```py\nclass StringAsInt(TypeDecorator):\n    impl = String\n\n    def column_expression(self, col):\n        return cast(col, Integer)\n\n    def bind_expression(self, value):\n        return cast(value, String)\n```", "```py\nclass Person(Base):\n    __tablename__ = \"person\"\n    id = Column(StringAsInt, primary_key=True)\n\n    pets = relationship(\n        \"Pets\",\n        primaryjoin=(\n            \"foreign(Pets.person_id)==cast(type_coerce(Person.id, Integer), Integer)\"\n        ),\n    )\n\nclass Pets(Base):\n    __tablename__ = \"pets\"\n    id = Column(\"id\", Integer, primary_key=True)\n    person_id = Column(\"person_id\", Integer)\n```", "```py\nSELECT  person.id  AS  person_id,  pets_1.id  AS  pets_1_id,\n  pets_1.person_id  AS  pets_1_person_id\nFROM  person\nLEFT  OUTER  JOIN  pets  AS  pets_1\nON  pets_1.person_id  =  CAST(person.id  AS  INTEGER)\n```", "```py\nSELECT  pets.id  AS  pets_id,  pets.person_id  AS  pets_person_id\nFROM  pets\nWHERE  pets.person_id  =  CAST(CAST(%(param_1)s  AS  VARCHAR)  AS  INTEGER)\n-- {'param_1': 5}\n```", "```py\nSELECT  pets.id  AS  pets_id,  pets.person_id  AS  pets_person_id\nFROM  pets\nWHERE  pets.person_id  =  CAST(%(param_1)s  AS  INTEGER)\n-- {'param_1': 5}\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    json_value = Column(JSON(none_as_null=False), nullable=False)\n```", "```py\nobj = MyObject()  # note no json_value\nsession.add(obj)\nsession.commit()  # will fail with integrity error\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    json_value = Column(JSON(none_as_null=False), nullable=False, default=JSON.NULL)\n```", "```py\nobj = MyObject(json_value=None)\nsession.add(obj)\nsession.commit()  # will insert JSON NULL\n```", "```py\n# default=None is the same as omitting it entirely, does not apply JSON NULL\njson_value = Column(JSON(none_as_null=False), nullable=False, default=None)\n```", "```py\nq = (\n    session.query(User.id, User.name.label(\"name\"))\n    .distinct()\n    .order_by(User.id, User.name, User.fullname)\n)\n```", "```py\nSELECT  DISTINCT  user.id  AS  a_id,  user.name  AS  name,\n  user.fullname  AS  a_fullname\nFROM  a  ORDER  BY  user.id,  user.name,  user.fullname\n```", "```py\nSELECT  DISTINCT  user.id  AS  a_id,  user.name  AS  name,  user.name  AS  a_name,\n  user.fullname  AS  a_fullname\nFROM  a  ORDER  BY  user.id,  user.name,  user.fullname\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\n    data = Column(String)\n\n    @validates(\"data\")\n    def _validate_data_one(self):\n        assert \"x\" in data\n\n    @validates(\"data\")\n    def _validate_data_two(self):\n        assert \"y\" in data\n\nconfigure_mappers()\n```", "```py\nsqlalchemy.exc.InvalidRequestError: A validation function for mapped attribute 'data'\non mapper Mapper|A|a already exists.\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    json_value = Column(JSON(none_as_null=False), nullable=False)\n```", "```py\nobj = MyObject()  # note no json_value\nsession.add(obj)\nsession.commit()  # will fail with integrity error\n```", "```py\nclass MyObject(Base):\n    # ...\n\n    json_value = Column(JSON(none_as_null=False), nullable=False, default=JSON.NULL)\n```", "```py\nobj = MyObject(json_value=None)\nsession.add(obj)\nsession.commit()  # will insert JSON NULL\n```", "```py\n# default=None is the same as omitting it entirely, does not apply JSON NULL\njson_value = Column(JSON(none_as_null=False), nullable=False, default=None)\n```", "```py\nq = (\n    session.query(User.id, User.name.label(\"name\"))\n    .distinct()\n    .order_by(User.id, User.name, User.fullname)\n)\n```", "```py\nSELECT  DISTINCT  user.id  AS  a_id,  user.name  AS  name,\n  user.fullname  AS  a_fullname\nFROM  a  ORDER  BY  user.id,  user.name,  user.fullname\n```", "```py\nSELECT  DISTINCT  user.id  AS  a_id,  user.name  AS  name,  user.name  AS  a_name,\n  user.fullname  AS  a_fullname\nFROM  a  ORDER  BY  user.id,  user.name,  user.fullname\n```", "```py\nclass A(Base):\n    __tablename__ = \"a\"\n    id = Column(Integer, primary_key=True)\n\n    data = Column(String)\n\n    @validates(\"data\")\n    def _validate_data_one(self):\n        assert \"x\" in data\n\n    @validates(\"data\")\n    def _validate_data_two(self):\n        assert \"y\" in data\n\nconfigure_mappers()\n```", "```py\nsqlalchemy.exc.InvalidRequestError: A validation function for mapped attribute 'data'\non mapper Mapper|A|a already exists.\n```", "```py\nstmt = text(\"SELECT id, name, description FROM table\")\n\n# no longer matches by name\nstmt = stmt.columns(my_table.c.name, my_table.c.description, my_table.c.id)\n```", "```py\n# correct version\nstmt = stmt.columns(my_table.c.id, my_table.c.name, my_table.c.description)\n```", "```py\nstmt = text(\"SELECT * FROM table\")\nstmt = stmt.columns(my_table.c.id, my_table.c.name, my_table.c.description)\n```", "```py\n>>> from sqlalchemy.schema import MetaData, Table, Column, CreateTable\n>>> from sqlalchemy.types import String\n>>> t = Table(\"t\", MetaData(), Column(\"x\", String(), server_default=\"hi ' there\"))\n>>> print(CreateTable(t))\nCREATE  TABLE  t  (\n  x  VARCHAR  DEFAULT  'hi '' there'\n) \n```", "```py\n(SELECT  x  FROM  table1  ORDER  BY  y  LIMIT  1)  UNION\n(SELECT  x  FROM  table2  ORDER  BY  y  LIMIT  2)\n```", "```py\nstmt1 = select([table1.c.x]).order_by(table1.c.y).limit(1)\nstmt2 = select([table1.c.x]).order_by(table2.c.y).limit(2)\n\nstmt = union(stmt1, stmt2)\n```", "```py\nstmt1 = select([table1.c.x]).order_by(table1.c.y).limit(1).alias().select()\nstmt2 = select([table2.c.x]).order_by(table2.c.y).limit(2).alias().select()\n\nstmt = union(stmt1, stmt2)\n```", "```py\nstmt1 = session.query(Model1).order_by(Model1.y).limit(1).subquery().select()\nstmt2 = session.query(Model2).order_by(Model2.y).limit(1).subquery().select()\n\nstmt = session.query(Model1).from_statement(stmt1.union(stmt2))\n```", "```py\nstmt = text(\"SELECT id, name, description FROM table\")\n\n# no longer matches by name\nstmt = stmt.columns(my_table.c.name, my_table.c.description, my_table.c.id)\n```", "```py\n# correct version\nstmt = stmt.columns(my_table.c.id, my_table.c.name, my_table.c.description)\n```", "```py\nstmt = text(\"SELECT * FROM table\")\nstmt = stmt.columns(my_table.c.id, my_table.c.name, my_table.c.description)\n```", "```py\n>>> from sqlalchemy.schema import MetaData, Table, Column, CreateTable\n>>> from sqlalchemy.types import String\n>>> t = Table(\"t\", MetaData(), Column(\"x\", String(), server_default=\"hi ' there\"))\n>>> print(CreateTable(t))\nCREATE  TABLE  t  (\n  x  VARCHAR  DEFAULT  'hi '' there'\n) \n```", "```py\n(SELECT  x  FROM  table1  ORDER  BY  y  LIMIT  1)  UNION\n(SELECT  x  FROM  table2  ORDER  BY  y  LIMIT  2)\n```", "```py\nstmt1 = select([table1.c.x]).order_by(table1.c.y).limit(1)\nstmt2 = select([table1.c.x]).order_by(table2.c.y).limit(2)\n\nstmt = union(stmt1, stmt2)\n```", "```py\nstmt1 = select([table1.c.x]).order_by(table1.c.y).limit(1).alias().select()\nstmt2 = select([table2.c.x]).order_by(table2.c.y).limit(2).alias().select()\n\nstmt = union(stmt1, stmt2)\n```", "```py\nstmt1 = session.query(Model1).order_by(Model1.y).limit(1).subquery().select()\nstmt2 = session.query(Model2).order_by(Model2.y).limit(1).subquery().select()\n\nstmt = session.query(Model1).from_statement(stmt1.union(stmt2))\n```", "```py\nfrom sqlalchemy.dialects.postgresql import insert\n\ninsert_stmt = insert(my_table).values(id=\"some_id\", data=\"some data to insert\")\n\ndo_update_stmt = insert_stmt.on_conflict_do_update(\n    index_elements=[my_table.c.id], set_=dict(data=\"some data to update\")\n)\n\nconn.execute(do_update_stmt)\n```", "```py\nINSERT  INTO  my_table  (id,  data)\nVALUES  (:id,  :data)\nON  CONFLICT  id  DO  UPDATE  SET  data=:data_2\n```", "```py\n    int_expr = col[5][6][7]  # returns an Integer expression object\n    ```", "```py\n    json_expr = json_col[\"key1\"][\"attr1\"][5]\n    ```", "```py\nexpr = json_col[\"somekey\"].cast(Integer)\n```", "```py\nexpr = json_col[\"somekey\"].astext.cast(Integer)\n```", "```py\nenum = Enum(\n    \"manager\",\n    \"place_admin\",\n    \"carwash_admin\",\n    \"parking_admin\",\n    \"service_admin\",\n    \"tire_admin\",\n    \"mechanic\",\n    \"carwasher\",\n    \"tire_mechanic\",\n    name=\"work_place_roles\",\n)\n\nclass WorkPlacement(Base):\n    __tablename__ = \"work_placement\"\n    id = Column(Integer, primary_key=True)\n    roles = Column(ARRAY(enum))\n\ne = create_engine(\"postgresql://scott:tiger@localhost/test\", echo=True)\nBase.metadata.create_all(e)\n```", "```py\nCREATE  TYPE  work_place_roles  AS  ENUM  (\n  'manager',  'place_admin',  'carwash_admin',  'parking_admin',\n  'service_admin',  'tire_admin',  'mechanic',  'carwasher',\n  'tire_mechanic')\n\nCREATE  TABLE  work_placement  (\n  id  SERIAL  NOT  NULL,\n  roles  work_place_roles[],\n  PRIMARY  KEY  (id)\n)\n```", "```py\nfrom sqlalchemy import inspect\n\ninsp = inspect(engine)\n\nplain_views = insp.get_view_names(include=\"plain\")\nall_views = insp.get_view_names(include=(\"plain\", \"materialized\"))\n```", "```py\n    stmt = select([table]).with_for_update(key_share=True)\n    ```", "```py\n    stmt = select([table]).with_for_update(skip_locked=True)\n    ```", "```py\n    stmt = select([table]).with_for_update(read=True, key_share=True)\n    ```", "```py\nfrom sqlalchemy.dialects.postgresql import insert\n\ninsert_stmt = insert(my_table).values(id=\"some_id\", data=\"some data to insert\")\n\ndo_update_stmt = insert_stmt.on_conflict_do_update(\n    index_elements=[my_table.c.id], set_=dict(data=\"some data to update\")\n)\n\nconn.execute(do_update_stmt)\n```", "```py\nINSERT  INTO  my_table  (id,  data)\nVALUES  (:id,  :data)\nON  CONFLICT  id  DO  UPDATE  SET  data=:data_2\n```", "```py\n    int_expr = col[5][6][7]  # returns an Integer expression object\n    ```", "```py\n    json_expr = json_col[\"key1\"][\"attr1\"][5]\n    ```", "```py\nexpr = json_col[\"somekey\"].cast(Integer)\n```", "```py\nexpr = json_col[\"somekey\"].astext.cast(Integer)\n```", "```py\nenum = Enum(\n    \"manager\",\n    \"place_admin\",\n    \"carwash_admin\",\n    \"parking_admin\",\n    \"service_admin\",\n    \"tire_admin\",\n    \"mechanic\",\n    \"carwasher\",\n    \"tire_mechanic\",\n    name=\"work_place_roles\",\n)\n\nclass WorkPlacement(Base):\n    __tablename__ = \"work_placement\"\n    id = Column(Integer, primary_key=True)\n    roles = Column(ARRAY(enum))\n\ne = create_engine(\"postgresql://scott:tiger@localhost/test\", echo=True)\nBase.metadata.create_all(e)\n```", "```py\nCREATE  TYPE  work_place_roles  AS  ENUM  (\n  'manager',  'place_admin',  'carwash_admin',  'parking_admin',\n  'service_admin',  'tire_admin',  'mechanic',  'carwasher',\n  'tire_mechanic')\n\nCREATE  TABLE  work_placement  (\n  id  SERIAL  NOT  NULL,\n  roles  work_place_roles[],\n  PRIMARY  KEY  (id)\n)\n```", "```py\nfrom sqlalchemy import inspect\n\ninsp = inspect(engine)\n\nplain_views = insp.get_view_names(include=\"plain\")\nall_views = insp.get_view_names(include=(\"plain\", \"materialized\"))\n```", "```py\n    stmt = select([table]).with_for_update(key_share=True)\n    ```", "```py\n    stmt = select([table]).with_for_update(skip_locked=True)\n    ```", "```py\n    stmt = select([table]).with_for_update(read=True, key_share=True)\n    ```", "```py\nconnection = engine.connect()\nconnection = connection.execution_options(isolation_level=\"AUTOCOMMIT\")\n```", "```py\nt = Table(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True, autoincrement=False),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n    mysql_engine=\"InnoDB\",\n)\n```", "```py\nCREATE  TABLE  some_table  (\n  x  INTEGER  NOT  NULL,\n  y  INTEGER  NOT  NULL  AUTO_INCREMENT,\n  PRIMARY  KEY  (x,  y),\n  KEY  idx_autoinc_y  (y)\n)ENGINE=InnoDB\n```", "```py\nCREATE  TABLE  some_table  (\n  x  INTEGER  NOT  NULL,\n  y  INTEGER  NOT  NULL  AUTO_INCREMENT,\n  PRIMARY  KEY  (y,  x)\n)ENGINE=InnoDB\n```", "```py\nt = Table(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n    PrimaryKeyConstraint(\"x\", \"y\"),\n    UniqueConstraint(\"y\"),\n    mysql_engine=\"InnoDB\",\n)\n```", "```py\nt = Table(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n    mysql_engine=\"InnoDB\",\n)\n```", "```py\nconnection = engine.connect()\nconnection = connection.execution_options(isolation_level=\"AUTOCOMMIT\")\n```", "```py\nt = Table(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True, autoincrement=False),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n    mysql_engine=\"InnoDB\",\n)\n```", "```py\nCREATE  TABLE  some_table  (\n  x  INTEGER  NOT  NULL,\n  y  INTEGER  NOT  NULL  AUTO_INCREMENT,\n  PRIMARY  KEY  (x,  y),\n  KEY  idx_autoinc_y  (y)\n)ENGINE=InnoDB\n```", "```py\nCREATE  TABLE  some_table  (\n  x  INTEGER  NOT  NULL,\n  y  INTEGER  NOT  NULL  AUTO_INCREMENT,\n  PRIMARY  KEY  (y,  x)\n)ENGINE=InnoDB\n```", "```py\nt = Table(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n    PrimaryKeyConstraint(\"x\", \"y\"),\n    UniqueConstraint(\"y\"),\n    mysql_engine=\"InnoDB\",\n)\n```", "```py\nt = Table(\n    \"some_table\",\n    metadata,\n    Column(\"x\", Integer, primary_key=True),\n    Column(\"y\", Integer, primary_key=True, autoincrement=True),\n    mysql_engine=\"InnoDB\",\n)\n```", "```py\nengine = create_engine(\n    \"mssql+pyodbc://scott:tiger@ms_2008\", isolation_level=\"REPEATABLE READ\"\n)\n```", "```py\n>>> from sqlalchemy import create_engine, inspect\n>>> engine = create_engine(\"mssql+pyodbc://scott:tiger@ms_2008\", echo=True)\n>>> engine.execute(\"create table s (x varchar(max), y varbinary(max))\")\n>>> insp = inspect(engine)\n>>> for col in insp.get_columns(\"s\"):\n...     print(col[\"type\"].__class__, col[\"type\"].length)\n<class 'sqlalchemy.sql.sqltypes.VARCHAR'> max\n<class 'sqlalchemy.dialects.mssql.base.VARBINARY'> max\n```", "```py\n>>> for col in insp.get_columns(\"s\"):\n...     print(col[\"type\"].__class__, col[\"type\"].length)\n<class 'sqlalchemy.sql.sqltypes.VARCHAR'> None\n<class 'sqlalchemy.dialects.mssql.base.VARBINARY'> None\n```", "```py\naccount_table = Table(\n    \"account\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"info\", String(100)),\n    schema=\"customer_schema\",\n)\n```", "```py\n>>> eng = create_engine(\"mssql+pymssql://mydsn\", legacy_schema_aliasing=True)\n>>> print(account_table.select().compile(eng))\nSELECT  account_1.id,  account_1.info\nFROM  customer_schema.account  AS  account_1 \n```", "```py\nengine = create_engine(\n    \"mssql+pyodbc://scott:tiger@ms_2008\", isolation_level=\"REPEATABLE READ\"\n)\n```", "```py\n>>> from sqlalchemy import create_engine, inspect\n>>> engine = create_engine(\"mssql+pyodbc://scott:tiger@ms_2008\", echo=True)\n>>> engine.execute(\"create table s (x varchar(max), y varbinary(max))\")\n>>> insp = inspect(engine)\n>>> for col in insp.get_columns(\"s\"):\n...     print(col[\"type\"].__class__, col[\"type\"].length)\n<class 'sqlalchemy.sql.sqltypes.VARCHAR'> max\n<class 'sqlalchemy.dialects.mssql.base.VARBINARY'> max\n```", "```py\n>>> for col in insp.get_columns(\"s\"):\n...     print(col[\"type\"].__class__, col[\"type\"].length)\n<class 'sqlalchemy.sql.sqltypes.VARCHAR'> None\n<class 'sqlalchemy.dialects.mssql.base.VARBINARY'> None\n```", "```py\naccount_table = Table(\n    \"account\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"info\", String(100)),\n    schema=\"customer_schema\",\n)\n```", "```py\n>>> eng = create_engine(\"mssql+pymssql://mydsn\", legacy_schema_aliasing=True)\n>>> print(account_table.select().compile(eng))\nSELECT  account_1.id,  account_1.info\nFROM  customer_schema.account  AS  account_1 \n```"]