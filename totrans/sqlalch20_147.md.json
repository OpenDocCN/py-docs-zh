["```py\n    class Parent(Base):\n        __tablename__ = \"parent\"\n        id = Column(Integer, primary_key=True)\n        child_id_one = Column(Integer, ForeignKey(\"child.id\"))\n        child_id_two = Column(Integer, ForeignKey(\"child.id\"))\n\n        child_one = relationship(\"Child\", foreign_keys=child_id_one)\n        child_two = relationship(\"Child\", foreign_keys=child_id_two)\n\n    class Child(Base):\n        __tablename__ = \"child\"\n        id = Column(Integer, primary_key=True)\n    ```", "```py\n    class Folder(Base):\n        __tablename__ = \"folder\"\n        __table_args__ = (\n            ForeignKeyConstraint(\n                [\"account_id\", \"parent_id\"], [\"folder.account_id\", \"folder.folder_id\"]\n            ),\n        )\n\n        account_id = Column(Integer, primary_key=True)\n        folder_id = Column(Integer, primary_key=True)\n        parent_id = Column(Integer)\n        name = Column(String)\n\n        parent_folder = relationship(\n            \"Folder\", backref=\"child_folders\", remote_side=[account_id, folder_id]\n        )\n    ```", "```py\n    SELECT\n      folder.account_id  AS  folder_account_id,\n      folder.folder_id  AS  folder_folder_id,\n      folder.parent_id  AS  folder_parent_id,\n      folder.name  AS  folder_name,\n      folder_1.account_id  AS  folder_1_account_id,\n      folder_1.folder_id  AS  folder_1_folder_id,\n      folder_1.parent_id  AS  folder_1_parent_id,\n      folder_1.name  AS  folder_1_name\n    FROM  folder\n      LEFT  OUTER  JOIN  folder  AS  folder_1\n      ON\n      folder_1.account_id  =  folder.account_id\n      AND  folder.folder_id  =  folder_1.parent_id\n\n    WHERE  folder.folder_id  =  ?  AND  folder.account_id  =  ?\n    ```", "```py\n    class HostEntry(Base):\n        __tablename__ = \"host_entry\"\n\n        id = Column(Integer, primary_key=True)\n        ip_address = Column(INET)\n        content = Column(String(50))\n\n        # relationship() using explicit foreign_keys, remote_side\n        parent_host = relationship(\n            \"HostEntry\",\n            primaryjoin=ip_address == cast(content, INET),\n            foreign_keys=content,\n            remote_side=ip_address,\n        )\n    ```", "```py\n    from sqlalchemy.orm import foreign, remote\n\n    class HostEntry(Base):\n        __tablename__ = \"host_entry\"\n\n        id = Column(Integer, primary_key=True)\n        ip_address = Column(INET)\n        content = Column(String(50))\n\n        # relationship() using explicit foreign() and remote() annotations\n        # in lieu of separate arguments\n        parent_host = relationship(\n            \"HostEntry\",\n            primaryjoin=remote(ip_address) == cast(foreign(content), INET),\n        )\n    ```", "```py\n>>> class User(Base):\n...     __tablename__ = \"user\"\n...     id = Column(Integer, primary_key=True)\n...     name = Column(String)\n...     name_syn = synonym(name)\n...     addresses = relationship(\"Address\")\n\n>>> # universal entry point is inspect()\n>>> b = inspect(User)\n\n>>> # b in this case is the Mapper\n>>> b\n<Mapper at 0x101521950; User>\n\n>>> # Column namespace\n>>> b.columns.id\nColumn('id', Integer(), table=<user>, primary_key=True, nullable=False)\n\n>>> # mapper's perspective of the primary key\n>>> b.primary_key\n(Column('id', Integer(), table=<user>, primary_key=True, nullable=False),)\n\n>>> # MapperProperties available from .attrs\n>>> b.attrs.keys()\n['name_syn', 'addresses', 'id', 'name']\n\n>>> # .column_attrs, .relationships, etc. filter this collection\n>>> b.column_attrs.keys()\n['id', 'name']\n\n>>> list(b.relationships)\n[<sqlalchemy.orm.properties.RelationshipProperty object at 0x1015212d0>]\n\n>>> # they are also namespaces\n>>> b.column_attrs.id\n<sqlalchemy.orm.properties.ColumnProperty object at 0x101525090>\n\n>>> b.relationships.addresses\n<sqlalchemy.orm.properties.RelationshipProperty object at 0x1015212d0>\n\n>>> # point inspect() at a mapped, class level attribute,\n>>> # returns the attribute itself\n>>> b = inspect(User.addresses)\n>>> b\n<sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x101521fd0>\n\n>>> # From here we can get the mapper:\n>>> b.mapper\n<Mapper at 0x101525810; Address>\n\n>>> # the parent inspector, in this case a mapper\n>>> b.parent\n<Mapper at 0x101521950; User>\n\n>>> # an expression\n>>> print(b.expression)\n\"user\".id  =  address.user_id\n>>> # inspect works on instances\n>>> u1 = User(id=3, name=\"x\")\n>>> b = inspect(u1)\n\n>>> # it returns the InstanceState\n>>> b\n<sqlalchemy.orm.state.InstanceState object at 0x10152bed0>\n\n>>> # similar attrs accessor refers to the\n>>> b.attrs.keys()\n['id', 'name_syn', 'addresses', 'name']\n\n>>> # attribute interface - from attrs, you get a state object\n>>> b.attrs.id\n<sqlalchemy.orm.state.AttributeState object at 0x10152bf90>\n\n>>> # this object can give you, current value...\n>>> b.attrs.id.value\n3\n\n>>> # ... current history\n>>> b.attrs.id.history\nHistory(added=[3], unchanged=(), deleted=())\n\n>>> # InstanceState can also provide session state information\n>>> # lets assume the object is persistent\n>>> s = Session()\n>>> s.add(u1)\n>>> s.commit()\n\n>>> # now we can get primary key identity, always\n>>> # works in query.get()\n>>> b.identity\n(3,)\n\n>>> # the mapper level key\n>>> b.identity_key\n(<class '__main__.User'>, (3,))\n\n>>> # state within the session\n>>> b.persistent, b.transient, b.deleted, b.detached\n(True, False, False, False)\n\n>>> # owning session\n>>> b.session\n<sqlalchemy.orm.session.Session object at 0x101701150>\n```", "```py\nfrom sqlalchemy.orm import with_polymorphic\n\npalias = with_polymorphic(Person, [Engineer, Manager])\nsession.query(Company).join(palias, Company.employees).filter(\n    or_(Engineer.language == \"java\", Manager.hair == \"pointy\")\n)\n```", "```py\n# use eager loading in conjunction with with_polymorphic targets\nJob_P = with_polymorphic(Job, [SubJob, ExtraJob], aliased=True)\nq = (\n    s.query(DataContainer)\n    .join(DataContainer.jobs.of_type(Job_P))\n    .options(contains_eager(DataContainer.jobs.of_type(Job_P)))\n)\n```", "```py\n# use eager loading in conjunction with with_polymorphic targets\nJob_P = with_polymorphic(Job, [SubJob, ExtraJob], aliased=True)\nq = (\n    s.query(DataContainer)\n    .join(DataContainer.jobs.of_type(Job_P))\n    .options(contains_eager(DataContainer.jobs.of_type(Job_P)))\n)\n\n# pass subclasses to eager loads (implicitly applies with_polymorphic)\nq = s.query(ParentThing).options(\n    joinedload_all(ParentThing.container, DataContainer.jobs.of_type(SubJob))\n)\n\n# control self-referential aliasing with any()/has()\nJob_A = aliased(Job)\nq = (\n    s.query(Job)\n    .join(DataContainer.jobs)\n    .filter(\n        DataContainer.jobs.of_type(Job_A).any(\n            and_(Job_A.id < Job.id, Job_A.type == \"fred\")\n        )\n    )\n)\n```", "```py\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\n@event.listens_for(\"load\", Base, propagate=True)\ndef on_load(target, context):\n    print(\"New instance loaded:\", target)\n\n# on_load() will be applied to SomeClass\nclass SomeClass(Base):\n    __tablename__ = \"sometable\"\n\n    # ...\n```", "```py\nclass Snack(Base):\n    # ...\n\n    peanuts = relationship(\n        \"nuts.Peanut\", primaryjoin=\"nuts.Peanut.snack_id == Snack.id\"\n    )\n```", "```py\nclass ReflectedOne(DeferredReflection, Base):\n    __abstract__ = True\n\nclass ReflectedTwo(DeferredReflection, Base):\n    __abstract__ = True\n\nclass MyClass(ReflectedOne):\n    __tablename__ = \"mytable\"\n\nclass MyOtherClass(ReflectedOne):\n    __tablename__ = \"myothertable\"\n\nclass YetAnotherClass(ReflectedTwo):\n    __tablename__ = \"yetanothertable\"\n\nReflectedOne.prepare(engine_one)\nReflectedTwo.prepare(engine_two)\n```", "```py\nfrom sqlalchemy import select\n\nstmt = select([User]).where(User.id == 5)\n```", "```py\nquery(SomeEntity).filter(SomeEntity.id == SomeOtherEntity.id).filter(\n    SomeOtherEntity.foo == \"bar\"\n).update({\"data\": \"x\"})\n```", "```py\nquery(Engineer).filter(Person.id == Engineer.id).filter(\n    Person.name == \"dilbert\"\n).update({\"engineer_data\": \"java\"})\n```", "```py\nUPDATE  engineer  SET  engineer_data='java'  FROM  person\nWHERE  person.id=engineer.id  AND  person.name='dilbert'\n```", "```py\n--- examples/beaker_caching/caching_query.py\n+++ examples/beaker_caching/caching_query.py\n@@ -222,7 +222,8 @@\n\n         \"\"\"\n         if query._current_path:\n-            mapper, key = query._current_path[-2:]\n+            mapper, prop = query._current_path[-2:]\n+            key = prop.key\n\n             for cls in mapper.class_.__mro__:\n                 if (cls, key) in self._relationship_options:\n```", "```py\nfrom sqlalchemy.types import Numeric\nfrom sqlalchemy.sql import func\n\nclass CustomNumeric(Numeric):\n    class comparator_factory(Numeric.Comparator):\n        def log(self, other):\n            return func.log(self.expr, other)\n```", "```py\ndata = Table(\n    \"data\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"x\", CustomNumeric(10, 5)),\n    Column(\"y\", CustomNumeric(10, 5)),\n)\n\nstmt = select([data.c.x.log(data.c.y)]).where(data.c.x.log(2) < value)\nprint(conn.execute(stmt).fetchall())\n```", "```py\nusers.insert().values(\n    [\n        {\"name\": \"some name\"},\n        {\"name\": \"some other name\"},\n        {\"name\": \"yet another name\"},\n    ]\n)\n```", "```py\nfrom sqlalchemy.types import String\nfrom sqlalchemy import func, Table, Column, MetaData\n\nclass LowerString(String):\n    def bind_expression(self, bindvalue):\n        return func.lower(bindvalue)\n\n    def column_expression(self, col):\n        return func.lower(col)\n\nmetadata = MetaData()\ntest_table = Table(\"test_table\", metadata, Column(\"data\", LowerString))\n```", "```py\n>>> print(select([test_table]).where(test_table.c.data == \"HI\"))\nSELECT  lower(test_table.data)  AS  data\nFROM  test_table\nWHERE  test_table.data  =  lower(:data_1) \n```", "```py\nfrom sqlalchemy import inspect\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"postgresql://scott:tiger@localhost/test\")\ninsp = inspect(engine)\nprint(insp.get_table_names())\n```", "```py\nclass SnortEvent(Base):\n    __tablename__ = \"event\"\n\n    id = Column(Integer, primary_key=True)\n    signature = Column(Integer, ForeignKey(\"signature.id\"))\n\n    signatures = relationship(\"Signature\", lazy=False)\n\nclass Signature(Base):\n    __tablename__ = \"signature\"\n\n    id = Column(Integer, primary_key=True)\n\n    sig_count = column_property(\n        select([func.count(\"*\")])\n        .where(SnortEvent.signature == id)\n        .correlate_except(SnortEvent)\n    )\n```", "```py\nfrom sqlalchemy.dialects.postgresql import HSTORE\n\ndata = Table(\n    \"data_table\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"hstore_data\", HSTORE),\n)\n\nengine.execute(select([data.c.hstore_data[\"some_key\"]])).scalar()\n\nengine.execute(select([data.c.hstore_data.matrix()])).scalar()\n```", "```py\n# old way, still works since PG supports N-dimensions per row:\nColumn(\"my_array\", postgresql.ARRAY(Integer))\n\n# new way, will render ARRAY with correct number of [] in DDL,\n# will process binds and results more efficiently as we don't need\n# to guess how many levels deep to go\nColumn(\"my_array\", postgresql.ARRAY(Integer, dimensions=2))\n```", "```py\nresult = conn.execute(select([mytable.c.arraycol[2]]))\n```", "```py\nresult = conn.execute(select([mytable.c.arraycol[2:4]]))\n```", "```py\nconn.execute(mytable.update().values({mytable.c.arraycol[2:3]: [7, 8]}))\n```", "```py\n>>> from sqlalchemy.dialects import postgresql\n>>> conn.scalar(select([postgresql.array([1, 2]) + postgresql.array([3, 4, 5])]))\n[1, 2, 3, 4, 5]\n```", "```py\nselect([mytable.c.arraycol + [4, 5, 6]])\n```", "```py\nColumn(\"sometimestamp\", sqlite.DATETIME(truncate_microseconds=True))\nColumn(\n    \"sometimestamp\",\n    sqlite.DATETIME(\n        storage_format=(\n            \"%(year)04d%(month)02d%(day)02d\"\n            \"%(hour)02d%(minute)02d%(second)02d%(microsecond)06d\"\n        ),\n        regexp=\"(\\d{4})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{6})\",\n    ),\n)\nColumn(\n    \"somedate\",\n    sqlite.DATE(\n        storage_format=\"%(month)02d/%(day)02d/%(year)04d\",\n        regexp=\"(?P<month>\\d+)/(?P<day>\\d+)/(?P<year>\\d+)\",\n    ),\n)\n```", "```py\n>>> stmt = select([cast(sometable.c.somechar, String(20, collation=\"utf8\"))])\n>>> print(stmt)\nSELECT  CAST(sometable.somechar  AS  VARCHAR(20)  COLLATE  \"utf8\")  AS  anon_1\nFROM  sometable \n```", "```py\nstmt = table.delete().prefix_with(\"LOW_PRIORITY\", dialect=\"mysql\")\n\nstmt = table.update().prefix_with(\"LOW_PRIORITY\", dialect=\"mysql\")\n```", "```py\nfrom sqlalchemy import Column, Integer, String, ForeignKey\nfrom sqlalchemy.orm import relationship, backref\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = \"user\"\n    id = Column(Integer, primary_key=True)\n    name = Column(String(64))\n\nclass UserKeyword(Base):\n    __tablename__ = \"user_keyword\"\n    user_id = Column(Integer, ForeignKey(\"user.id\"), primary_key=True)\n    keyword_id = Column(Integer, ForeignKey(\"keyword.id\"), primary_key=True)\n\n    user = relationship(\n        User, backref=backref(\"user_keywords\", cascade=\"all, delete-orphan\")\n    )\n\n    keyword = relationship(\n        \"Keyword\", backref=backref(\"user_keywords\", cascade=\"all, delete-orphan\")\n    )\n\n    # uncomment this to enable the old behavior\n    # __mapper_args__ = {\"legacy_is_orphan\": True}\n\nclass Keyword(Base):\n    __tablename__ = \"keyword\"\n    id = Column(Integer, primary_key=True)\n    keyword = Column(\"keyword\", String(64))\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import Session\n\n# note we're using PostgreSQL to ensure that referential integrity\n# is enforced, for demonstration purposes.\ne = create_engine(\"postgresql://scott:tiger@localhost/test\", echo=True)\n\nBase.metadata.drop_all(e)\nBase.metadata.create_all(e)\n\nsession = Session(e)\n\nu1 = User(name=\"u1\")\nk1 = Keyword(keyword=\"k1\")\n\nsession.add_all([u1, k1])\n\nuk1 = UserKeyword(keyword=k1, user=u1)\n\n# previously, if session.flush() were called here,\n# this operation would succeed, but if session.flush()\n# were not called here, the operation fails with an\n# integrity error.\n# session.flush()\ndel u1.user_keywords[0]\n\nsession.commit()\n```", "```py\n@event.listens_for(Session, \"after_attach\")\ndef after_attach(session, instance):\n    assert instance in session\n```", "```py\n@event.listens_for(Session, \"before_attach\")\ndef before_attach(session, instance):\n    instance.some_necessary_attribute = (\n        session.query(Widget).filter_by(instance.widget_name).first()\n    )\n```", "```py\nsubq = (\n    session.query(Entity.value)\n    .filter(Entity.id == Parent.entity_id)\n    .correlate(Parent)\n    .as_scalar()\n)\nsession.query(Parent).filter(subq == \"some value\")\n```", "```py\nsubq = session.query(Entity.value).filter(Entity.id == Parent.entity_id).as_scalar()\nsession.query(Parent).filter(subq == \"some value\")\n```", "```py\nfrom sqlalchemy.sql import table, column, select\n\nt1 = table(\"t1\", column(\"x\"))\nt2 = table(\"t2\", column(\"y\"))\ns = select([t1, t2]).correlate(t1)\n\nprint(s)\n```", "```py\nSELECT  t1.x,  t2.y  FROM  t2\n```", "```py\nSELECT  t1.x,  t2.y  FROM  t1,  t2\n```", "```py\ns2 = select([t1, t2]).where(t1.c.x == t2.c.y).where(t1.c.x == s)\nprint(s2)\n```", "```py\nSELECT  t1.x,  t2.y  FROM  t1,  t2\nWHERE  t1.x  =  t2.y  AND  t1.x  =\n  (SELECT  t1.x,  t2.y  FROM  t2)\n```", "```py\nscalar_subq = select([someothertable.c.id]).where(someothertable.c.data == \"foo\")\nselect([sometable]).where(sometable.c.id == scalar_subq)\n```", "```py\ns = select([table1]).apply_labels()\ns.c.table1_col1\ns.c.table1_col2\n```", "```py\n# before 0.8\ntable1 = Table(\"t1\", metadata, Column(\"col1\", Integer, key=\"column_one\"))\ns = select([table1])\ns.c.column_one  # would be accessible like this\ns.c.col1  # would raise AttributeError\n\ns = select([table1]).apply_labels()\ns.c.table1_column_one  # would raise AttributeError\ns.c.table1_col1  # would be accessible like this\n```", "```py\n# with 0.8\ntable1 = Table(\"t1\", metadata, Column(\"col1\", Integer, key=\"column_one\"))\ns = select([table1])\ns.c.column_one  # works\ns.c.col1  # AttributeError\n\ns = select([table1]).apply_labels()\ns.c.table1_column_one  # works\ns.c.table1_col1  # AttributeError\n```", "```py\n@event.listens_for(Table, \"column_reflect\")\ndef listen_for_col(inspector, table, column_info): ...\n```", "```py\nt1 = table(\"t1\", column(\"x\"))\nt1.insert().values(x=5, z=5)  # raises \"Unconsumed column names: z\"\n```", "```py\n>>> insp.get_primary_keys()\n[\"a\", \"b\"]\n\n>>> insp.get_pk_constraint()\n{\"name\":\"pk_constraint\", \"constrained_columns\":[\"a\", \"b\"]}\n```", "```py\n>>> row = result.fetchone()\n>>> row[\"foo\"] == row[\"FOO\"] == row[\"Foo\"]\nTrue\n```", "```py\n    class Parent(Base):\n        __tablename__ = \"parent\"\n        id = Column(Integer, primary_key=True)\n        child_id_one = Column(Integer, ForeignKey(\"child.id\"))\n        child_id_two = Column(Integer, ForeignKey(\"child.id\"))\n\n        child_one = relationship(\"Child\", foreign_keys=child_id_one)\n        child_two = relationship(\"Child\", foreign_keys=child_id_two)\n\n    class Child(Base):\n        __tablename__ = \"child\"\n        id = Column(Integer, primary_key=True)\n    ```", "```py\n    class Folder(Base):\n        __tablename__ = \"folder\"\n        __table_args__ = (\n            ForeignKeyConstraint(\n                [\"account_id\", \"parent_id\"], [\"folder.account_id\", \"folder.folder_id\"]\n            ),\n        )\n\n        account_id = Column(Integer, primary_key=True)\n        folder_id = Column(Integer, primary_key=True)\n        parent_id = Column(Integer)\n        name = Column(String)\n\n        parent_folder = relationship(\n            \"Folder\", backref=\"child_folders\", remote_side=[account_id, folder_id]\n        )\n    ```", "```py\n    SELECT\n      folder.account_id  AS  folder_account_id,\n      folder.folder_id  AS  folder_folder_id,\n      folder.parent_id  AS  folder_parent_id,\n      folder.name  AS  folder_name,\n      folder_1.account_id  AS  folder_1_account_id,\n      folder_1.folder_id  AS  folder_1_folder_id,\n      folder_1.parent_id  AS  folder_1_parent_id,\n      folder_1.name  AS  folder_1_name\n    FROM  folder\n      LEFT  OUTER  JOIN  folder  AS  folder_1\n      ON\n      folder_1.account_id  =  folder.account_id\n      AND  folder.folder_id  =  folder_1.parent_id\n\n    WHERE  folder.folder_id  =  ?  AND  folder.account_id  =  ?\n    ```", "```py\n    class HostEntry(Base):\n        __tablename__ = \"host_entry\"\n\n        id = Column(Integer, primary_key=True)\n        ip_address = Column(INET)\n        content = Column(String(50))\n\n        # relationship() using explicit foreign_keys, remote_side\n        parent_host = relationship(\n            \"HostEntry\",\n            primaryjoin=ip_address == cast(content, INET),\n            foreign_keys=content,\n            remote_side=ip_address,\n        )\n    ```", "```py\n    from sqlalchemy.orm import foreign, remote\n\n    class HostEntry(Base):\n        __tablename__ = \"host_entry\"\n\n        id = Column(Integer, primary_key=True)\n        ip_address = Column(INET)\n        content = Column(String(50))\n\n        # relationship() using explicit foreign() and remote() annotations\n        # in lieu of separate arguments\n        parent_host = relationship(\n            \"HostEntry\",\n            primaryjoin=remote(ip_address) == cast(foreign(content), INET),\n        )\n    ```", "```py\n>>> class User(Base):\n...     __tablename__ = \"user\"\n...     id = Column(Integer, primary_key=True)\n...     name = Column(String)\n...     name_syn = synonym(name)\n...     addresses = relationship(\"Address\")\n\n>>> # universal entry point is inspect()\n>>> b = inspect(User)\n\n>>> # b in this case is the Mapper\n>>> b\n<Mapper at 0x101521950; User>\n\n>>> # Column namespace\n>>> b.columns.id\nColumn('id', Integer(), table=<user>, primary_key=True, nullable=False)\n\n>>> # mapper's perspective of the primary key\n>>> b.primary_key\n(Column('id', Integer(), table=<user>, primary_key=True, nullable=False),)\n\n>>> # MapperProperties available from .attrs\n>>> b.attrs.keys()\n['name_syn', 'addresses', 'id', 'name']\n\n>>> # .column_attrs, .relationships, etc. filter this collection\n>>> b.column_attrs.keys()\n['id', 'name']\n\n>>> list(b.relationships)\n[<sqlalchemy.orm.properties.RelationshipProperty object at 0x1015212d0>]\n\n>>> # they are also namespaces\n>>> b.column_attrs.id\n<sqlalchemy.orm.properties.ColumnProperty object at 0x101525090>\n\n>>> b.relationships.addresses\n<sqlalchemy.orm.properties.RelationshipProperty object at 0x1015212d0>\n\n>>> # point inspect() at a mapped, class level attribute,\n>>> # returns the attribute itself\n>>> b = inspect(User.addresses)\n>>> b\n<sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x101521fd0>\n\n>>> # From here we can get the mapper:\n>>> b.mapper\n<Mapper at 0x101525810; Address>\n\n>>> # the parent inspector, in this case a mapper\n>>> b.parent\n<Mapper at 0x101521950; User>\n\n>>> # an expression\n>>> print(b.expression)\n\"user\".id  =  address.user_id\n>>> # inspect works on instances\n>>> u1 = User(id=3, name=\"x\")\n>>> b = inspect(u1)\n\n>>> # it returns the InstanceState\n>>> b\n<sqlalchemy.orm.state.InstanceState object at 0x10152bed0>\n\n>>> # similar attrs accessor refers to the\n>>> b.attrs.keys()\n['id', 'name_syn', 'addresses', 'name']\n\n>>> # attribute interface - from attrs, you get a state object\n>>> b.attrs.id\n<sqlalchemy.orm.state.AttributeState object at 0x10152bf90>\n\n>>> # this object can give you, current value...\n>>> b.attrs.id.value\n3\n\n>>> # ... current history\n>>> b.attrs.id.history\nHistory(added=[3], unchanged=(), deleted=())\n\n>>> # InstanceState can also provide session state information\n>>> # lets assume the object is persistent\n>>> s = Session()\n>>> s.add(u1)\n>>> s.commit()\n\n>>> # now we can get primary key identity, always\n>>> # works in query.get()\n>>> b.identity\n(3,)\n\n>>> # the mapper level key\n>>> b.identity_key\n(<class '__main__.User'>, (3,))\n\n>>> # state within the session\n>>> b.persistent, b.transient, b.deleted, b.detached\n(True, False, False, False)\n\n>>> # owning session\n>>> b.session\n<sqlalchemy.orm.session.Session object at 0x101701150>\n```", "```py\nfrom sqlalchemy.orm import with_polymorphic\n\npalias = with_polymorphic(Person, [Engineer, Manager])\nsession.query(Company).join(palias, Company.employees).filter(\n    or_(Engineer.language == \"java\", Manager.hair == \"pointy\")\n)\n```", "```py\n# use eager loading in conjunction with with_polymorphic targets\nJob_P = with_polymorphic(Job, [SubJob, ExtraJob], aliased=True)\nq = (\n    s.query(DataContainer)\n    .join(DataContainer.jobs.of_type(Job_P))\n    .options(contains_eager(DataContainer.jobs.of_type(Job_P)))\n)\n```", "```py\n# use eager loading in conjunction with with_polymorphic targets\nJob_P = with_polymorphic(Job, [SubJob, ExtraJob], aliased=True)\nq = (\n    s.query(DataContainer)\n    .join(DataContainer.jobs.of_type(Job_P))\n    .options(contains_eager(DataContainer.jobs.of_type(Job_P)))\n)\n\n# pass subclasses to eager loads (implicitly applies with_polymorphic)\nq = s.query(ParentThing).options(\n    joinedload_all(ParentThing.container, DataContainer.jobs.of_type(SubJob))\n)\n\n# control self-referential aliasing with any()/has()\nJob_A = aliased(Job)\nq = (\n    s.query(Job)\n    .join(DataContainer.jobs)\n    .filter(\n        DataContainer.jobs.of_type(Job_A).any(\n            and_(Job_A.id < Job.id, Job_A.type == \"fred\")\n        )\n    )\n)\n```", "```py\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\n@event.listens_for(\"load\", Base, propagate=True)\ndef on_load(target, context):\n    print(\"New instance loaded:\", target)\n\n# on_load() will be applied to SomeClass\nclass SomeClass(Base):\n    __tablename__ = \"sometable\"\n\n    # ...\n```", "```py\nclass Snack(Base):\n    # ...\n\n    peanuts = relationship(\n        \"nuts.Peanut\", primaryjoin=\"nuts.Peanut.snack_id == Snack.id\"\n    )\n```", "```py\nclass ReflectedOne(DeferredReflection, Base):\n    __abstract__ = True\n\nclass ReflectedTwo(DeferredReflection, Base):\n    __abstract__ = True\n\nclass MyClass(ReflectedOne):\n    __tablename__ = \"mytable\"\n\nclass MyOtherClass(ReflectedOne):\n    __tablename__ = \"myothertable\"\n\nclass YetAnotherClass(ReflectedTwo):\n    __tablename__ = \"yetanothertable\"\n\nReflectedOne.prepare(engine_one)\nReflectedTwo.prepare(engine_two)\n```", "```py\nfrom sqlalchemy import select\n\nstmt = select([User]).where(User.id == 5)\n```", "```py\nquery(SomeEntity).filter(SomeEntity.id == SomeOtherEntity.id).filter(\n    SomeOtherEntity.foo == \"bar\"\n).update({\"data\": \"x\"})\n```", "```py\nquery(Engineer).filter(Person.id == Engineer.id).filter(\n    Person.name == \"dilbert\"\n).update({\"engineer_data\": \"java\"})\n```", "```py\nUPDATE  engineer  SET  engineer_data='java'  FROM  person\nWHERE  person.id=engineer.id  AND  person.name='dilbert'\n```", "```py\n--- examples/beaker_caching/caching_query.py\n+++ examples/beaker_caching/caching_query.py\n@@ -222,7 +222,8 @@\n\n         \"\"\"\n         if query._current_path:\n-            mapper, key = query._current_path[-2:]\n+            mapper, prop = query._current_path[-2:]\n+            key = prop.key\n\n             for cls in mapper.class_.__mro__:\n                 if (cls, key) in self._relationship_options:\n```", "```py\n    class Parent(Base):\n        __tablename__ = \"parent\"\n        id = Column(Integer, primary_key=True)\n        child_id_one = Column(Integer, ForeignKey(\"child.id\"))\n        child_id_two = Column(Integer, ForeignKey(\"child.id\"))\n\n        child_one = relationship(\"Child\", foreign_keys=child_id_one)\n        child_two = relationship(\"Child\", foreign_keys=child_id_two)\n\n    class Child(Base):\n        __tablename__ = \"child\"\n        id = Column(Integer, primary_key=True)\n    ```", "```py\n    class Folder(Base):\n        __tablename__ = \"folder\"\n        __table_args__ = (\n            ForeignKeyConstraint(\n                [\"account_id\", \"parent_id\"], [\"folder.account_id\", \"folder.folder_id\"]\n            ),\n        )\n\n        account_id = Column(Integer, primary_key=True)\n        folder_id = Column(Integer, primary_key=True)\n        parent_id = Column(Integer)\n        name = Column(String)\n\n        parent_folder = relationship(\n            \"Folder\", backref=\"child_folders\", remote_side=[account_id, folder_id]\n        )\n    ```", "```py\n    SELECT\n      folder.account_id  AS  folder_account_id,\n      folder.folder_id  AS  folder_folder_id,\n      folder.parent_id  AS  folder_parent_id,\n      folder.name  AS  folder_name,\n      folder_1.account_id  AS  folder_1_account_id,\n      folder_1.folder_id  AS  folder_1_folder_id,\n      folder_1.parent_id  AS  folder_1_parent_id,\n      folder_1.name  AS  folder_1_name\n    FROM  folder\n      LEFT  OUTER  JOIN  folder  AS  folder_1\n      ON\n      folder_1.account_id  =  folder.account_id\n      AND  folder.folder_id  =  folder_1.parent_id\n\n    WHERE  folder.folder_id  =  ?  AND  folder.account_id  =  ?\n    ```", "```py\n    class HostEntry(Base):\n        __tablename__ = \"host_entry\"\n\n        id = Column(Integer, primary_key=True)\n        ip_address = Column(INET)\n        content = Column(String(50))\n\n        # relationship() using explicit foreign_keys, remote_side\n        parent_host = relationship(\n            \"HostEntry\",\n            primaryjoin=ip_address == cast(content, INET),\n            foreign_keys=content,\n            remote_side=ip_address,\n        )\n    ```", "```py\n    from sqlalchemy.orm import foreign, remote\n\n    class HostEntry(Base):\n        __tablename__ = \"host_entry\"\n\n        id = Column(Integer, primary_key=True)\n        ip_address = Column(INET)\n        content = Column(String(50))\n\n        # relationship() using explicit foreign() and remote() annotations\n        # in lieu of separate arguments\n        parent_host = relationship(\n            \"HostEntry\",\n            primaryjoin=remote(ip_address) == cast(foreign(content), INET),\n        )\n    ```", "```py\n>>> class User(Base):\n...     __tablename__ = \"user\"\n...     id = Column(Integer, primary_key=True)\n...     name = Column(String)\n...     name_syn = synonym(name)\n...     addresses = relationship(\"Address\")\n\n>>> # universal entry point is inspect()\n>>> b = inspect(User)\n\n>>> # b in this case is the Mapper\n>>> b\n<Mapper at 0x101521950; User>\n\n>>> # Column namespace\n>>> b.columns.id\nColumn('id', Integer(), table=<user>, primary_key=True, nullable=False)\n\n>>> # mapper's perspective of the primary key\n>>> b.primary_key\n(Column('id', Integer(), table=<user>, primary_key=True, nullable=False),)\n\n>>> # MapperProperties available from .attrs\n>>> b.attrs.keys()\n['name_syn', 'addresses', 'id', 'name']\n\n>>> # .column_attrs, .relationships, etc. filter this collection\n>>> b.column_attrs.keys()\n['id', 'name']\n\n>>> list(b.relationships)\n[<sqlalchemy.orm.properties.RelationshipProperty object at 0x1015212d0>]\n\n>>> # they are also namespaces\n>>> b.column_attrs.id\n<sqlalchemy.orm.properties.ColumnProperty object at 0x101525090>\n\n>>> b.relationships.addresses\n<sqlalchemy.orm.properties.RelationshipProperty object at 0x1015212d0>\n\n>>> # point inspect() at a mapped, class level attribute,\n>>> # returns the attribute itself\n>>> b = inspect(User.addresses)\n>>> b\n<sqlalchemy.orm.attributes.InstrumentedAttribute object at 0x101521fd0>\n\n>>> # From here we can get the mapper:\n>>> b.mapper\n<Mapper at 0x101525810; Address>\n\n>>> # the parent inspector, in this case a mapper\n>>> b.parent\n<Mapper at 0x101521950; User>\n\n>>> # an expression\n>>> print(b.expression)\n\"user\".id  =  address.user_id\n>>> # inspect works on instances\n>>> u1 = User(id=3, name=\"x\")\n>>> b = inspect(u1)\n\n>>> # it returns the InstanceState\n>>> b\n<sqlalchemy.orm.state.InstanceState object at 0x10152bed0>\n\n>>> # similar attrs accessor refers to the\n>>> b.attrs.keys()\n['id', 'name_syn', 'addresses', 'name']\n\n>>> # attribute interface - from attrs, you get a state object\n>>> b.attrs.id\n<sqlalchemy.orm.state.AttributeState object at 0x10152bf90>\n\n>>> # this object can give you, current value...\n>>> b.attrs.id.value\n3\n\n>>> # ... current history\n>>> b.attrs.id.history\nHistory(added=[3], unchanged=(), deleted=())\n\n>>> # InstanceState can also provide session state information\n>>> # lets assume the object is persistent\n>>> s = Session()\n>>> s.add(u1)\n>>> s.commit()\n\n>>> # now we can get primary key identity, always\n>>> # works in query.get()\n>>> b.identity\n(3,)\n\n>>> # the mapper level key\n>>> b.identity_key\n(<class '__main__.User'>, (3,))\n\n>>> # state within the session\n>>> b.persistent, b.transient, b.deleted, b.detached\n(True, False, False, False)\n\n>>> # owning session\n>>> b.session\n<sqlalchemy.orm.session.Session object at 0x101701150>\n```", "```py\nfrom sqlalchemy.orm import with_polymorphic\n\npalias = with_polymorphic(Person, [Engineer, Manager])\nsession.query(Company).join(palias, Company.employees).filter(\n    or_(Engineer.language == \"java\", Manager.hair == \"pointy\")\n)\n```", "```py\n# use eager loading in conjunction with with_polymorphic targets\nJob_P = with_polymorphic(Job, [SubJob, ExtraJob], aliased=True)\nq = (\n    s.query(DataContainer)\n    .join(DataContainer.jobs.of_type(Job_P))\n    .options(contains_eager(DataContainer.jobs.of_type(Job_P)))\n)\n```", "```py\n# use eager loading in conjunction with with_polymorphic targets\nJob_P = with_polymorphic(Job, [SubJob, ExtraJob], aliased=True)\nq = (\n    s.query(DataContainer)\n    .join(DataContainer.jobs.of_type(Job_P))\n    .options(contains_eager(DataContainer.jobs.of_type(Job_P)))\n)\n\n# pass subclasses to eager loads (implicitly applies with_polymorphic)\nq = s.query(ParentThing).options(\n    joinedload_all(ParentThing.container, DataContainer.jobs.of_type(SubJob))\n)\n\n# control self-referential aliasing with any()/has()\nJob_A = aliased(Job)\nq = (\n    s.query(Job)\n    .join(DataContainer.jobs)\n    .filter(\n        DataContainer.jobs.of_type(Job_A).any(\n            and_(Job_A.id < Job.id, Job_A.type == \"fred\")\n        )\n    )\n)\n```", "```py\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\n@event.listens_for(\"load\", Base, propagate=True)\ndef on_load(target, context):\n    print(\"New instance loaded:\", target)\n\n# on_load() will be applied to SomeClass\nclass SomeClass(Base):\n    __tablename__ = \"sometable\"\n\n    # ...\n```", "```py\nclass Snack(Base):\n    # ...\n\n    peanuts = relationship(\n        \"nuts.Peanut\", primaryjoin=\"nuts.Peanut.snack_id == Snack.id\"\n    )\n```", "```py\nclass ReflectedOne(DeferredReflection, Base):\n    __abstract__ = True\n\nclass ReflectedTwo(DeferredReflection, Base):\n    __abstract__ = True\n\nclass MyClass(ReflectedOne):\n    __tablename__ = \"mytable\"\n\nclass MyOtherClass(ReflectedOne):\n    __tablename__ = \"myothertable\"\n\nclass YetAnotherClass(ReflectedTwo):\n    __tablename__ = \"yetanothertable\"\n\nReflectedOne.prepare(engine_one)\nReflectedTwo.prepare(engine_two)\n```", "```py\nfrom sqlalchemy import select\n\nstmt = select([User]).where(User.id == 5)\n```", "```py\nquery(SomeEntity).filter(SomeEntity.id == SomeOtherEntity.id).filter(\n    SomeOtherEntity.foo == \"bar\"\n).update({\"data\": \"x\"})\n```", "```py\nquery(Engineer).filter(Person.id == Engineer.id).filter(\n    Person.name == \"dilbert\"\n).update({\"engineer_data\": \"java\"})\n```", "```py\nUPDATE  engineer  SET  engineer_data='java'  FROM  person\nWHERE  person.id=engineer.id  AND  person.name='dilbert'\n```", "```py\n--- examples/beaker_caching/caching_query.py\n+++ examples/beaker_caching/caching_query.py\n@@ -222,7 +222,8 @@\n\n         \"\"\"\n         if query._current_path:\n-            mapper, key = query._current_path[-2:]\n+            mapper, prop = query._current_path[-2:]\n+            key = prop.key\n\n             for cls in mapper.class_.__mro__:\n                 if (cls, key) in self._relationship_options:\n```", "```py\nfrom sqlalchemy.types import Numeric\nfrom sqlalchemy.sql import func\n\nclass CustomNumeric(Numeric):\n    class comparator_factory(Numeric.Comparator):\n        def log(self, other):\n            return func.log(self.expr, other)\n```", "```py\ndata = Table(\n    \"data\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"x\", CustomNumeric(10, 5)),\n    Column(\"y\", CustomNumeric(10, 5)),\n)\n\nstmt = select([data.c.x.log(data.c.y)]).where(data.c.x.log(2) < value)\nprint(conn.execute(stmt).fetchall())\n```", "```py\nusers.insert().values(\n    [\n        {\"name\": \"some name\"},\n        {\"name\": \"some other name\"},\n        {\"name\": \"yet another name\"},\n    ]\n)\n```", "```py\nfrom sqlalchemy.types import String\nfrom sqlalchemy import func, Table, Column, MetaData\n\nclass LowerString(String):\n    def bind_expression(self, bindvalue):\n        return func.lower(bindvalue)\n\n    def column_expression(self, col):\n        return func.lower(col)\n\nmetadata = MetaData()\ntest_table = Table(\"test_table\", metadata, Column(\"data\", LowerString))\n```", "```py\n>>> print(select([test_table]).where(test_table.c.data == \"HI\"))\nSELECT  lower(test_table.data)  AS  data\nFROM  test_table\nWHERE  test_table.data  =  lower(:data_1) \n```", "```py\nfrom sqlalchemy import inspect\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"postgresql://scott:tiger@localhost/test\")\ninsp = inspect(engine)\nprint(insp.get_table_names())\n```", "```py\nclass SnortEvent(Base):\n    __tablename__ = \"event\"\n\n    id = Column(Integer, primary_key=True)\n    signature = Column(Integer, ForeignKey(\"signature.id\"))\n\n    signatures = relationship(\"Signature\", lazy=False)\n\nclass Signature(Base):\n    __tablename__ = \"signature\"\n\n    id = Column(Integer, primary_key=True)\n\n    sig_count = column_property(\n        select([func.count(\"*\")])\n        .where(SnortEvent.signature == id)\n        .correlate_except(SnortEvent)\n    )\n```", "```py\nfrom sqlalchemy.dialects.postgresql import HSTORE\n\ndata = Table(\n    \"data_table\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"hstore_data\", HSTORE),\n)\n\nengine.execute(select([data.c.hstore_data[\"some_key\"]])).scalar()\n\nengine.execute(select([data.c.hstore_data.matrix()])).scalar()\n```", "```py\n# old way, still works since PG supports N-dimensions per row:\nColumn(\"my_array\", postgresql.ARRAY(Integer))\n\n# new way, will render ARRAY with correct number of [] in DDL,\n# will process binds and results more efficiently as we don't need\n# to guess how many levels deep to go\nColumn(\"my_array\", postgresql.ARRAY(Integer, dimensions=2))\n```", "```py\nresult = conn.execute(select([mytable.c.arraycol[2]]))\n```", "```py\nresult = conn.execute(select([mytable.c.arraycol[2:4]]))\n```", "```py\nconn.execute(mytable.update().values({mytable.c.arraycol[2:3]: [7, 8]}))\n```", "```py\n>>> from sqlalchemy.dialects import postgresql\n>>> conn.scalar(select([postgresql.array([1, 2]) + postgresql.array([3, 4, 5])]))\n[1, 2, 3, 4, 5]\n```", "```py\nselect([mytable.c.arraycol + [4, 5, 6]])\n```", "```py\nColumn(\"sometimestamp\", sqlite.DATETIME(truncate_microseconds=True))\nColumn(\n    \"sometimestamp\",\n    sqlite.DATETIME(\n        storage_format=(\n            \"%(year)04d%(month)02d%(day)02d\"\n            \"%(hour)02d%(minute)02d%(second)02d%(microsecond)06d\"\n        ),\n        regexp=\"(\\d{4})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{6})\",\n    ),\n)\nColumn(\n    \"somedate\",\n    sqlite.DATE(\n        storage_format=\"%(month)02d/%(day)02d/%(year)04d\",\n        regexp=\"(?P<month>\\d+)/(?P<day>\\d+)/(?P<year>\\d+)\",\n    ),\n)\n```", "```py\n>>> stmt = select([cast(sometable.c.somechar, String(20, collation=\"utf8\"))])\n>>> print(stmt)\nSELECT  CAST(sometable.somechar  AS  VARCHAR(20)  COLLATE  \"utf8\")  AS  anon_1\nFROM  sometable \n```", "```py\nstmt = table.delete().prefix_with(\"LOW_PRIORITY\", dialect=\"mysql\")\n\nstmt = table.update().prefix_with(\"LOW_PRIORITY\", dialect=\"mysql\")\n```", "```py\nfrom sqlalchemy.types import Numeric\nfrom sqlalchemy.sql import func\n\nclass CustomNumeric(Numeric):\n    class comparator_factory(Numeric.Comparator):\n        def log(self, other):\n            return func.log(self.expr, other)\n```", "```py\ndata = Table(\n    \"data\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"x\", CustomNumeric(10, 5)),\n    Column(\"y\", CustomNumeric(10, 5)),\n)\n\nstmt = select([data.c.x.log(data.c.y)]).where(data.c.x.log(2) < value)\nprint(conn.execute(stmt).fetchall())\n```", "```py\nusers.insert().values(\n    [\n        {\"name\": \"some name\"},\n        {\"name\": \"some other name\"},\n        {\"name\": \"yet another name\"},\n    ]\n)\n```", "```py\nfrom sqlalchemy.types import String\nfrom sqlalchemy import func, Table, Column, MetaData\n\nclass LowerString(String):\n    def bind_expression(self, bindvalue):\n        return func.lower(bindvalue)\n\n    def column_expression(self, col):\n        return func.lower(col)\n\nmetadata = MetaData()\ntest_table = Table(\"test_table\", metadata, Column(\"data\", LowerString))\n```", "```py\n>>> print(select([test_table]).where(test_table.c.data == \"HI\"))\nSELECT  lower(test_table.data)  AS  data\nFROM  test_table\nWHERE  test_table.data  =  lower(:data_1) \n```", "```py\nfrom sqlalchemy import inspect\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"postgresql://scott:tiger@localhost/test\")\ninsp = inspect(engine)\nprint(insp.get_table_names())\n```", "```py\nclass SnortEvent(Base):\n    __tablename__ = \"event\"\n\n    id = Column(Integer, primary_key=True)\n    signature = Column(Integer, ForeignKey(\"signature.id\"))\n\n    signatures = relationship(\"Signature\", lazy=False)\n\nclass Signature(Base):\n    __tablename__ = \"signature\"\n\n    id = Column(Integer, primary_key=True)\n\n    sig_count = column_property(\n        select([func.count(\"*\")])\n        .where(SnortEvent.signature == id)\n        .correlate_except(SnortEvent)\n    )\n```", "```py\nfrom sqlalchemy.dialects.postgresql import HSTORE\n\ndata = Table(\n    \"data_table\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True),\n    Column(\"hstore_data\", HSTORE),\n)\n\nengine.execute(select([data.c.hstore_data[\"some_key\"]])).scalar()\n\nengine.execute(select([data.c.hstore_data.matrix()])).scalar()\n```", "```py\n# old way, still works since PG supports N-dimensions per row:\nColumn(\"my_array\", postgresql.ARRAY(Integer))\n\n# new way, will render ARRAY with correct number of [] in DDL,\n# will process binds and results more efficiently as we don't need\n# to guess how many levels deep to go\nColumn(\"my_array\", postgresql.ARRAY(Integer, dimensions=2))\n```", "```py\nresult = conn.execute(select([mytable.c.arraycol[2]]))\n```", "```py\nresult = conn.execute(select([mytable.c.arraycol[2:4]]))\n```", "```py\nconn.execute(mytable.update().values({mytable.c.arraycol[2:3]: [7, 8]}))\n```", "```py\n>>> from sqlalchemy.dialects import postgresql\n>>> conn.scalar(select([postgresql.array([1, 2]) + postgresql.array([3, 4, 5])]))\n[1, 2, 3, 4, 5]\n```", "```py\nselect([mytable.c.arraycol + [4, 5, 6]])\n```", "```py\nColumn(\"sometimestamp\", sqlite.DATETIME(truncate_microseconds=True))\nColumn(\n    \"sometimestamp\",\n    sqlite.DATETIME(\n        storage_format=(\n            \"%(year)04d%(month)02d%(day)02d\"\n            \"%(hour)02d%(minute)02d%(second)02d%(microsecond)06d\"\n        ),\n        regexp=\"(\\d{4})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{6})\",\n    ),\n)\nColumn(\n    \"somedate\",\n    sqlite.DATE(\n        storage_format=\"%(month)02d/%(day)02d/%(year)04d\",\n        regexp=\"(?P<month>\\d+)/(?P<day>\\d+)/(?P<year>\\d+)\",\n    ),\n)\n```", "```py\n>>> stmt = select([cast(sometable.c.somechar, String(20, collation=\"utf8\"))])\n>>> print(stmt)\nSELECT  CAST(sometable.somechar  AS  VARCHAR(20)  COLLATE  \"utf8\")  AS  anon_1\nFROM  sometable \n```", "```py\nstmt = table.delete().prefix_with(\"LOW_PRIORITY\", dialect=\"mysql\")\n\nstmt = table.update().prefix_with(\"LOW_PRIORITY\", dialect=\"mysql\")\n```", "```py\nfrom sqlalchemy import Column, Integer, String, ForeignKey\nfrom sqlalchemy.orm import relationship, backref\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = \"user\"\n    id = Column(Integer, primary_key=True)\n    name = Column(String(64))\n\nclass UserKeyword(Base):\n    __tablename__ = \"user_keyword\"\n    user_id = Column(Integer, ForeignKey(\"user.id\"), primary_key=True)\n    keyword_id = Column(Integer, ForeignKey(\"keyword.id\"), primary_key=True)\n\n    user = relationship(\n        User, backref=backref(\"user_keywords\", cascade=\"all, delete-orphan\")\n    )\n\n    keyword = relationship(\n        \"Keyword\", backref=backref(\"user_keywords\", cascade=\"all, delete-orphan\")\n    )\n\n    # uncomment this to enable the old behavior\n    # __mapper_args__ = {\"legacy_is_orphan\": True}\n\nclass Keyword(Base):\n    __tablename__ = \"keyword\"\n    id = Column(Integer, primary_key=True)\n    keyword = Column(\"keyword\", String(64))\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import Session\n\n# note we're using PostgreSQL to ensure that referential integrity\n# is enforced, for demonstration purposes.\ne = create_engine(\"postgresql://scott:tiger@localhost/test\", echo=True)\n\nBase.metadata.drop_all(e)\nBase.metadata.create_all(e)\n\nsession = Session(e)\n\nu1 = User(name=\"u1\")\nk1 = Keyword(keyword=\"k1\")\n\nsession.add_all([u1, k1])\n\nuk1 = UserKeyword(keyword=k1, user=u1)\n\n# previously, if session.flush() were called here,\n# this operation would succeed, but if session.flush()\n# were not called here, the operation fails with an\n# integrity error.\n# session.flush()\ndel u1.user_keywords[0]\n\nsession.commit()\n```", "```py\n@event.listens_for(Session, \"after_attach\")\ndef after_attach(session, instance):\n    assert instance in session\n```", "```py\n@event.listens_for(Session, \"before_attach\")\ndef before_attach(session, instance):\n    instance.some_necessary_attribute = (\n        session.query(Widget).filter_by(instance.widget_name).first()\n    )\n```", "```py\nsubq = (\n    session.query(Entity.value)\n    .filter(Entity.id == Parent.entity_id)\n    .correlate(Parent)\n    .as_scalar()\n)\nsession.query(Parent).filter(subq == \"some value\")\n```", "```py\nsubq = session.query(Entity.value).filter(Entity.id == Parent.entity_id).as_scalar()\nsession.query(Parent).filter(subq == \"some value\")\n```", "```py\nfrom sqlalchemy.sql import table, column, select\n\nt1 = table(\"t1\", column(\"x\"))\nt2 = table(\"t2\", column(\"y\"))\ns = select([t1, t2]).correlate(t1)\n\nprint(s)\n```", "```py\nSELECT  t1.x,  t2.y  FROM  t2\n```", "```py\nSELECT  t1.x,  t2.y  FROM  t1,  t2\n```", "```py\ns2 = select([t1, t2]).where(t1.c.x == t2.c.y).where(t1.c.x == s)\nprint(s2)\n```", "```py\nSELECT  t1.x,  t2.y  FROM  t1,  t2\nWHERE  t1.x  =  t2.y  AND  t1.x  =\n  (SELECT  t1.x,  t2.y  FROM  t2)\n```", "```py\nscalar_subq = select([someothertable.c.id]).where(someothertable.c.data == \"foo\")\nselect([sometable]).where(sometable.c.id == scalar_subq)\n```", "```py\ns = select([table1]).apply_labels()\ns.c.table1_col1\ns.c.table1_col2\n```", "```py\n# before 0.8\ntable1 = Table(\"t1\", metadata, Column(\"col1\", Integer, key=\"column_one\"))\ns = select([table1])\ns.c.column_one  # would be accessible like this\ns.c.col1  # would raise AttributeError\n\ns = select([table1]).apply_labels()\ns.c.table1_column_one  # would raise AttributeError\ns.c.table1_col1  # would be accessible like this\n```", "```py\n# with 0.8\ntable1 = Table(\"t1\", metadata, Column(\"col1\", Integer, key=\"column_one\"))\ns = select([table1])\ns.c.column_one  # works\ns.c.col1  # AttributeError\n\ns = select([table1]).apply_labels()\ns.c.table1_column_one  # works\ns.c.table1_col1  # AttributeError\n```", "```py\n@event.listens_for(Table, \"column_reflect\")\ndef listen_for_col(inspector, table, column_info): ...\n```", "```py\nt1 = table(\"t1\", column(\"x\"))\nt1.insert().values(x=5, z=5)  # raises \"Unconsumed column names: z\"\n```", "```py\n>>> insp.get_primary_keys()\n[\"a\", \"b\"]\n\n>>> insp.get_pk_constraint()\n{\"name\":\"pk_constraint\", \"constrained_columns\":[\"a\", \"b\"]}\n```", "```py\n>>> row = result.fetchone()\n>>> row[\"foo\"] == row[\"FOO\"] == row[\"Foo\"]\nTrue\n```", "```py\nfrom sqlalchemy import Column, Integer, String, ForeignKey\nfrom sqlalchemy.orm import relationship, backref\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = \"user\"\n    id = Column(Integer, primary_key=True)\n    name = Column(String(64))\n\nclass UserKeyword(Base):\n    __tablename__ = \"user_keyword\"\n    user_id = Column(Integer, ForeignKey(\"user.id\"), primary_key=True)\n    keyword_id = Column(Integer, ForeignKey(\"keyword.id\"), primary_key=True)\n\n    user = relationship(\n        User, backref=backref(\"user_keywords\", cascade=\"all, delete-orphan\")\n    )\n\n    keyword = relationship(\n        \"Keyword\", backref=backref(\"user_keywords\", cascade=\"all, delete-orphan\")\n    )\n\n    # uncomment this to enable the old behavior\n    # __mapper_args__ = {\"legacy_is_orphan\": True}\n\nclass Keyword(Base):\n    __tablename__ = \"keyword\"\n    id = Column(Integer, primary_key=True)\n    keyword = Column(\"keyword\", String(64))\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import Session\n\n# note we're using PostgreSQL to ensure that referential integrity\n# is enforced, for demonstration purposes.\ne = create_engine(\"postgresql://scott:tiger@localhost/test\", echo=True)\n\nBase.metadata.drop_all(e)\nBase.metadata.create_all(e)\n\nsession = Session(e)\n\nu1 = User(name=\"u1\")\nk1 = Keyword(keyword=\"k1\")\n\nsession.add_all([u1, k1])\n\nuk1 = UserKeyword(keyword=k1, user=u1)\n\n# previously, if session.flush() were called here,\n# this operation would succeed, but if session.flush()\n# were not called here, the operation fails with an\n# integrity error.\n# session.flush()\ndel u1.user_keywords[0]\n\nsession.commit()\n```", "```py\n@event.listens_for(Session, \"after_attach\")\ndef after_attach(session, instance):\n    assert instance in session\n```", "```py\n@event.listens_for(Session, \"before_attach\")\ndef before_attach(session, instance):\n    instance.some_necessary_attribute = (\n        session.query(Widget).filter_by(instance.widget_name).first()\n    )\n```", "```py\nsubq = (\n    session.query(Entity.value)\n    .filter(Entity.id == Parent.entity_id)\n    .correlate(Parent)\n    .as_scalar()\n)\nsession.query(Parent).filter(subq == \"some value\")\n```", "```py\nsubq = session.query(Entity.value).filter(Entity.id == Parent.entity_id).as_scalar()\nsession.query(Parent).filter(subq == \"some value\")\n```", "```py\nfrom sqlalchemy.sql import table, column, select\n\nt1 = table(\"t1\", column(\"x\"))\nt2 = table(\"t2\", column(\"y\"))\ns = select([t1, t2]).correlate(t1)\n\nprint(s)\n```", "```py\nSELECT  t1.x,  t2.y  FROM  t2\n```", "```py\nSELECT  t1.x,  t2.y  FROM  t1,  t2\n```", "```py\ns2 = select([t1, t2]).where(t1.c.x == t2.c.y).where(t1.c.x == s)\nprint(s2)\n```", "```py\nSELECT  t1.x,  t2.y  FROM  t1,  t2\nWHERE  t1.x  =  t2.y  AND  t1.x  =\n  (SELECT  t1.x,  t2.y  FROM  t2)\n```", "```py\nscalar_subq = select([someothertable.c.id]).where(someothertable.c.data == \"foo\")\nselect([sometable]).where(sometable.c.id == scalar_subq)\n```", "```py\ns = select([table1]).apply_labels()\ns.c.table1_col1\ns.c.table1_col2\n```", "```py\n# before 0.8\ntable1 = Table(\"t1\", metadata, Column(\"col1\", Integer, key=\"column_one\"))\ns = select([table1])\ns.c.column_one  # would be accessible like this\ns.c.col1  # would raise AttributeError\n\ns = select([table1]).apply_labels()\ns.c.table1_column_one  # would raise AttributeError\ns.c.table1_col1  # would be accessible like this\n```", "```py\n# with 0.8\ntable1 = Table(\"t1\", metadata, Column(\"col1\", Integer, key=\"column_one\"))\ns = select([table1])\ns.c.column_one  # works\ns.c.col1  # AttributeError\n\ns = select([table1]).apply_labels()\ns.c.table1_column_one  # works\ns.c.table1_col1  # AttributeError\n```", "```py\n@event.listens_for(Table, \"column_reflect\")\ndef listen_for_col(inspector, table, column_info): ...\n```", "```py\nt1 = table(\"t1\", column(\"x\"))\nt1.insert().values(x=5, z=5)  # raises \"Unconsumed column names: z\"\n```", "```py\n>>> insp.get_primary_keys()\n[\"a\", \"b\"]\n\n>>> insp.get_pk_constraint()\n{\"name\":\"pk_constraint\", \"constrained_columns\":[\"a\", \"b\"]}\n```", "```py\n>>> row = result.fetchone()\n>>> row[\"foo\"] == row[\"FOO\"] == row[\"Foo\"]\nTrue\n```"]