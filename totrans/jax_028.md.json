["```py\nimport jax\n\n@jax.jit\ndef f(x):\n  y = x + 1\n  print(\"intermediate value: {}\".format(y))\n  return y * 2\n\nresult = f(2) \n```", "```py\nintermediate value: Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=1/0)> \n```", "```py\n@jax.jit\ndef f(x):\n  y = x + 1\n  jax.debug.print(\"intermediate value: {}\", y)\n  return y * 2\n\nresult = f(2) \n```", "```py\nintermediate value: 3 \n```", "```py\nimport jax\nimport jax.numpy as jnp\nimport numpy as np\n\ndef f_host(x):\n  # call a numpy (not jax.numpy) operation:\n  return np.sin(x).astype(x.dtype)\n\ndef f(x):\n  result_shape = jax.ShapeDtypeStruct(x.shape, x.dtype)\n  return jax.pure_callback(f_host, result_shape, x)\n\nx = jnp.arange(5.0)\nf(x) \n```", "```py\nArray([ 0\\.       ,  0.841471 ,  0.9092974,  0.14112  , -0.7568025],      dtype=float32) \n```", "```py\njax.jit(f)(x) \n```", "```py\nArray([ 0\\.       ,  0.841471 ,  0.9092974,  0.14112  , -0.7568025],      dtype=float32) \n```", "```py\njax.vmap(f)(x) \n```", "```py\nArray([ 0\\.       ,  0.841471 ,  0.9092974,  0.14112  , -0.7568025],      dtype=float32) \n```", "```py\ndef body_fun(_, x):\n  return _, f(x)\njax.lax.scan(body_fun, None, jnp.arange(5.0))[1] \n```", "```py\nArray([ 0\\.       ,  0.841471 ,  0.9092974,  0.14112  , -0.7568025],      dtype=float32) \n```", "```py\n%xmode minimal \n```", "```py\nException reporting mode: Minimal \n```", "```py\njax.grad(f)(x) \n```", "```py\nValueError: Pure callbacks do not support JVP. Please use `jax.custom_jvp` to use callbacks while taking gradients. \n```", "```py\ndef print_something():\n  print('printing something')\n  return np.int32(0)\n\n@jax.jit\ndef f1():\n  return jax.pure_callback(print_something, np.int32(0))\nf1(); \n```", "```py\nprinting something \n```", "```py\n@jax.jit\ndef f2():\n  jax.pure_callback(print_something, np.int32(0))\n  return 1.0\nf2(); \n```", "```py\nfrom jax.experimental import io_callback\nfrom functools import partial\n\nglobal_rng = np.random.default_rng(0)\n\ndef host_side_random_like(x):\n  \"\"\"Generate a random array like x using the global_rng state\"\"\"\n  # We have two side-effects here:\n  # - printing the shape and dtype\n  # - calling global_rng, thus updating its state\n  print(f'generating {x.dtype}{list(x.shape)}')\n  return global_rng.uniform(size=x.shape).astype(x.dtype)\n\n@jax.jit\ndef numpy_random_like(x):\n  return io_callback(host_side_random_like, x, x)\n\nx = jnp.zeros(5)\nnumpy_random_like(x) \n```", "```py\ngenerating float32[5] \n```", "```py\nArray([0.6369617 , 0.26978672, 0.04097353, 0.01652764, 0.8132702 ],      dtype=float32) \n```", "```py\njax.vmap(numpy_random_like)(x) \n```", "```py\ngenerating float32[]\ngenerating float32[]\ngenerating float32[]\ngenerating float32[]\ngenerating float32[] \n```", "```py\nArray([0.91275555, 0.60663575, 0.72949654, 0.543625  , 0.9350724 ],      dtype=float32) \n```", "```py\n@jax.jit\ndef numpy_random_like_ordered(x):\n  return io_callback(host_side_random_like, x, x, ordered=True)\n\njax.vmap(numpy_random_like_ordered)(x) \n```", "```py\nJaxStackTraceBeforeTransformation: ValueError: Cannot `vmap` ordered IO callback.\n\nThe preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n\n--------------------\n\nThe above exception was the direct cause of the following exception:\n\nValueError: Cannot `vmap` ordered IO callback. \n```", "```py\ndef body_fun(_, x):\n  return _, numpy_random_like_ordered(x)\njax.lax.scan(body_fun, None, jnp.arange(5.0))[1] \n```", "```py\ngenerating float32[]\ngenerating float32[]\ngenerating float32[]\ngenerating float32[]\ngenerating float32[] \n```", "```py\nArray([0.81585354, 0.0027385 , 0.8574043 , 0.03358557, 0.72965544],      dtype=float32) \n```", "```py\njax.grad(numpy_random_like)(x) \n```", "```py\nJaxStackTraceBeforeTransformation: ValueError: IO callbacks do not support JVP.\n\nThe preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n\n--------------------\n\nThe above exception was the direct cause of the following exception:\n\nValueError: IO callbacks do not support JVP. \n```", "```py\n@jax.jit\ndef f(x):\n  io_callback(lambda: print('hello'), None)\n  return x\n\njax.grad(f)(1.0); \n```", "```py\nhello \n```", "```py\nfrom jax import debug\n\ndef log_value(x):\n  # This could be an actual logging call; we'll use\n  # print() for demonstration\n  print(\"log:\", x)\n\n@jax.jit\ndef f(x):\n  debug.callback(log_value, x)\n  return x\n\nf(1.0); \n```", "```py\nlog: 1.0 \n```", "```py\nx = jnp.arange(5.0)\njax.vmap(f)(x); \n```", "```py\nlog: 0.0\nlog: 1.0\nlog: 2.0\nlog: 3.0\nlog: 4.0 \n```", "```py\njax.grad(f)(1.0); \n```", "```py\nlog: 1.0 \n```", "```py\nimport jax\nimport jax.numpy as jnp\nimport scipy.special\n\ndef jv(v, z):\n  v, z = jnp.asarray(v), jnp.asarray(z)\n\n  # Require the order v to be integer type: this simplifies\n  # the JVP rule below.\n  assert jnp.issubdtype(v.dtype, jnp.integer)\n\n  # Promote the input to inexact (float/complex).\n  # Note that jnp.result_type() accounts for the enable_x64 flag.\n  z = z.astype(jnp.result_type(float, z.dtype))\n\n  # Wrap scipy function to return the expected dtype.\n  _scipy_jv = lambda v, z: scipy.special.jv(v, z).astype(z.dtype)\n\n  # Define the expected shape & dtype of output.\n  result_shape_dtype = jax.ShapeDtypeStruct(\n      shape=jnp.broadcast_shapes(v.shape, z.shape),\n      dtype=z.dtype)\n\n  # We use vectorize=True because scipy.special.jv handles broadcasted inputs.\n  return jax.pure_callback(_scipy_jv, result_shape_dtype, v, z, vectorized=True) \n```", "```py\nfrom functools import partial\nj1 = partial(jv, 1)\nz = jnp.arange(5.0) \n```", "```py\nprint(j1(z)) \n```", "```py\n[ 0\\.          0.44005057  0.5767248   0.33905897 -0.06604332] \n```", "```py\nprint(jax.jit(j1)(z)) \n```", "```py\n[ 0\\.          0.44005057  0.5767248   0.33905897 -0.06604332] \n```", "```py\nprint(jax.vmap(j1)(z)) \n```", "```py\n[ 0\\.          0.44005057  0.5767248   0.33905897 -0.06604332] \n```", "```py\njax.grad(j1)(z) \n```", "```py\nValueError: Pure callbacks do not support JVP. Please use `jax.custom_jvp` to use callbacks while taking gradients. \n```", "```py\njv = jax.custom_jvp(jv)\n\n@jv.defjvp\ndef _jv_jvp(primals, tangents):\n  v, z = primals\n  _, z_dot = tangents  # Note: v_dot is always 0 because v is integer.\n  jv_minus_1, jv_plus_1 = jv(v - 1, z), jv(v + 1, z)\n  djv_dz = jnp.where(v == 0, -jv_plus_1, 0.5 * (jv_minus_1 - jv_plus_1))\n  return jv(v, z), z_dot * djv_dz \n```", "```py\nj1 = partial(jv, 1)\nprint(jax.grad(j1)(2.0)) \n```", "```py\n-0.06447162 \n```", "```py\njax.hessian(j1)(2.0) \n```", "```py\nArray(-0.4003078, dtype=float32, weak_type=True) \n```"]