- en: Training a Simple Neural Network, with tensorflow/datasets Data Loading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`jax.readthedocs.io/en/latest/notebooks/neural_network_with_tfds_data.html`](https://jax.readthedocs.io/en/latest/notebooks/neural_network_with_tfds_data.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Open in Colab](https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/neural_network_with_tfds_data.ipynb)
    ![Open in Kaggle](https://kaggle.com/kernels/welcome?src=https://github.com/google/jax/blob/main/docs/notebooks/neural_network_with_tfds_data.ipynb)'
  prefs: []
  type: TYPE_IMG
- en: '*Forked from* `neural_network_and_data_loading.ipynb`'
  prefs: []
  type: TYPE_NORMAL
- en: '![JAX](img/5f620f90762a1045911438d68b694265.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s combine everything we showed in the [quickstart](https://jax.readthedocs.io/en/latest/quickstart.html)
    to train a simple neural network. We will first specify and train a simple MLP
    on MNIST using JAX for the computation. We will use `tensorflow/datasets` data
    loading API to load images and labels (because it’s pretty great, and the world
    doesn’t need yet another data loading library :P).
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you can use JAX with any API that is compatible with NumPy to make
    specifying the model a bit more plug-and-play. Here, just for explanatory purposes,
    we won’t use any neural network libraries or special APIs for building our model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Hyperparameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s get a few bookkeeping items out of the way.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Auto-batching predictions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let us first define our prediction function. Note that we’re defining this for
    a *single* image example. We’re going to use JAX’s `vmap` function to automatically
    handle mini-batches, with no performance penalty.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Let’s check that our prediction function only works on single images.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we have all the ingredients we need to define our neural network
    and train it. We’ve built an auto-batched version of `predict`, which we should
    be able to use in a loss function. We should be able to use `grad` to take the
    derivative of the loss with respect to the neural network parameters. Last, we
    should be able to use `jit` to speed up everything.
  prefs: []
  type: TYPE_NORMAL
- en: Utility and loss functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Data Loading with `tensorflow/datasets`
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: JAX is laser-focused on program transformations and accelerator-backed NumPy,
    so we don’t include data loading or munging in the JAX library. There are already
    a lot of great data loaders out there, so let’s just use them instead of reinventing
    anything. We’ll use the `tensorflow/datasets` data loader.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Training Loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ve now used most of the JAX API: `grad` for derivatives, `jit` for speedups
    and `vmap` for auto-vectorization. We used NumPy to specify all of our computation,
    and borrowed the great data loaders from `tensorflow/datasets`, and ran the whole
    thing on the GPU.'
  prefs: []
  type: TYPE_NORMAL
