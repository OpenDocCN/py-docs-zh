- en: Generalized Convolutions in JAX
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`jax.readthedocs.io/en/latest/notebooks/convolutions.html`](https://jax.readthedocs.io/en/latest/notebooks/convolutions.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Open in Colab](https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/convolutions.ipynb)
    ![Open in Kaggle](https://kaggle.com/kernels/welcome?src=https://github.com/google/jax/blob/main/docs/notebooks/convolutions.ipynb)'
  prefs: []
  type: TYPE_IMG
- en: 'JAX provides a number of interfaces to compute convolutions across data, including:'
  prefs: []
  type: TYPE_NORMAL
- en: '`jax.numpy.convolve()` (also `jax.numpy.correlate()`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jax.scipy.signal.convolve()` (also `correlate()`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jax.scipy.signal.convolve2d()` (also `correlate2d()`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`jax.lax.conv_general_dilated()`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For basic convolution operations, the `jax.numpy` and `jax.scipy` operations
    are usually sufficient. If you want to do more general batched multi-dimensional
    convolution, the `jax.lax` function is where you should start.
  prefs: []
  type: TYPE_NORMAL
- en: Basic One-dimensional Convolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Basic one-dimensional convolution is implemented by `jax.numpy.convolve()`,
    which provides a JAX interface for [`numpy.convolve()`](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html#numpy.convolve
    "(in NumPy v2.0)"). Here is a simple example of 1D smoothing implemented via a
    convolution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/e961d0a0fbc2816ce80591a1da477bbb60ca788cd7033a4fd6553e0369a2dcbf.png](img/f79966682ffcbcb8f10ef6a819cfc5da.png)'
  prefs: []
  type: TYPE_IMG
- en: The `mode` parameter controls how boundary conditions are treated; here we use
    `mode='same'` to ensure that the output is the same size as the input.
  prefs: []
  type: TYPE_NORMAL
- en: For more information, see the `jax.numpy.convolve()` documentation, or the documentation
    associated with the original [`numpy.convolve()`](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html#numpy.convolve
    "(in NumPy v2.0)") function.
  prefs: []
  type: TYPE_NORMAL
- en: Basic N-dimensional Convolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For *N*-dimensional convolution, `jax.scipy.signal.convolve()` provides a similar
    interface to that of `jax.numpy.convolve()`, generalized to *N* dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, here is a simple approach to de-noising an image based on convolution
    with a Gaussian filter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/cfa90156f790ef47f43618a7b4369c686b8a52f253f7f316ccc76360b27b1090.png](img/7d961651756c17c0a99c98f086c5ea09.png)'
  prefs: []
  type: TYPE_IMG
- en: Like in the one-dimensional case, we use `mode='same'` to specify how we would
    like edges to be handled. For more information on available options in *N*-dimensional
    convolutions, see the `jax.scipy.signal.convolve()` documentation.
  prefs: []
  type: TYPE_NORMAL
- en: General Convolutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For the more general types of batched convolutions often useful in the context
    of building deep neural networks, JAX and XLA offer the very general N-dimensional
    **conv_general_dilated** function, but it’s not very obvious how to use it. We’ll
    give some examples of the common use-cases.
  prefs: []
  type: TYPE_NORMAL
- en: A survey of the family of convolutional operators, [a guide to convolutional
    arithmetic](https://arxiv.org/abs/1603.07285), is highly recommended reading!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s define a simple diagonal edge kernel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/c1b68affefa9c6fa409beeda4a0301aba932fec55465efd74fcdffd03f04faa8.png](img/276d4a01c60ff957e05745fcbbf0e1d2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And we’ll make a simple synthetic image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/1ed93c894919df616fdd321a7985a911cc662cb1e021c0951116ab0821b042d2.png](img/5caffdc29f11de4c01519d9c3dd8c14d.png)'
  prefs: []
  type: TYPE_IMG
- en: lax.conv and lax.conv_with_general_padding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: These are the simple convenience functions for convolutions
  prefs: []
  type: TYPE_NORMAL
- en: ️⚠️ The convenience `lax.conv`, `lax.conv_with_general_padding` helper function
    assume **NCHW** images and **OIHW** kernels.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/d9bee780828085fbc09b1d92d421d3003963e72bbe4c17ab02bbe9fcfc18edbd.png](img/2e5efe6381662a2a7ed237ba757bc4d6.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/2daccd0cd7424c739ea9d1af43c2dfd330c45cea6ce5a8dc0196126917bed5e7.png](img/540b5f46a71aa47f61baf1763c4450b1.png)'
  prefs: []
  type: TYPE_IMG
- en: Dimension Numbers define dimensional layout for conv_general_dilated
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The important argument is the 3-tuple of axis layout arguments: (Input Layout,
    Kernel Layout, Output Layout)'
  prefs: []
  type: TYPE_NORMAL
- en: '**N** - batch dimension'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**H** - spatial height'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**W** - spatial width'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**C** - channel dimension'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I** - kernel *input* channel dimension'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**O** - kernel *output* channel dimension'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ⚠️ To demonstrate the flexibility of dimension numbers we choose a **NHWC**
    image and **HWIO** kernel convention for `lax.conv_general_dilated` below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: SAME padding, no stride, no dilation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/d9bee780828085fbc09b1d92d421d3003963e72bbe4c17ab02bbe9fcfc18edbd.png](img/2e5efe6381662a2a7ed237ba757bc4d6.png)'
  prefs: []
  type: TYPE_IMG
- en: VALID padding, no stride, no dilation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/d8f21810f67381c4e5e5ba5e6bcd0f0d8b830af5381b0975dec0b9b38a51afce.png](img/f80b1d21fa54cf1f49fe574b81f958ef.png)'
  prefs: []
  type: TYPE_IMG
- en: SAME padding, 2,2 stride, no dilation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/8051cc233d17fe493c7e0ffd2c2dbc0773e61b4d1138afef6d075b8d8cbfb3cc.png](img/37a5838c540df746a86ce15d3bb0ef71.png)'
  prefs: []
  type: TYPE_IMG
- en: VALID padding, no stride, rhs kernel dilation ~ Atrous convolution (excessive
    to illustrate)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/3242ab6a93d02ac641e42bd7b9087627444554747e07711b8e61b41904571b71.png](img/4f16c994e14bbfdd9d099fffc2e5abd9.png)'
  prefs: []
  type: TYPE_IMG
- en: VALID padding, no stride, lhs=input dilation ~ Transposed Convolution
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/c3363d9a17e1cf60f967a6658f171abff3a047bd9a6dc9a57f7c3f5850964c82.png](img/cb19dd89902788c0e2cc076ec1a48289.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can use the last to, for instance, implement *transposed convolutions*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/a31887582f261bc887008a3d1ccc329a276e965031f3a3d6f07365c86b694ede.png](img/49ff0f7697e4e37e9bc87de4910d5344.png)'
  prefs: []
  type: TYPE_IMG
- en: 1D Convolutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You aren’t limited to 2D convolutions, a simple 1D demo is below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/f14439a560314f430af73acf634bc696a09066b2609b4e5bace068b40cbfe639.png](img/dba7566216d992189974ce9f231aa30c.png)
    ![../_images/a816d20e944cdb9853c00466568be6f3d6f956c461202d6b33c6b4a821c21748.png](img/000dc195ccf8e4a2a374335c2321b133.png)'
  prefs: []
  type: TYPE_IMG
- en: 3D Convolutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '![../_images/aa5fabdf6a7e20bcb9b3f6ed4fdecb7c85355a4c25dbf8bd5083f19fc5e44ccc.png](img/c19aa20810da1132fc4c052d9d9faa85.png)
    ![../_images/f7f2915cb609bebbd6319369ebe9fb40e258ed1ca2c6e92c5ee2ac275562cb94.png](img/317130b3b016ffbed6b09e7292976eb7.png)'
  prefs: []
  type: TYPE_IMG
