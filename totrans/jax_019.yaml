- en: Profiling JAX programs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`jax.readthedocs.io/en/latest/profiling.html`](https://jax.readthedocs.io/en/latest/profiling.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Viewing program traces with Perfetto
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can use the JAX profiler to generate traces of a JAX program that can be
    visualized using the [Perfetto visualizer](https://ui.perfetto.dev). Currently,
    this method blocks the program until a link is clicked and the Perfetto UI loads
    the trace. If you wish to get profiling information without any interaction, check
    out the Tensorboard profiler below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: After this computation is done, the program will prompt you to open a link to
    `ui.perfetto.dev`. When you open the link, the Perfetto UI will load the trace
    file and open a visualizer.
  prefs: []
  type: TYPE_NORMAL
- en: '![Perfetto trace viewer](img/9357f9090a2d8149fbef99811b8ed0f2.png)'
  prefs: []
  type: TYPE_IMG
- en: Program execution will continue after loading the link. The link is no longer
    valid after opening once, but it will redirect to a new URL that remains valid.
    You can then click the “Share” button in the Perfetto UI to create a permalink
    to the trace that can be shared with others.
  prefs: []
  type: TYPE_NORMAL
- en: Remote profiling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When profiling code that is running remotely (for example on a hosted VM),
    you need to establish an SSH tunnel on port 9001 for the link to work. You can
    do that with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'or if you’re using Google Cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Manual capture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Instead of capturing traces programmatically using `jax.profiler.trace`, you
    can instead start a profiling server in the script of interest by calling `jax.profiler.start_server(<port>)`.
    If you only need the profiler server to be active for a portion of your script,
    you can shut it down by calling `jax.profiler.stop_server()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the script is running and after the profiler server has started, we can
    manually capture and trace by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: By default, the resulting trace information is dumped into a temporary directory
    but this can be overridden by passing in `--log_dir=<directory of choice>`. Also,
    by default, the program will prompt you to open a link to `ui.perfetto.dev`. When
    you open the link, the Perfetto UI will load the trace file and open a visualizer.
    This feature is disabled by passing in `--no_perfetto_link` into the command.
    Alternatively, you can also point Tensorboard to the `log_dir` to analyze the
    trace (see the “Tensorboard Profiling” section below).
  prefs: []
  type: TYPE_NORMAL
- en: '## TensorBoard profiling'
  prefs: []
  type: TYPE_NORMAL
- en: '[TensorBoard’s profiler](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras)
    can be used to profile JAX programs. Tensorboard is a great way to acquire and
    visualize performance traces and profiles of your program, including activity
    on GPU and TPU. The end result looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![TensorBoard profiler example](img/21e301e55032925d9ef8c8e8b171cf4f.png)'
  prefs: []
  type: TYPE_IMG
- en: Installation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The TensorBoard profiler is only available with the version of TensorBoard bundled
    with TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: If you already have TensorFlow installed, you only need to install the `tensorboard-plugin-profile`
    pip package. Be careful to only install one version of TensorFlow or TensorBoard,
    otherwise you may encounter the “duplicate plugins” error described below. See
    [`www.tensorflow.org/guide/profiler`](https://www.tensorflow.org/guide/profiler)
    for more information on installing TensorBoard.
  prefs: []
  type: TYPE_NORMAL
- en: Programmatic capture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can instrument your code to capture a profiler trace via the `jax.profiler.start_trace()`
    and `jax.profiler.stop_trace()` methods. Call `start_trace()` with the directory
    to write trace files to. This should be the same `--logdir` directory used to
    start TensorBoard. Then, you can use TensorBoard to view the traces.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to take a profiler trace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note the `block_until_ready()` call. We use this to make sure on-device execution
    is captured by the trace. See Asynchronous dispatch for details on why this is
    necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also use the `jax.profiler.trace()` context manager as an alternative
    to `start_trace` and `stop_trace`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To view the trace, first start TensorBoard if you haven’t already:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You should be able to load TensorBoard at [`localhost:6006/`](http://localhost:6006/)
    in this example. You can specify a different port with the `--port` flag. See
    Profiling on a remote machine below if running JAX on a remote server.
  prefs: []
  type: TYPE_NORMAL
- en: Then, either select “Profile” in the upper-right dropdown menu, or go directly
    to [`localhost:6006/#profile`](http://localhost:6006/#profile). Available traces
    appear in the “Runs” dropdown menu on the left. Select the run you’re interested
    in, and then under “Tools”, select `trace_viewer`. You should now see a timeline
    of the execution. You can use the WASD keys to navigate the trace, and click or
    drag to select events to see more details at the bottom. See [these TensorFlow
    docs](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras#use_the_tensorflow_profiler_to_profile_model_training_performance)
    for more details on using the trace viewer.
  prefs: []
  type: TYPE_NORMAL
- en: You can also use the `memory_viewer`, `op_profile`, and `graph_viewer` tools.
  prefs: []
  type: TYPE_NORMAL
- en: Manual capture via TensorBoard
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The following are instructions for capturing a manually-triggered N-second trace
    from a running program.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start a TensorBoard server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You should be able to load TensorBoard at [`localhost:6006/`](http://localhost:6006/).
    You can specify a different port with the `--port` flag. See Profiling on a remote
    machine below if running JAX on a remote server.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the Python program or process you’d like to profile, add the following somewhere
    near the beginning:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This starts the profiler server that TensorBoard connects to. The profiler server
    must be running before you move on to the next step. When you’re done using the
    server, you can call `jax.profiler.stop_server()` to shut it down.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you’d like to profile a snippet of a long-running program (e.g. a long training
    loop), you can put this at the beginning of the program and start your program
    as usual. If you’d like to profile a short program (e.g. a microbenchmark), one
    option is to start the profiler server in an IPython shell, and run the short
    program with `%run` after starting the capture in the next step. Another option
    is to start the profiler server at the beginning of the program and use `time.sleep()`
    to give you enough time to start the capture.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Open [`localhost:6006/#profile`](http://localhost:6006/#profile), and click
    the “CAPTURE PROFILE” button in the upper left. Enter “localhost:9999” as the
    profile service URL (this is the address of the profiler server you started in
    the previous step). Enter the number of milliseconds you’d like to profile for,
    and click “CAPTURE”.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the code you’d like to profile isn’t already running (e.g. if you started
    the profiler server in a Python shell), run it while the capture is running.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After the capture finishes, TensorBoard should automatically refresh. (Not all
    of the TensorBoard profiling features are hooked up with JAX, so it may initially
    look like nothing was captured.) On the left under “Tools”, select `trace_viewer`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should now see a timeline of the execution. You can use the WASD keys to
    navigate the trace, and click or drag to select events to see more details at
    the bottom. See [these TensorFlow docs](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras#use_the_tensorflow_profiler_to_profile_model_training_performance)
    for more details on using the trace viewer.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also use the `memory_viewer`, `op_profile`, and `graph_viewer` tools.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Adding custom trace events
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By default, the events in the trace viewer are mostly low-level internal JAX
    functions. You can add your own events and functions by using `jax.profiler.TraceAnnotation`
    and `jax.profiler.annotate_function()` in your code.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GPU profiling
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Programs running on GPU should produce traces for the GPU streams near the top
    of the trace viewer. If you’re only seeing the host traces, check your program
    logs and/or output for the following error messages.
  prefs: []
  type: TYPE_NORMAL
- en: '**If you get an error like: `Could not load dynamic library ''libcupti.so.10.1''`**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Full error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the path to `libcupti.so` to the environment variable `LD_LIBRARY_PATH`.
    (Try `locate libcupti.so` to find the path.) For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: If you still get the `Could not load dynamic library` message after doing this,
    check if the GPU trace shows up in the trace viewer anyway. This message sometimes
    occurs even when everything is working, since it looks for the `libcupti` library
    in multiple places.
  prefs: []
  type: TYPE_NORMAL
- en: '**If you get an error like: `failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES`**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Full error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following commands (note this requires a reboot):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: See [NVIDIA’s documentation on this error](https://developer.nvidia.com/nvidia-development-tools-solutions-err-nvgpuctrperm-cupti)
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: '#### Profiling on a remote machine'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the JAX program you’d like to profile is running on a remote machine, one
    option is to run all the instructions above on the remote machine (in particular,
    start the TensorBoard server on the remote machine), then use SSH local port forwarding
    to access the TensorBoard web UI from your local machine. Use the following SSH
    command to forward the default TensorBoard port 6006 from the local to the remote
    machine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'or if you’re using Google Cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]  #### Multiple TensorBoard installs'
  prefs: []
  type: TYPE_NORMAL
- en: '**If starting TensorBoard fails with an error like: `ValueError: Duplicate
    plugins for name projector`**'
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s often because there are two versions of TensorBoard and/or TensorFlow
    installed (e.g. the `tensorflow`, `tf-nightly`, `tensorboard`, and `tb-nightly`
    pip packages all include TensorBoard). Uninstalling a single pip package can result
    in the `tensorboard` executable being removed which is then hard to replace, so
    it may be necessary to uninstall everything and reinstall a single version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Nsight
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: NVIDIA’s `Nsight` tools can be used to trace and profile JAX code on GPU. For
    details, see the [`Nsight` documentation](https://developer.nvidia.com/tools-overview).
  prefs: []
  type: TYPE_NORMAL
