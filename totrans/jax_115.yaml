- en: jax.lax module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`jax.readthedocs.io/en/latest/jax.lax.html`](https://jax.readthedocs.io/en/latest/jax.lax.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`jax.lax` is a library of primitives operations that underpins libraries such
    as `jax.numpy`. Transformation rules, such as JVP and batching rules, are typically
    defined as transformations on `jax.lax` primitives.'
  prefs: []
  type: TYPE_NORMAL
- en: Many of the primitives are thin wrappers around equivalent XLA operations, described
    by the [XLA operation semantics](https://www.tensorflow.org/xla/operation_semantics)
    documentation. In a few cases JAX diverges from XLA, usually to ensure that the
    set of operations is closed under the operation of JVP and transpose rules.
  prefs: []
  type: TYPE_NORMAL
- en: Where possible, prefer to use libraries such as `jax.numpy` instead of using
    `jax.lax` directly. The `jax.numpy` API follows NumPy, and is therefore more stable
    and less likely to change than the `jax.lax` API.
  prefs: []
  type: TYPE_NORMAL
- en: Operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| `abs`(x) | Elementwise absolute value: \(&#124;x&#124;\). |'
  prefs: []
  type: TYPE_TB
- en: '| `acos`(x) | Elementwise arc cosine: \(\mathrm{acos}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `acosh`(x) | Elementwise inverse hyperbolic cosine: \(\mathrm{acosh}(x)\).
    |'
  prefs: []
  type: TYPE_TB
- en: '| `add`(x, y) | Elementwise addition: \(x + y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `after_all`(*operands) | Merges one or more XLA token values. |'
  prefs: []
  type: TYPE_TB
- en: '| `approx_max_k`(operand, k[, ...]) | Returns max `k` values and their indices
    of the `operand` in an approximate manner. |'
  prefs: []
  type: TYPE_TB
- en: '| `approx_min_k`(operand, k[, ...]) | Returns min `k` values and their indices
    of the `operand` in an approximate manner. |'
  prefs: []
  type: TYPE_TB
- en: '| `argmax`(operand, axis, index_dtype) | Computes the index of the maximum
    element along `axis`. |'
  prefs: []
  type: TYPE_TB
- en: '| `argmin`(operand, axis, index_dtype) | Computes the index of the minimum
    element along `axis`. |'
  prefs: []
  type: TYPE_TB
- en: '| `asin`(x) | Elementwise arc sine: \(\mathrm{asin}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `asinh`(x) | Elementwise inverse hyperbolic sine: \(\mathrm{asinh}(x)\).
    |'
  prefs: []
  type: TYPE_TB
- en: '| `atan`(x) | Elementwise arc tangent: \(\mathrm{atan}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `atan2`(x, y) | Elementwise arc tangent of two variables: \(\mathrm{atan}({x
    \over y})\). |'
  prefs: []
  type: TYPE_TB
- en: '| `atanh`(x) | Elementwise inverse hyperbolic tangent: \(\mathrm{atanh}(x)\).
    |'
  prefs: []
  type: TYPE_TB
- en: '| `batch_matmul`(lhs, rhs[, precision]) | Batch matrix multiplication. |'
  prefs: []
  type: TYPE_TB
- en: '| `bessel_i0e`(x) | Exponentially scaled modified Bessel function of order
    0: \(\mathrm{i0e}(x) = e^{-&#124;x&#124;} \mathrm{i0}(x)\) |'
  prefs: []
  type: TYPE_TB
- en: '| `bessel_i1e`(x) | Exponentially scaled modified Bessel function of order
    1: \(\mathrm{i1e}(x) = e^{-&#124;x&#124;} \mathrm{i1}(x)\) |'
  prefs: []
  type: TYPE_TB
- en: '| `betainc`(a, b, x) | Elementwise regularized incomplete beta integral. |'
  prefs: []
  type: TYPE_TB
- en: '| `bitcast_convert_type`(operand, new_dtype) | Elementwise bitcast. |'
  prefs: []
  type: TYPE_TB
- en: '| `bitwise_and`(x, y) | Elementwise AND: \(x \wedge y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `bitwise_not`(x) | Elementwise NOT: \(\neg x\). |'
  prefs: []
  type: TYPE_TB
- en: '| `bitwise_or`(x, y) | Elementwise OR: \(x \vee y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `bitwise_xor`(x, y) | Elementwise exclusive OR: \(x \oplus y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `population_count`(x) | Elementwise popcount, count the number of set bits
    in each element. |'
  prefs: []
  type: TYPE_TB
- en: '| `broadcast`(operand, sizes) | Broadcasts an array, adding new leading dimensions
    |'
  prefs: []
  type: TYPE_TB
- en: '| `broadcast_in_dim`(operand, shape, ...) | Wraps XLA''s [BroadcastInDim](https://www.tensorflow.org/xla/operation_semantics#broadcastindim)
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `broadcast_shapes`() | Returns the shape that results from NumPy broadcasting
    of shapes. |'
  prefs: []
  type: TYPE_TB
- en: '| `broadcast_to_rank`(x, rank) | Adds leading dimensions of `1` to give `x`
    rank `rank`. |'
  prefs: []
  type: TYPE_TB
- en: '| `broadcasted_iota`(dtype, shape, dimension) | Convenience wrapper around
    `iota`. |'
  prefs: []
  type: TYPE_TB
- en: '| `cbrt`(x) | Elementwise cube root: \(\sqrt[3]{x}\). |'
  prefs: []
  type: TYPE_TB
- en: '| `ceil`(x) | Elementwise ceiling: \(\left\lceil x \right\rceil\). |'
  prefs: []
  type: TYPE_TB
- en: '| `clamp`(min, x, max) | Elementwise clamp. |'
  prefs: []
  type: TYPE_TB
- en: '| `clz`(x) | Elementwise count-leading-zeros. |'
  prefs: []
  type: TYPE_TB
- en: '| `collapse`(operand, start_dimension[, ...]) | Collapses dimensions of an
    array into a single dimension. |'
  prefs: []
  type: TYPE_TB
- en: '| `complex`(x, y) | Elementwise make complex number: \(x + jy\). |'
  prefs: []
  type: TYPE_TB
- en: '| `concatenate`(operands, dimension) | Concatenates a sequence of arrays along
    dimension. |'
  prefs: []
  type: TYPE_TB
- en: '| `conj`(x) | Elementwise complex conjugate function: \(\overline{x}\). |'
  prefs: []
  type: TYPE_TB
- en: '| `conv`(lhs, rhs, window_strides, padding[, ...]) | Convenience wrapper around
    conv_general_dilated. |'
  prefs: []
  type: TYPE_TB
- en: '| `convert_element_type`(operand, new_dtype) | Elementwise cast. |'
  prefs: []
  type: TYPE_TB
- en: '| `conv_dimension_numbers`(lhs_shape, rhs_shape, ...) | Converts convolution
    dimension_numbers to a ConvDimensionNumbers. |'
  prefs: []
  type: TYPE_TB
- en: '| `conv_general_dilated`(lhs, rhs, ...[, ...]) | General n-dimensional convolution
    operator, with optional dilation. |'
  prefs: []
  type: TYPE_TB
- en: '| `conv_general_dilated_local`(lhs, rhs, ...[, ...]) | General n-dimensional
    unshared convolution operator with optional dilation. |'
  prefs: []
  type: TYPE_TB
- en: '| `conv_general_dilated_patches`(lhs, ...[, ...]) | Extract patches subject
    to the receptive field of conv_general_dilated. |'
  prefs: []
  type: TYPE_TB
- en: '| `conv_transpose`(lhs, rhs, strides, padding[, ...]) | Convenience wrapper
    for calculating the N-d convolution "transpose". |'
  prefs: []
  type: TYPE_TB
- en: '| `conv_with_general_padding`(lhs, rhs, ...[, ...]) | Convenience wrapper around
    conv_general_dilated. |'
  prefs: []
  type: TYPE_TB
- en: '| `cos`(x) | Elementwise cosine: \(\mathrm{cos}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `cosh`(x) | Elementwise hyperbolic cosine: \(\mathrm{cosh}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `cumlogsumexp`(operand[, axis, reverse]) | Computes a cumulative logsumexp
    along axis. |'
  prefs: []
  type: TYPE_TB
- en: '| `cummax`(operand[, axis, reverse]) | Computes a cumulative maximum along
    axis. |'
  prefs: []
  type: TYPE_TB
- en: '| `cummin`(operand[, axis, reverse]) | Computes a cumulative minimum along
    axis. |'
  prefs: []
  type: TYPE_TB
- en: '| `cumprod`(operand[, axis, reverse]) | Computes a cumulative product along
    axis. |'
  prefs: []
  type: TYPE_TB
- en: '| `cumsum`(operand[, axis, reverse]) | Computes a cumulative sum along axis.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `digamma`(x) | Elementwise digamma: \(\psi(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `div`(x, y) | Elementwise division: \(x \over y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `dot`(lhs, rhs[, precision, ...]) | Vector/vector, matrix/vector, and matrix/matrix
    multiplication. |'
  prefs: []
  type: TYPE_TB
- en: '| `dot_general`(lhs, rhs, dimension_numbers[, ...]) | General dot product/contraction
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `dynamic_index_in_dim`(operand, index[, axis, ...]) | Convenience wrapper
    around dynamic_slice to perform int indexing. |'
  prefs: []
  type: TYPE_TB
- en: '| `dynamic_slice`(operand, start_indices, ...) | Wraps XLA''s [DynamicSlice](https://www.tensorflow.org/xla/operation_semantics#dynamicslice)
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `dynamic_slice_in_dim`(operand, start_index, ...) | Convenience wrapper around
    `lax.dynamic_slice()` applied to one dimension. |'
  prefs: []
  type: TYPE_TB
- en: '| `dynamic_update_index_in_dim`(operand, update, ...) | Convenience wrapper
    around `dynamic_update_slice()` to update a slice of size 1 in a single `axis`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `dynamic_update_slice`(operand, update, ...) | Wraps XLA''s [DynamicUpdateSlice](https://www.tensorflow.org/xla/operation_semantics#dynamicupdateslice)
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `dynamic_update_slice_in_dim`(operand, update, ...) | Convenience wrapper
    around `dynamic_update_slice()` to update a slice in a single `axis`. |'
  prefs: []
  type: TYPE_TB
- en: '| `eq`(x, y) | Elementwise equals: \(x = y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `erf`(x) | Elementwise error function: \(\mathrm{erf}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `erfc`(x) | Elementwise complementary error function: \(\mathrm{erfc}(x)
    = 1 - \mathrm{erf}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `erf_inv`(x) | Elementwise inverse error function: \(\mathrm{erf}^{-1}(x)\).
    |'
  prefs: []
  type: TYPE_TB
- en: '| `exp`(x) | Elementwise exponential: \(e^x\). |'
  prefs: []
  type: TYPE_TB
- en: '| `expand_dims`(array, dimensions) | Insert any number of size 1 dimensions
    into an array. |'
  prefs: []
  type: TYPE_TB
- en: '| `expm1`(x) | Elementwise \(e^{x} - 1\). |'
  prefs: []
  type: TYPE_TB
- en: '| `fft`(x, fft_type, fft_lengths) |  |'
  prefs: []
  type: TYPE_TB
- en: '| `floor`(x) | Elementwise floor: \(\left\lfloor x \right\rfloor\). |'
  prefs: []
  type: TYPE_TB
- en: '| `full`(shape, fill_value[, dtype, sharding]) | Returns an array of shape
    filled with fill_value. |'
  prefs: []
  type: TYPE_TB
- en: '| `full_like`(x, fill_value[, dtype, shape, ...]) | Create a full array like
    np.full based on the example array x. |'
  prefs: []
  type: TYPE_TB
- en: '| `gather`(operand, start_indices, ...[, ...]) | Gather operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `ge`(x, y) | Elementwise greater-than-or-equals: \(x \geq y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `gt`(x, y) | Elementwise greater-than: \(x > y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `igamma`(a, x) | Elementwise regularized incomplete gamma function. |'
  prefs: []
  type: TYPE_TB
- en: '| `igammac`(a, x) | Elementwise complementary regularized incomplete gamma
    function. |'
  prefs: []
  type: TYPE_TB
- en: '| `imag`(x) | Elementwise extract imaginary part: \(\mathrm{Im}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `index_in_dim`(operand, index[, axis, keepdims]) | Convenience wrapper around
    `lax.slice()` to perform int indexing. |'
  prefs: []
  type: TYPE_TB
- en: '| `index_take`(src, idxs, axes) |  |'
  prefs: []
  type: TYPE_TB
- en: '| `integer_pow`(x, y) | Elementwise power: \(x^y\), where \(y\) is a fixed
    integer. |'
  prefs: []
  type: TYPE_TB
- en: '| `iota`(dtype, size) | Wraps XLA''s [Iota](https://www.tensorflow.org/xla/operation_semantics#iota)
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `is_finite`(x) | Elementwise \(\mathrm{isfinite}\). |'
  prefs: []
  type: TYPE_TB
- en: '| `le`(x, y) | Elementwise less-than-or-equals: \(x \leq y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `lgamma`(x) | Elementwise log gamma: \(\mathrm{log}(\Gamma(x))\). |'
  prefs: []
  type: TYPE_TB
- en: '| `log`(x) | Elementwise natural logarithm: \(\mathrm{log}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `log1p`(x) | Elementwise \(\mathrm{log}(1 + x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `logistic`(x) | Elementwise logistic (sigmoid) function: \(\frac{1}{1 + e^{-x}}\).
    |'
  prefs: []
  type: TYPE_TB
- en: '| `lt`(x, y) | Elementwise less-than: \(x < y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `max`(x, y) | Elementwise maximum: \(\mathrm{max}(x, y)\) |'
  prefs: []
  type: TYPE_TB
- en: '| `min`(x, y) | Elementwise minimum: \(\mathrm{min}(x, y)\) |'
  prefs: []
  type: TYPE_TB
- en: '| `mul`(x, y) | Elementwise multiplication: \(x \times y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `ne`(x, y) | Elementwise not-equals: \(x \neq y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `neg`(x) | Elementwise negation: \(-x\). |'
  prefs: []
  type: TYPE_TB
- en: '| `nextafter`(x1, x2) | Returns the next representable value after x1 in the
    direction of x2. |'
  prefs: []
  type: TYPE_TB
- en: '| `pad`(operand, padding_value, padding_config) | Applies low, high, and/or
    interior padding to an array. |'
  prefs: []
  type: TYPE_TB
- en: '| `polygamma`(m, x) | Elementwise polygamma: \(\psi^{(m)}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `population_count`(x) | Elementwise popcount, count the number of set bits
    in each element. |'
  prefs: []
  type: TYPE_TB
- en: '| `pow`(x, y) | Elementwise power: \(x^y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `random_gamma_grad`(a, x) | Elementwise derivative of samples from Gamma(a,
    1). |'
  prefs: []
  type: TYPE_TB
- en: '| `real`(x) | Elementwise extract real part: \(\mathrm{Re}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `reciprocal`(x) | Elementwise reciprocal: \(1 \over x\). |'
  prefs: []
  type: TYPE_TB
- en: '| `reduce`(operands, init_values, computation, ...) | Wraps XLA''s [Reduce](https://www.tensorflow.org/xla/operation_semantics#reduce)
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `reduce_precision`(operand, exponent_bits, ...) | Wraps XLA''s [ReducePrecision](https://www.tensorflow.org/xla/operation_semantics#reduceprecision)
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `reduce_window`(operand, init_value, ...[, ...]) |  |'
  prefs: []
  type: TYPE_TB
- en: '| `rem`(x, y) | Elementwise remainder: \(x \bmod y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `reshape`(operand, new_sizes[, dimensions]) | Wraps XLA''s [Reshape](https://www.tensorflow.org/xla/operation_semantics#reshape)
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `rev`(operand, dimensions) | Wraps XLA''s [Rev](https://www.tensorflow.org/xla/operation_semantics#rev_reverse)
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `rng_bit_generator`(key, shape[, dtype, algorithm]) | Stateless PRNG bit
    generator. |'
  prefs: []
  type: TYPE_TB
- en: '| `rng_uniform`(a, b, shape) | Stateful PRNG generator. |'
  prefs: []
  type: TYPE_TB
- en: '| `round`(x[, rounding_method]) | Elementwise round. |'
  prefs: []
  type: TYPE_TB
- en: '| `rsqrt`(x) | Elementwise reciprocal square root: \(1 \over \sqrt{x}\). |'
  prefs: []
  type: TYPE_TB
- en: '| `scatter`(operand, scatter_indices, updates, ...) | Scatter-update operator.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `scatter_add`(operand, scatter_indices, ...[, ...]) | Scatter-add operator.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `scatter_apply`(operand, scatter_indices, ...) | Scatter-apply operator.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `scatter_max`(operand, scatter_indices, ...[, ...]) | Scatter-max operator.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `scatter_min`(operand, scatter_indices, ...[, ...]) | Scatter-min operator.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `scatter_mul`(operand, scatter_indices, ...[, ...]) | Scatter-multiply operator.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `shift_left`(x, y) | Elementwise left shift: \(x \ll y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `shift_right_arithmetic`(x, y) | Elementwise arithmetic right shift: \(x
    \gg y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `shift_right_logical`(x, y) | Elementwise logical right shift: \(x \gg y\).
    |'
  prefs: []
  type: TYPE_TB
- en: '| `sign`(x) | Elementwise sign. |'
  prefs: []
  type: TYPE_TB
- en: '| `sin`(x) | Elementwise sine: \(\mathrm{sin}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `sinh`(x) | Elementwise hyperbolic sine: \(\mathrm{sinh}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `slice`(operand, start_indices, limit_indices) | Wraps XLA''s [Slice](https://www.tensorflow.org/xla/operation_semantics#slice)
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `slice_in_dim`(operand, start_index, limit_index) | Convenience wrapper around
    `lax.slice()` applying to only one dimension. |'
  prefs: []
  type: TYPE_TB
- en: '| `sort`() | Wraps XLA''s [Sort](https://www.tensorflow.org/xla/operation_semantics#sort)
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `sort_key_val`(keys, values[, dimension, ...]) | Sorts `keys` along `dimension`
    and applies the same permutation to `values`. |'
  prefs: []
  type: TYPE_TB
- en: '| `sqrt`(x) | Elementwise square root: \(\sqrt{x}\). |'
  prefs: []
  type: TYPE_TB
- en: '| `square`(x) | Elementwise square: \(x²\). |'
  prefs: []
  type: TYPE_TB
- en: '| `squeeze`(array, dimensions) | Squeeze any number of size 1 dimensions from
    an array. |'
  prefs: []
  type: TYPE_TB
- en: '| `sub`(x, y) | Elementwise subtraction: \(x - y\). |'
  prefs: []
  type: TYPE_TB
- en: '| `tan`(x) | Elementwise tangent: \(\mathrm{tan}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `tanh`(x) | Elementwise hyperbolic tangent: \(\mathrm{tanh}(x)\). |'
  prefs: []
  type: TYPE_TB
- en: '| `top_k`(operand, k) | Returns top `k` values and their indices along the
    last axis of `operand`. |'
  prefs: []
  type: TYPE_TB
- en: '| `transpose`(operand, permutation) | Wraps XLA''s [Transpose](https://www.tensorflow.org/xla/operation_semantics#transpose)
    operator. |'
  prefs: []
  type: TYPE_TB
- en: '| `zeros_like_array`(x) |  |'
  prefs: []
  type: TYPE_TB
- en: '| `zeta`(x, q) | Elementwise Hurwitz zeta function: \(\zeta(x, q)\) |'
  prefs: []
  type: TYPE_TB
- en: '## Control flow operators'
  prefs: []
  type: TYPE_NORMAL
- en: '| `associative_scan`(fn, elems[, reverse, axis]) | Performs a scan with an
    associative binary operation, in parallel. |'
  prefs: []
  type: TYPE_TB
- en: '| `cond`(pred, true_fun, false_fun, *operands[, ...]) | Conditionally apply
    `true_fun` or `false_fun`. |'
  prefs: []
  type: TYPE_TB
- en: '| `fori_loop`(lower, upper, body_fun, init_val, *) | Loop from `lower` to `upper`
    by reduction to `jax.lax.while_loop()`. |'
  prefs: []
  type: TYPE_TB
- en: '| `map`(f, xs) | Map a function over leading array axes. |'
  prefs: []
  type: TYPE_TB
- en: '| `scan`(f, init[, xs, length, reverse, unroll, ...]) | Scan a function over
    leading array axes while carrying along state. |'
  prefs: []
  type: TYPE_TB
- en: '| `select`(pred, on_true, on_false) | Selects between two branches based on
    a boolean predicate. |'
  prefs: []
  type: TYPE_TB
- en: '| `select_n`(which, *cases) | Selects array values from multiple cases. |'
  prefs: []
  type: TYPE_TB
- en: '| `switch`(index, branches, *operands[, operand]) | Apply exactly one of the
    `branches` given by `index`. |'
  prefs: []
  type: TYPE_TB
- en: '| `while_loop`(cond_fun, body_fun, init_val) | Call `body_fun` repeatedly in
    a loop while `cond_fun` is True. |'
  prefs: []
  type: TYPE_TB
- en: Custom gradient operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| `stop_gradient`(x) | Stops gradient computation. |'
  prefs: []
  type: TYPE_TB
- en: '| `custom_linear_solve`(matvec, b, solve[, ...]) | Perform a matrix-free linear
    solve with implicitly defined gradients. |'
  prefs: []
  type: TYPE_TB
- en: '| `custom_root`(f, initial_guess, solve, ...[, ...]) | Differentiably solve
    for the roots of a function. |'
  prefs: []
  type: TYPE_TB
- en: '## Parallel operators'
  prefs: []
  type: TYPE_NORMAL
- en: '| `all_gather`(x, axis_name, *[, ...]) | Gather values of x across all replicas.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `all_to_all`(x, axis_name, split_axis, ...[, ...]) | Materialize the mapped
    axis and map a different axis. |'
  prefs: []
  type: TYPE_TB
- en: '| `pdot`(x, y, axis_name[, pos_contract, ...]) |  |'
  prefs: []
  type: TYPE_TB
- en: '| `psum`(x, axis_name, *[, axis_index_groups]) | Compute an all-reduce sum
    on `x` over the pmapped axis `axis_name`. |'
  prefs: []
  type: TYPE_TB
- en: '| `psum_scatter`(x, axis_name, *[, ...]) | Like `psum(x, axis_name)` but each
    device retains only part of the result. |'
  prefs: []
  type: TYPE_TB
- en: '| `pmax`(x, axis_name, *[, axis_index_groups]) | Compute an all-reduce max
    on `x` over the pmapped axis `axis_name`. |'
  prefs: []
  type: TYPE_TB
- en: '| `pmin`(x, axis_name, *[, axis_index_groups]) | Compute an all-reduce min
    on `x` over the pmapped axis `axis_name`. |'
  prefs: []
  type: TYPE_TB
- en: '| `pmean`(x, axis_name, *[, axis_index_groups]) | Compute an all-reduce mean
    on `x` over the pmapped axis `axis_name`. |'
  prefs: []
  type: TYPE_TB
- en: '| `ppermute`(x, axis_name, perm) | Perform a collective permutation according
    to the permutation `perm`. |'
  prefs: []
  type: TYPE_TB
- en: '| `pshuffle`(x, axis_name, perm) | Convenience wrapper of jax.lax.ppermute
    with alternate permutation encoding |'
  prefs: []
  type: TYPE_TB
- en: '| `pswapaxes`(x, axis_name, axis, *[, ...]) | Swap the pmapped axis `axis_name`
    with the unmapped axis `axis`. |'
  prefs: []
  type: TYPE_TB
- en: '| `axis_index`(axis_name) | Return the index along the mapped axis `axis_name`.
    |'
  prefs: []
  type: TYPE_TB
- en: Sharding-related operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| `with_sharding_constraint`(x, shardings) | Mechanism to constrain the sharding
    of an Array inside a jitted computation |'
  prefs: []
  type: TYPE_TB
- en: '## Linear algebra operators (jax.lax.linalg)'
  prefs: []
  type: TYPE_NORMAL
- en: '| `cholesky`(x, *[, symmetrize_input]) | Cholesky decomposition. |'
  prefs: []
  type: TYPE_TB
- en: '| `eig`(x, *[, compute_left_eigenvectors, ...]) | Eigendecomposition of a general
    matrix. |'
  prefs: []
  type: TYPE_TB
- en: '| `eigh`(x, *[, lower, symmetrize_input, ...]) | Eigendecomposition of a Hermitian
    matrix. |'
  prefs: []
  type: TYPE_TB
- en: '| `hessenberg`(a) | Reduces a square matrix to upper Hessenberg form. |'
  prefs: []
  type: TYPE_TB
- en: '| `lu`(x) | LU decomposition with partial pivoting. |'
  prefs: []
  type: TYPE_TB
- en: '| `householder_product`(a, taus) | Product of elementary Householder reflectors.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `qdwh`(x, *[, is_hermitian, max_iterations, ...]) | QR-based dynamically
    weighted Halley iteration for polar decomposition. |'
  prefs: []
  type: TYPE_TB
- en: '| `qr`(x, *[, full_matrices]) | QR decomposition. |'
  prefs: []
  type: TYPE_TB
- en: '| `schur`(x, *[, compute_schur_vectors, ...]) |  |'
  prefs: []
  type: TYPE_TB
- en: '| `svd`() | Singular value decomposition. |'
  prefs: []
  type: TYPE_TB
- en: '| `triangular_solve`(a, b, *[, left_side, ...]) | Triangular solve. |'
  prefs: []
  type: TYPE_TB
- en: '| `tridiagonal`(a, *[, lower]) | Reduces a symmetric/Hermitian matrix to tridiagonal
    form. |'
  prefs: []
  type: TYPE_TB
- en: '| `tridiagonal_solve`(dl, d, du, b) | Computes the solution of a tridiagonal
    linear system. |'
  prefs: []
  type: TYPE_TB
- en: Argument classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Describes batch, spatial, and feature dimensions of a convolution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**lhs_spec** ([*Sequence*](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence
    "(in Python v3.12)")*[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]*) – a tuple of nonnegative integer dimension numbers containing
    (batch dimension, feature dimension, spatial dimensions…).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**rhs_spec** ([*Sequence*](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence
    "(in Python v3.12)")*[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]*) – a tuple of nonnegative integer dimension numbers containing
    (out feature dimension, in feature dimension, spatial dimensions…).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**out_spec** ([*Sequence*](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence
    "(in Python v3.12)")*[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]*) – a tuple of nonnegative integer dimension numbers containing
    (batch dimension, feature dimension, spatial dimensions…).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: alias of [`tuple`](https://docs.python.org/3/library/stdtypes.html#tuple "(in
    Python v3.12)")[[`str`](https://docs.python.org/3/library/stdtypes.html#str "(in
    Python v3.12)"), [`str`](https://docs.python.org/3/library/stdtypes.html#str "(in
    Python v3.12)"), [`str`](https://docs.python.org/3/library/stdtypes.html#str "(in
    Python v3.12)")] | `ConvDimensionNumbers` | [`None`](https://docs.python.org/3/library/constants.html#None
    "(in Python v3.12)")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Describes the dimension number arguments to an [XLA’s Gather operator](https://www.tensorflow.org/xla/operation_semantics#gather).
    See the XLA documentation for more details of what the dimension numbers mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**offset_dims** ([*tuple*](https://docs.python.org/3/library/stdtypes.html#tuple
    "(in Python v3.12)")*[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*,* *...**]*) – the set of dimensions in the gather output
    that offset into an array sliced from operand. Must be a tuple of integers in
    ascending order, each representing a dimension number of the output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**collapsed_slice_dims** ([*tuple*](https://docs.python.org/3/library/stdtypes.html#tuple
    "(in Python v3.12)")*[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*,* *...**]*) – the set of dimensions i in operand that have
    slice_sizes[i] == 1 and that should not have a corresponding dimension in the
    output of the gather. Must be a tuple of integers in ascending order.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**start_index_map** ([*tuple*](https://docs.python.org/3/library/stdtypes.html#tuple
    "(in Python v3.12)")*[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*,* *...**]*) – for each dimension in start_indices, gives
    the corresponding dimension in the operand that is to be sliced. Must be a tuple
    of integers with size equal to start_indices.shape[-1].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unlike XLA’s GatherDimensionNumbers structure, index_vector_dim is implicit;
    there is always an index vector dimension and it must always be the last dimension.
    To gather scalar indices, add a trailing dimension of size 1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Describes how to handle out-of-bounds indices in a gather or scatter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Possible values are:'
  prefs: []
  type: TYPE_NORMAL
- en: 'CLIP:'
  prefs: []
  type: TYPE_NORMAL
- en: Indices will be clamped to the nearest in-range value, i.e., such that the entire
    window to be gathered is in-range.
  prefs: []
  type: TYPE_NORMAL
- en: 'FILL_OR_DROP:'
  prefs: []
  type: TYPE_NORMAL
- en: If any part of a gathered window is out of bounds, the entire window that is
    returned, even those elements that were otherwise in-bounds, will be filled with
    a constant. If any part of a scattered window is out of bounds, the entire window
    will be discarded.
  prefs: []
  type: TYPE_NORMAL
- en: 'PROMISE_IN_BOUNDS:'
  prefs: []
  type: TYPE_NORMAL
- en: The user promises that indices are in bounds. No additional checking will be
    performed. In practice, with the current XLA implementation this means that out-of-bounds
    gathers will be clamped but out-of-bounds scatters will be discarded. Gradients
    will not be correct if indices are out-of-bounds.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Precision enum for lax functions
  prefs: []
  type: TYPE_NORMAL
- en: 'The precision argument to JAX functions generally controls the tradeoff between
    speed and accuracy for array computations on accelerator backends, (i.e. TPU and
    GPU). Members are:'
  prefs: []
  type: TYPE_NORMAL
- en: 'DEFAULT:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fastest mode, but least accurate. Performs computations in bfloat16. Aliases:
    `''default''`, `''fastest''`, `''bfloat16''`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'HIGH:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Slower but more accurate. Performs float32 computations in 3 bfloat16 passes,
    or using tensorfloat32 where available. Aliases: `''high''`, `''bfloat16_3x''`,
    `''tensorfloat32''`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'HIGHEST:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Slowest but most accurate. Performs computations in float32 or float64 as applicable.
    Aliases: `''highest''`, `''float32''`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: alias of [`str`](https://docs.python.org/3/library/stdtypes.html#str "(in Python
    v3.12)") | `Precision` | [`tuple`](https://docs.python.org/3/library/stdtypes.html#tuple
    "(in Python v3.12)")[[`str`](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)"), [`str`](https://docs.python.org/3/library/stdtypes.html#str
    "(in Python v3.12)")] | [`tuple`](https://docs.python.org/3/library/stdtypes.html#tuple
    "(in Python v3.12)")[`Precision`, `Precision`] | [`None`](https://docs.python.org/3/library/constants.html#None
    "(in Python v3.12)")
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: An enumeration.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Describes the dimension number arguments to an [XLA’s Scatter operator](https://www.tensorflow.org/xla/operation_semantics#scatter).
    See the XLA documentation for more details of what the dimension numbers mean.
  prefs: []
  type: TYPE_NORMAL
- en: 'Parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**update_window_dims** ([*Sequence*](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence
    "(in Python v3.12)")*[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]*) – the set of dimensions in the updates that are window
    dimensions. Must be a tuple of integers in ascending order, each representing
    a dimension number.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**inserted_window_dims** ([*Sequence*](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence
    "(in Python v3.12)")*[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]*) – the set of size 1 window dimensions that must be inserted
    into the shape of updates. Must be a tuple of integers in ascending order, each
    representing a dimension number of the output. These are the mirror image of collapsed_slice_dims
    in the case of gather.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**scatter_dims_to_operand_dims** ([*Sequence*](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence
    "(in Python v3.12)")*[*[*int*](https://docs.python.org/3/library/functions.html#int
    "(in Python v3.12)")*]*) – for each dimension in scatter_indices, gives the corresponding
    dimension in operand. Must be a sequence of integers with size equal to scatter_indices.shape[-1].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unlike XLA’s ScatterDimensionNumbers structure, index_vector_dim is implicit;
    there is always an index vector dimension and it must always be the last dimension.
    To scatter scalar indices, add a trailing dimension of size 1.
  prefs: []
  type: TYPE_NORMAL
