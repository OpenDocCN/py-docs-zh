- en: Automatic differentiation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动微分
- en: 原文：[`jax.readthedocs.io/en/latest/automatic-differentiation.html`](https://jax.readthedocs.io/en/latest/automatic-differentiation.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`jax.readthedocs.io/en/latest/automatic-differentiation.html`](https://jax.readthedocs.io/en/latest/automatic-differentiation.html)
- en: 'In this section, you will learn about fundamental applications of automatic
    differentiation (autodiff) in JAX. JAX has a pretty general autodiff system. Computing
    gradients is a critical part of modern machine learning methods, and this tutorial
    will walk you through a few introductory autodiff topics, such as:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习JAX中自动微分（autodiff）的基本应用。JAX具有一个非常通用的自动微分系统。计算梯度是现代机器学习方法的关键部分，本教程将引导您了解一些自动微分的入门主题，例如：
- en: 1\. Taking gradients with jax.grad
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1\. 使用jax.grad计算梯度
- en: 2\. Computing gradients in a linear logistic regression
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2\. 在线性逻辑回归中计算梯度
- en: 3\. Differentiating with respect to nested lists, tuples, and dicts
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3\. 对嵌套列表、元组和字典进行微分
- en: 4\. Evaluating a function and its gradient using jax.value_and_grad
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4\. 使用jax.value_and_grad评估函数及其梯度
- en: 5\. Checking against numerical differences
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5\. 检查数值差异
- en: Make sure to also check out the Advanced automatic differentiation tutorial
    for more advanced topics.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 还要确保查看高级自动微分教程，了解更多高级主题。
- en: While understanding how automatic differentiation works “under the hood” isn’t
    crucial for using JAX in most contexts, you are encouraged to check out this quite
    accessible [video](https://www.youtube.com/watch?v=wG_nF1awSSY) to get a deeper
    sense of what’s going on.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然理解自动微分的“内部工作原理”对于在大多数情况下使用JAX并不关键，但建议您观看这个非常易懂的[视频](https://www.youtube.com/watch?v=wG_nF1awSSY)，以深入了解发生的事情。
- en: '## 1\. Taking gradients with `jax.grad`'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '## 1\. 使用`jax.grad()`计算梯度'
- en: 'In JAX, you can differentiate a scalar-valued function with the `jax.grad()`
    transformation:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在JAX中，您可以使用`jax.grad()`变换微分一个标量值函数：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`jax.grad()` takes a function and returns a function. If you have a Python
    function `f` that evaluates the mathematical function \(f\), then `jax.grad(f)`
    is a Python function that evaluates the mathematical function \(\nabla f\). That
    means `grad(f)(x)` represents the value \(\nabla f(x)\).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '`jax.grad()`接受一个函数并返回一个函数。如果你有一个Python函数`f`，它计算数学函数\( f \)，那么`jax.grad(f)`是一个Python函数，它计算数学函数\(
    \nabla f \)。这意味着`grad(f)(x)`表示值\( \nabla f(x) \)。'
- en: 'Since `jax.grad()` operates on functions, you can apply it to its own output
    to differentiate as many times as you like:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`jax.grad()`操作函数，您可以将其应用于其自身的输出，以任意次数进行微分：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'JAX’s autodiff makes it easy to compute higher-order derivatives, because the
    functions that compute derivatives are themselves differentiable. Thus, higher-order
    derivatives are as easy as stacking transformations. This can be illustrated in
    the single-variable case:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: JAX的自动微分使得计算高阶导数变得容易，因为计算导数的函数本身是可微的。因此，高阶导数就像堆叠转换一样容易。这可以在单变量情况下说明：
- en: 'The derivative of \(f(x) = x³ + 2x² - 3x + 1\) can be computed as:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 函数\( f(x) = x³ + 2x² - 3x + 1 \)的导数可以计算如下：
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The higher-order derivatives of \(f\) are:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 函数\( f \)的高阶导数为：
- en: \[\begin{split} \begin{array}{l} f'(x) = 3x² + 4x -3\\ f''(x) = 6x + 4\\ f'''(x)
    = 6\\ f^{iv}(x) = 0 \end{array} \end{split}\]
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{array}{l} f'(x) = 3x² + 4x -3\\ f''(x) = 6x + 4\\ f'''(x)
    = 6\\ f^{iv}(x) = 0 \end{array} \end{split}\]
- en: 'Computing any of these in JAX is as easy as chaining the `jax.grad()` function:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在JAX中计算任何这些都像链接`jax.grad()`函数一样简单：
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Evaluating the above in \(x=1\) would give you:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在\( x=1 \)处评估上述内容将给出：
- en: \[\begin{split} \begin{array}{l} f'(1) = 4\\ f''(1) = 10\\ f'''(1) = 6\\ f^{iv}(1)
    = 0 \end{array} \end{split}\]
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: \[\begin{split} \begin{array}{l} f'(1) = 4\\ f''(1) = 10\\ f'''(1) = 6\\ f^{iv}(1)
    = 0 \end{array} \end{split}\]
- en: 'Using JAX:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用JAX：
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]  ## 2\. Computing gradients in a linear logistic regression'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE7]  ## 2\. 在线性逻辑回归中计算梯度'
- en: 'The next example shows how to compute gradients with `jax.grad()` in a linear
    logistic regression model. First, the setup:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例展示了如何在线性逻辑回归模型中使用`jax.grad()`计算梯度。首先，设置：
- en: '[PRE8]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Use the `jax.grad()` function with its `argnums` argument to differentiate a
    function with respect to positional arguments.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`jax.grad()`函数及其`argnums`参数对位置参数进行函数微分。
- en: '[PRE9]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `jax.grad()` API has a direct correspondence to the excellent notation in
    Spivak’s classic *Calculus on Manifolds* (1965), also used in Sussman and Wisdom’s
    [*Structure and Interpretation of Classical Mechanics*](https://mitpress.mit.edu/9780262028967/structure-and-interpretation-of-classical-mechanics)
    (2015) and their [*Functional Differential Geometry*](https://mitpress.mit.edu/9780262019347/functional-differential-geometry)
    (2013). Both books are open-access. See in particular the “Prologue” section of
    *Functional Differential Geometry* for a defense of this notation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`jax.grad()` API 直接对应于斯皮瓦克经典著作《流形上的微积分》（1965年）中的优秀符号表示法，也用于苏斯曼和威斯登的《古典力学的结构与解释》（2015年）及其《函数微分几何》（2013年）。这两本书都是开放获取的。特别是，《函数微分几何》的“前言”部分为此符号的使用进行了辩护。'
- en: 'Essentially, when using the `argnums` argument, if `f` is a Python function
    for evaluating the mathematical function \(f\), then the Python expression `jax.grad(f,
    i)` evaluates to a Python function for evaluating \(\partial_i f\).  ## 3\. Differentiating
    with respect to nested lists, tuples, and dicts'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '实际上，当使用`argnums`参数时，如果`f`是用于评估数学函数\(f\)的Python函数，则Python表达式`jax.grad(f, i)`评估为一个用于评估\(\partial_i
    f\)的Python函数。  ## 3\. 对嵌套列表、元组和字典进行微分'
- en: Due to JAX’s PyTree abstraction (see Working with pytrees), differentiating
    with respect to standard Python containers just works, so use tuples, lists, and
    dicts (and arbitrary nesting) however you like.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 由于JAX的PyTree抽象（详见处理pytrees），关于标准Python容器的微分工作都能正常进行，因此你可以随意使用元组、列表和字典（及任意嵌套结构）。
- en: 'Continuing the previous example:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 继续前面的示例：
- en: '[PRE11]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can create Custom pytree nodes to work with not just `jax.grad()` but other
    JAX transformations (`jax.jit()`, `jax.vmap()`, and so on).  ## 4\. Evaluating
    a function and its gradient using `jax.value_and_grad`'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '你可以创建自定义的pytree节点，以便与不仅仅是`jax.grad()`，还有其他JAX转换（`jax.jit()`，`jax.vmap()`等）一起使用。  ##
    4\. 使用`jax.value_and_grad`评估函数及其梯度'
- en: Another convenient function is `jax.value_and_grad()` for efficiently computing
    both a function’s value as well as its gradient’s value in one pass.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个方便的函数是`jax.value_and_grad()`，可以在一次计算中高效地同时计算函数值和其梯度值。
- en: 'Continuing the previous examples:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 继续前面的示例：
- en: '[PRE13]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]  ## 5\. Checking against numerical differences'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE14]  ## 5\. 对数值差异进行检查'
- en: A great thing about derivatives is that they’re straightforward to check with
    finite differences.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 关于导数的一大好处是，它们对有限差异的检查非常直观。
- en: 'Continuing the previous examples:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 继续前面的示例：
- en: '[PRE15]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'JAX provides a simple convenience function that does essentially the same thing,
    but checks up to any order of differentiation that you like:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: JAX提供了一个简单的便利函数，实际上做了相同的事情，但可以检查任意阶数的微分：
- en: '[PRE17]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Next steps
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一步
- en: The Advanced automatic differentiation tutorial provides more advanced and detailed
    explanations of how the ideas covered in this document are implemented in the
    JAX backend. Some features, such as Custom derivative rules for JAX-transformable
    Python functions, depend on understanding advanced automatic differentiation,
    so do check out that section in the Advanced automatic differentiation tutorial
    if you are interested.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 高级自动微分教程提供了关于如何在JAX后端实现本文档涵盖的思想的更高级和详细的解释。某些功能，如用于JAX可转换Python函数的自定义导数规则，依赖于对高级自动微分的理解，因此如果您感兴趣，请查看高级自动微分教程中的相关部分。
