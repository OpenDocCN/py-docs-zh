- en: Distributed data loading in a multi-host/multi-process environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[`jax.readthedocs.io/en/latest/distributed_data_loading.html`](https://jax.readthedocs.io/en/latest/distributed_data_loading.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This high-level guide demonstrates how you can perform distributed data loading
    — when you run JAX in a multi-host or multi-process environment, and the data
    required for the JAX computations is split across the multiple processes. This
    document covers the overall approach for how to think about distributed data loading,
    and then how to apply it to *data-parallel* (simpler) and *model-parallel* (more
    complicated) workloads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Distributed data loading is usually more efficient (the data is split across
    processes) but also *more complex* compared with its alternatives, such as: 1)
    loading the *full global data in a single process*, splitting it up and sending
    the needed parts to the other processes via RPC; and 2) loading the *full global
    data in all processes* and only using the needed parts in each process. Loading
    the full global data is often simpler but more expensive. For example, in machine
    learning the training loop can get blocked while waiting for data, and additional
    network bandwidth gets used per each process.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: When using distributed data loading, it’s important that each device (for example,
    each GPU or TPU) has access to the input data shard(s) that it needs to run the
    computation. This is what usually makes distributed data loading more complicated
    and challenging to implement correctly (compared with the alternatives described
    above). If the incorrect data shards end up on the wrong devices, the computation
    can still run without errors, since the computation has no way to know what the
    input data “should” be. However, the final result will often be incorrect, since
    the input data was different than intended.
  prefs: []
  type: TYPE_NORMAL
- en: General approach for loading a `jax.Array`
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Consider a case of creating a single `jax.Array` from raw data not produced
    by JAX. These concepts apply beyond loading batched data records, such as any
    multi-process `jax.Array` that wasn’t directly produced by a JAX computation.
    Examples include: 1) loading model weights from a checkpoint; or 2) loading a
    large spatially-sharded image.'
  prefs: []
  type: TYPE_NORMAL
- en: Every `jax.Array` has an associated `Sharding`, which describes which shard
    of the global data is required by each global device. When you create a `jax.Array`
    from scratch, you also need to create its `Sharding`. This is how JAX can understand
    how the data is laid out across devices. You can create whatever `Sharding` you
    want. In practice, you usually pick a `Sharding` based on what kind of parallelism
    strategy you are implementing (you will learn more about data and model parallelism
    in more detail later in this guide). You can also pick a `Sharding` based on how
    the raw data will be produced within each process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have defined a `Sharding`, you can use `addressable_devices()` to
    provide a list of devices needed to load data for within the current process.
    (Note: The term “addressable devices” is a more general version of “local devices”.
    The goal is to make sure that each process’s data loader provides the right data
    to all of that process’ local devices.'
  prefs: []
  type: TYPE_NORMAL
- en: Examples
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For example, consider a `(64, 128)` `jax.Array` that you need to shard across
    4 processes with 2 devices each (8 devices total). This will result in 8 unique
    data shards, one for each device. There are many ways to shard this `jax.Array`.
    You can perform a 1D sharding across the second dimension of the `jax.Array`,
    giving each device a `(64, 16)` shard, as demonstrated below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![8 unique data shards](img/1620c7594731e8a4457c14e5c5672ff1.png)'
  prefs: []
  type: TYPE_IMG
- en: In the above figure, each data shard has its own color to indicate which process
    needs to load that shard. For example, you assume process `0`’s 2 devices contain
    shards `A` and `B`, corresponding to the first `(64, 32)` piece of the global
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can pick a different distribution of shards to devices. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![8 unique data shards - different distribution](img/553038501f071e8cdbb6d2947da7e3e9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here is another example — a 2D sharding:'
  prefs: []
  type: TYPE_NORMAL
- en: '![2D sharding](img/2b5e3038a613ddadddc37216afbadaff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However the `jax.Array` happens to be sharded, you have to make sure that each
    process’s data loader is provided with/loads the required shard(s) of the global
    data. There are several high-level methods for achieving this: 1) load the global
    data in each process; 2) use a per-device data pipeline; 3) use a consolidated
    per-process data pipeline; 4) load data in some convenient way and then reshard
    inside computation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Option 1: Load the global data in each process'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Loading the global data in each process](img/8a324f72bc5b92cbd952104642608662.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Using this option, each process:'
  prefs: []
  type: TYPE_NORMAL
- en: Loads the full value needed; and
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Transfers only the needed shards to that process’s local devices.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is not an efficient approach to distributed data loading, since each process
    will throw away the data not needed by its local devices, and the total data ingested
    can be higher than necessary. But this option works and is relatively simple to
    implement, while the performance overhead may be acceptable for certain workloads
    (for example, if the global data is small).
  prefs: []
  type: TYPE_NORMAL
- en: 'Option 2: Use a per-device data pipeline'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Using a per-device data pipeline](img/c003002ad8634050d6b779752d92cf2d.png)'
  prefs: []
  type: TYPE_IMG
- en: In this option, each process sets up a data loader for each of its local devices
    (that is, each device gets its own data loader for just the data shard it requires).
  prefs: []
  type: TYPE_NORMAL
- en: 'This is efficient in terms of the data loaded. It can also sometimes be simpler
    to consider each device independently rather than all of a process’s local devices
    at once (refer to *Option 3: Use a consolidated per-process data pipeline* below).
    However, having multiple concurrent data loaders can sometimes cause performance
    issues.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Option 3: Use a consolidated per-process data pipeline'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Using a consolidated per-process data pipeline](img/4ec605833b964c8162d77874b20639ba.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you choose this option, each process:'
  prefs: []
  type: TYPE_NORMAL
- en: Sets up a single data loader that loads the data required for all of its local
    devices; and then
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Shards the local data before transferring to each local device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is the *most efficient way to do distributed loading*. However, it’s also
    the *most complex*, since logic is needed both to figure out which data is needed
    by each device, and to create a single data loading that loads only all of that
    data (and, ideally, no other extra data).
  prefs: []
  type: TYPE_NORMAL
- en: 'Option 4: Load data in some convenient way, reshard inside computation'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Loading  data in some convenient way, reshard inside computation](img/0990b88b78dc3375026a784b5d15ab95.png)'
  prefs: []
  type: TYPE_IMG
- en: This option is more challenging to explain, but often easier to implement than
    the above options (from 1 to 3).
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a scenario where it’s difficult or rather impossible to set up data
    loaders that load exactly the data you need, either for per-device or per-process
    loaders. However, it may still be possible to set up a data loader per process
    that loads `1 / num_processes` of the data, just not in the right sharding.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, continuing with your 2D example sharding from before, assume it is easier
    for each process to load a single column of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: Then, you can create a `jax.Array` with a `Sharding` representing the per-column
    data, pass that directly into the computation, and use `jax.lax.with_sharding_constraint()`
    to immediately reshard the column-sharded input to the desired sharding. And since
    the data is resharded inside the computation, it will be resharded over the accelerator
    communication links (for example, TPU ICI or NVLink).
  prefs: []
  type: TYPE_NORMAL
- en: 'This Option 4 has similar benefits to Option 3 (*Use a consolidated per-process
    data pipeline*):'
  prefs: []
  type: TYPE_NORMAL
- en: Each process still has a single data loader; and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The global data is loaded exactly once across all processes; and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The global data has the additional benefit of offering more flexibility in how
    the data is loaded.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, this approach uses accelerator interconnect bandwidth to perform the
    resharding, which may slow down certain workloads. Option 4 also requires that
    the input data be expressed as a separate `Sharding`, in addition to the target
    `Sharding`.
  prefs: []
  type: TYPE_NORMAL
- en: Replication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Replication describes a process where multiple devices have the same data shard.
    The general options mentioned above (Options 1 through 4) still work with replication.
    The only difference is that some processes may end up loading the same data shards.
    This section describes full replication and partial replication.
  prefs: []
  type: TYPE_NORMAL
- en: Full replication
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Full replication** is a process where all devices have a full copy of the
    data (that is, the data “shard” is the entire array value).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the below example, since there are 8 devices in total (2 per process), you
    will end up with 8 copies of the full data. Each copy of the data is unsharded,
    that is the copy lives on a single device:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Full replication](img/1cb84863cdedd7bd0d22230758242771.png)'
  prefs: []
  type: TYPE_IMG
- en: Partial replication
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Partial replication** describes a process where there are multiple copies
    of the data, and each copy is sharded across multiple devices. For a given array
    value, there are generally many possible ways to perform partial replication (Note:
    There is always a single fully-replicated `Sharding` for a given array shape).'
  prefs: []
  type: TYPE_NORMAL
- en: Below are two possible examples.
  prefs: []
  type: TYPE_NORMAL
- en: In the first example below, each copy is sharded across the two local devices
    of a process, for a total of 4 copies. This means that each process will need
    to load the full global data, since its local devices will have a full copy of
    the data.
  prefs: []
  type: TYPE_NORMAL
- en: '![Partial replication - example 1](img/768f3cfac402875aec715ae83d5d8f0f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the second example below, each copy is still sharded across two devices,
    but each device pair is spread across two different processes. Process `0` (pink)
    and process `1` (yellow) both need to load just the first row of the data, and
    process `2` (green) and process `3` (blue) both need to load just the second row
    of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Partial replication - example 2](img/0316e1037c0a936ae5295cdf7e2217dc.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that you’ve gone over the high-level options for creating a `jax.Array`,
    let’s apply them to data loading for ML applications.
  prefs: []
  type: TYPE_NORMAL
- en: Data parallelism
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In *pure data parallelism* (without model parallelism):'
  prefs: []
  type: TYPE_NORMAL
- en: You replicate the model on each device; and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each model replica (that is, each device) receives a different per-replica batch
    of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Data parallelism - example 1](img/ed0ee4ec93d8c1e7b06e7f3b4f1fca51.png)'
  prefs: []
  type: TYPE_IMG
- en: When representing the input data as a single `jax.Array`, the Array contains
    the data across all replicas for this step (this is called *global batch*), with
    each shard of the `jax.Array` containing a single per-replica batch. You can represent
    this as a 1D sharding across all devices (check the example below) — in other
    words, the global batch is composed of all the per-replica batches concatenated
    together across the batch axis.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data parallelism - example 2](img/ba9ccdcbb454af1cccf0d1441e54be69.png)'
  prefs: []
  type: TYPE_IMG
- en: Applying this framework, you may conclude that process `0` should get the first
    quarter (2 out of 8) of the global batch, while process `1` should get the second,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: But how can you know what the first quarter is? And how do you make sure process
    `0` gets the first quarter? Luckily, there’s a very important trick about data
    parallelism that means you don’t have to answer these questions and makes the
    whole setup simpler.
  prefs: []
  type: TYPE_NORMAL
- en: Important trick about data parallelism
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The trick is you don’t need to care which per-replica batch lands on which replica.
    Therefore, it doesn’t matter which process loads a batch. The reason is that since
    each device corresponds to a model replica performing the same thing, it doesn’t
    matter which device gets which per-replica batch within the global batch.
  prefs: []
  type: TYPE_NORMAL
- en: What this means is that you are free to rearrange the per-replica batches within
    the global batch. In other words, you are free to randomize which data shard each
    device gets.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Data parallelism - example 3](img/3e63f708dff32add917838e5b324e494.png)'
  prefs: []
  type: TYPE_IMG
- en: Usually, rearranging the data shards of a `jax.Array`, as demonstrated above,
    is not a good idea – you’re effectively permuting the value of the `jax.Array`!
    However, for data parallelism, the global batch order isn’t meaningful, and you
    are free to rearrange the per-replica batches in the global batch, as already
    mentioned before.
  prefs: []
  type: TYPE_NORMAL
- en: This simplifies data loading because it means each device just needs an independent
    stream of per-replica batches, which can be easily implemented in most data loaders
    by creating an independent pipeline per process and chunking the resulting per-process
    batch into per-replica batches.
  prefs: []
  type: TYPE_NORMAL
- en: '![Data parallelism - example 4](img/bc7cc20323c4155fcc2e3796b156a09c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This is an instance of the *Option 2: Consolidated per-process data pipeline*.
    You can also use other options (such as 0, 1 and 3, which are covered earlier
    in this document), but this one is relatively simple and efficient.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of how to implement this setup using tf.data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Data + model parallelism
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In **model parallelism** you shard each model replica across multiple devices.
    If you use **pure model parallelism** (without data parallelism):'
  prefs: []
  type: TYPE_NORMAL
- en: There’s just one model replica sharded across all devices; and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The data is (usually) fully replicated across all devices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This guide considers a case where you use **both data and model parallelism**:'
  prefs: []
  type: TYPE_NORMAL
- en: You shard each of the multiple model replicas over multiple devices; and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You partially replicate the data over each model replica — each device in the
    same model replica gets the same per-replica batch, and devices across model replicas
    get different per-replica batches.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model parallelism within a process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the purposes of data loading, the simplest approach can be to shard each
    model replica within the local devices of a single process.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, let’s switch to 2 processes with 4 devices each (instead
    of 4 processes with 2 devices each). Consider a scenario where each model replica
    is sharded over the 2 local devices of a single process. This results in 2 model
    replicas per process and 4 model replicas total, as demonstrated below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Data and model parallelism - example 1](img/50baf940e74eaaba1fae84e721a0aaa4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here, once again, the input data is represented as a single `jax.Array` with
    a 1D sharding where each shard is a per-replica batch with an exception:'
  prefs: []
  type: TYPE_NORMAL
- en: Unlike in the pure data parallelism case, you introduce partial replication
    and make 2 copies of the 1D-sharded global batch.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is because each model replica is composed of 2 devices that each need a
    copy of the per-replica batch.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Data and model parallelism - example 2](img/425e3c08e61ea384503426e6ae0c0694.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Keeping each model replica within a single process can make things simpler
    because you can reuse the pure data parallelism setup described above, except
    you also need to replicate the per-replica batches:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Data and model parallelism - example 3](img/950f554f9d89e6e9dc75e0db17844e61.png)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: '*It’s also very important to replicate the per-replica batches to the correct
    devices!* While the very important trick about data parallelism means you don’t
    care which batch ends up on which replica, *you do care that a single replica
    only gets a single batch*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, this is OK:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Data and model parallelism - example 4](img/e1fa137c8543477be6e375d42972ccce.png)'
  prefs: []
  type: TYPE_IMG
- en: 'However, if you’re not careful about which local device you load each batch
    onto, you may accidentally create unreplicated data, even though the `Sharding`
    (and the parallelism strategy) says the data is replicated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Data and model parallelism - example 4](img/c9ccdf8d01126f142e7af011fbdf39e7.png)'
  prefs: []
  type: TYPE_IMG
- en: JAX will raise an error if you accidentally create a `jax.Array` with unreplicated
    data that should be replicated within a single process (this isn’t always true
    for model parallelism across processes though; see the next section).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example of how to implement per-process model parallelism and data
    parallelism using `tf.data`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Model parallelism across processes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It can get more interesting when model replicas are spread across processes,
    either:'
  prefs: []
  type: TYPE_NORMAL
- en: Because a single replica can’t fit within a process; or
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because the device assignment just isn’t set up that way.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, going back to the previous setup of 4 processes with 2 devices
    each, if you assign devices to replicas like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Model parallelism across processes - example 1](img/faead091f47b3535fb0995d91ffc61f4.png)'
  prefs: []
  type: TYPE_IMG
- en: This is the same parallelism strategy as the previous per-process model parallelism
    example – 4 model replicas each sharded across 2 devices. The only difference
    is the device assignment – each replica’s two devices are split across different
    processes, and each process is only responsible for one copy of each per-replica
    batch (but for two replicas).
  prefs: []
  type: TYPE_NORMAL
- en: Splitting the model replicas across processes like this may seem like an arbitrary
    and unnecessary thing to do (and in this example it arguably is), but actual deployments
    may end up with this kind of device assignment to best take advantage of the communication
    links between devices.
  prefs: []
  type: TYPE_NORMAL
- en: Data loading now becomes more complicated because some extra coordination is
    required across processes. In the pure data parallelism and per-process model
    parallelism cases, it was only important that each process loaded a unique data
    stream. Now certain processes must load the same data, and some must load different
    data. In the above example, processes `0` and `2` (in colors pink and green, respectively)
    must load the same 2 per-replica batches, and processes `1` and `3` (colors yellow
    and blue, respectively) must also load the same 2 per-replica batches (but different
    from process `0` and `2`’s batches).
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, it’s important that each process doesn’t mix up its 2 per-replica
    batches. While you don’t care which batch lands on which replica (the very important
    trick about data parallelism), you need to care that all the devices in a replica
    get the same batch. For example, this would be bad:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Model parallelism across processes - example 2](img/03432bedef0f4b0734a8ee71aea5f19c.png)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: As of August 2023, JAX cannot detect if `jax.Array` shards across processes
    are supposed to be replicated but aren’t, and will produce wrong results when
    the computation is run. So be careful not to do this!
  prefs: []
  type: TYPE_NORMAL
- en: 'To get the correct per-replica batch on each device, you need to represent
    the global input data as the following `jax.Array`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Model parallelism across processes - example 3](img/17939e84e2dbae73c80e0b1c07382fa2.png)'
  prefs: []
  type: TYPE_IMG
