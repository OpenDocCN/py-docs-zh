# 4.3。内存管理

> 原文： [http://numba.pydata.org/numba-doc/latest/cuda-reference/memory.html](http://numba.pydata.org/numba-doc/latest/cuda-reference/memory.html)

```py
numba.cuda.to_device(obj, stream=0, copy=True, to=None)
```

将 numpy ndarray 或结构化标量分配并传输到设备。

要将 host-＆gt;设备复制为 numpy 数组：

```py
ary = np.arange(10)
d_ary = cuda.to_device(ary)

```

要将传输排入队列：

```py
stream = cuda.stream()
d_ary = cuda.to_device(ary, stream=stream)

```

得到的`d_ary`是`DeviceNDArray`。

要复制 device-＆gt;主机：

```py
hary = d_ary.copy_to_host()

```

要将 device-＆gt;主机复制到现有数组：

```py
ary = np.empty(shape=d_ary.shape, dtype=d_ary.dtype)
d_ary.copy_to_host(ary)

```

要将传输排入队列：

```py
hary = d_ary.copy_to_host(stream=stream)

```

```py
numba.cuda.device_array(shape, dtype=np.float, strides=None, order='C', stream=0)
```

分配一个空设备 ndarray。与`numpy.empty()`类似。

```py
numba.cuda.device_array_like(ary, stream=0)
```

使用数组中的信息调用 cuda.devicearray（）。

```py
numba.cuda.pinned_array(shape, dtype=np.float, strides=None, order='C')
```

使用固定（页面锁定）的缓冲区分配 np.ndarray。与 np.empty（）类似。

```py
numba.cuda.mapped_array(shape, dtype=np.float, strides=None, order='C', stream=0, portable=False, wc=False)
```

使用固定并映射到设备的缓冲区分配映射的 ndarray。与 np.empty（）相似

| 参数： | 

*   **便携式** - 一个布尔标志，允许分配的设备内存在多个设备中使用。
*   **wc** - 一个布尔标志，用于启用写组合分配，主机写入和设备读取速度更快，但主机写入速度较慢，设备写入速度较慢。

 |
| --- | --- |

```py
numba.cuda.pinned(*arylist)
```

用于临时固定主机 ndarray 序列的上下文管理器。

```py
numba.cuda.mapped(*arylist, **kws)
```

用于临时映射主机 ndarray 序列的上下文管理器。

## 4.3.1。设备对象

```py
class numba.cuda.cudadrv.devicearray.DeviceNDArray(shape, strides, dtype, stream=0, writeback=None, gpu_data=None)
```

GPU 上阵列类型

```py
copy_to_device(ary, stream=0)
```

将 &lt;cite&gt;ary&lt;/cite&gt; 复制到 &lt;cite&gt;self&lt;/cite&gt; 。

如果 &lt;cite&gt;ary&lt;/cite&gt; 是 CUDA 内存，请执行设备到设备传输。否则，执行主机到设备传输。

```py
copy_to_host(ary=None, stream=0)
```

如果`ary`为`None`，则将`self`复制到`ary`或创建新的 Numpy ndarray。

如果给出了 CUDA `stream`，则传输将作为给定流的一部分异步进行。否则，传输是同步的：复制完成后函数返回。

始终返回主机阵列。

例：

```py
import numpy as np
from numba import cuda

arr = np.arange(1000)
d_arr = cuda.to_device(arr)

my_kernel[100, 100](d_arr)

result_array = d_arr.copy_to_host()

```

```py
is_c_contiguous()
```

如果数组是 C-contiguous，则返回 true。

```py
is_f_contiguous()
```

如果数组是 Fortran-contiguous，则返回 true。

```py
ravel(order='C', stream=0)
```

在不改变其内容的情况下展平阵列，类似于 [`numpy.ndarray.ravel()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.ravel.html#numpy.ndarray.ravel "(in NumPy v1.16)") 。

```py
reshape(*newshape, **kws)
```

与 [`numpy.ndarray.reshape()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.reshape.html#numpy.ndarray.reshape "(in NumPy v1.16)") 类似，重塑阵列而不改变其内容。例：

```py
d_arr = d_arr.reshape(20, 50, order='F')

```

```py
split(section, stream=0)
```

将数组拆分为&lt;cite&gt;部分&lt;/cite&gt;大小的相等分区。如果阵列不能平均分割，则最后一部分将更小。

```py
class numba.cuda.cudadrv.devicearray.DeviceRecord(dtype, stream=0, gpu_data=None)
```

GPU 上的记录类型

```py
copy_to_device(ary, stream=0)
```

将 &lt;cite&gt;ary&lt;/cite&gt; 复制到 &lt;cite&gt;self&lt;/cite&gt; 。

如果 &lt;cite&gt;ary&lt;/cite&gt; 是 CUDA 内存，请执行设备到设备传输。否则，执行主机到设备传输。

```py
copy_to_host(ary=None, stream=0)
```

如果`ary`为`None`，则将`self`复制到`ary`或创建新的 Numpy ndarray。

如果给出了 CUDA `stream`，则传输将作为给定流的一部分异步进行。否则，传输是同步的：复制完成后函数返回。

始终返回主机阵列。

例：

```py
import numpy as np
from numba import cuda

arr = np.arange(1000)
d_arr = cuda.to_device(arr)

my_kernel[100, 100](d_arr)

result_array = d_arr.copy_to_host()

```

```py
class numba.cuda.cudadrv.devicearray.MappedNDArray(shape, strides, dtype, stream=0, writeback=None, gpu_data=None)
```

使用 CUDA 映射内存的主机阵列。

```py
copy_to_device(ary, stream=0)
```

将 &lt;cite&gt;ary&lt;/cite&gt; 复制到 &lt;cite&gt;self&lt;/cite&gt; 。

如果 &lt;cite&gt;ary&lt;/cite&gt; 是 CUDA 内存，请执行设备到设备传输。否则，执行主机到设备传输。

```py
copy_to_host(ary=None, stream=0)
```

如果`ary`为`None`，则将`self`复制到`ary`或创建新的 Numpy ndarray。

如果给出了 CUDA `stream`，则传输将作为给定流的一部分异步进行。否则，传输是同步的：复制完成后函数返回。

始终返回主机阵列。

例：

```py
import numpy as np
from numba import cuda

arr = np.arange(1000)
d_arr = cuda.to_device(arr)

my_kernel[100, 100](d_arr)

result_array = d_arr.copy_to_host()

```

```py
split(section, stream=0)
```

将数组拆分为&lt;cite&gt;部分&lt;/cite&gt;大小的相等分区。如果阵列不能平均分割，则最后一部分将更小。