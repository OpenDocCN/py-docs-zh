# JAX 中的广义卷积

> 原文：[`jax.readthedocs.io/en/latest/notebooks/convolutions.html`](https://jax.readthedocs.io/en/latest/notebooks/convolutions.html)

![在 Colab 中打开](https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/convolutions.ipynb) ![在 Kaggle 中打开](https://kaggle.com/kernels/welcome?src=https://github.com/google/jax/blob/main/docs/notebooks/convolutions.ipynb)

JAX 提供了多种接口来跨数据计算卷积，包括：

+   `jax.numpy.convolve()`（也有`jax.numpy.correlate()`）

+   `jax.scipy.signal.convolve()`（也有`correlate()`）

+   `jax.scipy.signal.convolve2d()`（也有`correlate2d()`）

+   `jax.lax.conv_general_dilated()`

对于基本的卷积操作，`jax.numpy` 和 `jax.scipy` 的操作通常足够使用。如果要进行更一般的批量多维卷积，`jax.lax` 函数是你应该开始的地方。

## 基本的一维卷积

基本的一维卷积由`jax.numpy.convolve()`实现，它为[`numpy.convolve()`](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html#numpy.convolve "(在 NumPy v2.0)")提供了一个 JAX 接口。这里是通过卷积实现的简单一维平滑的例子：

```py
import matplotlib.pyplot as plt

from jax import random
import jax.numpy as jnp
import numpy as np

key = random.key(1701)

x = jnp.linspace(0, 10, 500)
y = jnp.sin(x) + 0.2 * random.normal(key, shape=(500,))

window = jnp.ones(10) / 10
y_smooth = jnp.convolve(y, window, mode='same')

plt.plot(x, y, 'lightgray')
plt.plot(x, y_smooth, 'black'); 
```

![../_images/e961d0a0fbc2816ce80591a1da477bbb60ca788cd7033a4fd6553e0369a2dcbf.png](img/f79966682ffcbcb8f10ef6a819cfc5da.png)

`mode`参数控制如何处理边界条件；这里我们使用`mode='same'`确保输出与输入大小相同。

欲了解更多信息，请参阅`jax.numpy.convolve()`文档，或与原始[`numpy.convolve()`](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html#numpy.convolve "(在 NumPy v2.0)")函数相关的文档。

## 基本的*N*维卷积

对于*N*维卷积，`jax.scipy.signal.convolve()`提供了类似于`jax.numpy.convolve()`的界面，推广到*N*维。

例如，这里是一种使用高斯滤波器进行图像去噪的简单方法：

```py
from scipy import misc
import jax.scipy as jsp

fig, ax = plt.subplots(1, 3, figsize=(12, 5))

# Load a sample image; compute mean() to convert from RGB to grayscale.
image = jnp.array(misc.face().mean(-1))
ax[0].imshow(image, cmap='binary_r')
ax[0].set_title('original')

# Create a noisy version by adding random Gaussian noise
key = random.key(1701)
noisy_image = image + 50 * random.normal(key, image.shape)
ax[1].imshow(noisy_image, cmap='binary_r')
ax[1].set_title('noisy')

# Smooth the noisy image with a 2D Gaussian smoothing kernel.
x = jnp.linspace(-3, 3, 7)
window = jsp.stats.norm.pdf(x) * jsp.stats.norm.pdf(x[:, None])
smooth_image = jsp.signal.convolve(noisy_image, window, mode='same')
ax[2].imshow(smooth_image, cmap='binary_r')
ax[2].set_title('smoothed'); 
```

```py
/tmp/ipykernel_1464/4118182506.py:7: DeprecationWarning: scipy.misc.face has been deprecated in SciPy v1.10.0; and will be completely removed in SciPy v1.12.0\. Dataset methods have moved into the scipy.datasets module. Use scipy.datasets.face instead.
  image = jnp.array(misc.face().mean(-1)) 
```

![../_images/cfa90156f790ef47f43618a7b4369c686b8a52f253f7f316ccc76360b27b1090.png](img/7d961651756c17c0a99c98f086c5ea09.png)

如同一维情况，我们使用`mode='same'`指定如何处理边缘。有关*N*维卷积中可用选项的更多信息，请参阅`jax.scipy.signal.convolve()`文档。

## 广义卷积

对于在构建深度神经网络中通常有用的更一般类型的批量卷积，JAX 和 XLA 提供了非常通用的 N 维**conv_general_dilated**函数，但如何使用它并不是很明显。我们将给出一些常见用例的示例。

一篇关于卷积算术的家族调查，[卷积算术指南](https://arxiv.org/abs/1603.07285)，强烈推荐阅读！

让我们定义一个简单的对角边缘核：

```py
# 2D kernel - HWIO layout
kernel = jnp.zeros((3, 3, 3, 3), dtype=jnp.float32)
kernel += jnp.array([[1, 1, 0],
                     [1, 0,-1],
                     [0,-1,-1]])[:, :, jnp.newaxis, jnp.newaxis]

print("Edge Conv kernel:")
plt.imshow(kernel[:, :, 0, 0]); 
```

```py
Edge Conv kernel: 
```

![../_images/c1b68affefa9c6fa409beeda4a0301aba932fec55465efd74fcdffd03f04faa8.png](img/276d4a01c60ff957e05745fcbbf0e1d2.png)

接下来我们将创建一个简单的合成图像：

```py
# NHWC layout
img = jnp.zeros((1, 200, 198, 3), dtype=jnp.float32)
for k in range(3):
  x = 30 + 60*k
  y = 20 + 60*k
  img = img.at[0, x:x+10, y:y+10, k].set(1.0)

print("Original Image:")
plt.imshow(img[0]); 
```

```py
Original Image: 
```

![../_images/1ed93c894919df616fdd321a7985a911cc662cb1e021c0951116ab0821b042d2.png](img/5caffdc29f11de4c01519d9c3dd8c14d.png)

### `lax.conv` 和 `lax.conv_with_general_padding`

这些是卷积的简单便捷函数

️⚠️ 便捷函数 `lax.conv`，`lax.conv_with_general_padding` 假定 **NCHW** 图像和 **OIHW** 卷积核。

```py
from jax import lax
out = lax.conv(jnp.transpose(img,[0,3,1,2]),    # lhs = NCHW image tensor
               jnp.transpose(kernel,[3,2,0,1]), # rhs = OIHW conv kernel tensor
               (1, 1),  # window strides
               'SAME') # padding mode
print("out shape: ", out.shape)
print("First output channel:")
plt.figure(figsize=(10,10))
plt.imshow(np.array(out)[0,0,:,:]); 
```

```py
out shape:  (1, 3, 200, 198)
First output channel: 
```

![../_images/d9bee780828085fbc09b1d92d421d3003963e72bbe4c17ab02bbe9fcfc18edbd.png](img/2e5efe6381662a2a7ed237ba757bc4d6.png)

```py
out = lax.conv_with_general_padding(
  jnp.transpose(img,[0,3,1,2]),    # lhs = NCHW image tensor
  jnp.transpose(kernel,[2,3,0,1]), # rhs = IOHW conv kernel tensor
  (1, 1),  # window strides
  ((2,2),(2,2)), # general padding 2x2
  (1,1),  # lhs/image dilation
  (1,1))  # rhs/kernel dilation
print("out shape: ", out.shape)
print("First output channel:")
plt.figure(figsize=(10,10))
plt.imshow(np.array(out)[0,0,:,:]); 
```

```py
out shape:  (1, 3, 202, 200)
First output channel: 
```

![../_images/2daccd0cd7424c739ea9d1af43c2dfd330c45cea6ce5a8dc0196126917bed5e7.png](img/540b5f46a71aa47f61baf1763c4450b1.png)

### 维度编号定义了 `conv_general_dilated` 的维度布局

重要的参数是轴布局的三元组：（输入布局，卷积核布局，输出布局）

+   **N** - 批次维度

+   **H** - 空间高度

+   **W** - 空间宽度

+   **C** - 通道维度

+   **I** - 卷积核 *输入* 通道维度

+   **O** - 卷积核 *输出* 通道维度

⚠️ 为了展示维度编号的灵活性，我们选择了 **NHWC** 图像和 **HWIO** 卷积核约定，如下所示 `lax.conv_general_dilated`。

```py
dn = lax.conv_dimension_numbers(img.shape,     # only ndim matters, not shape
                                kernel.shape,  # only ndim matters, not shape 
                                ('NHWC', 'HWIO', 'NHWC'))  # the important bit
print(dn) 
```

```py
ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) 
```

#### SAME 填充，无步长，无扩张

```py
out = lax.conv_general_dilated(img,    # lhs = image tensor
                               kernel, # rhs = conv kernel tensor
                               (1,1),  # window strides
                               'SAME', # padding mode
                               (1,1),  # lhs/image dilation
                               (1,1),  # rhs/kernel dilation
                               dn)     # dimension_numbers = lhs, rhs, out dimension permutation
print("out shape: ", out.shape)
print("First output channel:")
plt.figure(figsize=(10,10))
plt.imshow(np.array(out)[0,:,:,0]); 
```

```py
out shape:  (1, 200, 198, 3)
First output channel: 
```

![../_images/d9bee780828085fbc09b1d92d421d3003963e72bbe4c17ab02bbe9fcfc18edbd.png](img/2e5efe6381662a2a7ed237ba757bc4d6.png)

#### VALID 填充，无步长，无扩张

```py
out = lax.conv_general_dilated(img,     # lhs = image tensor
                               kernel,  # rhs = conv kernel tensor
                               (1,1),   # window strides
                               'VALID', # padding mode
                               (1,1),   # lhs/image dilation
                               (1,1),   # rhs/kernel dilation
                               dn)      # dimension_numbers = lhs, rhs, out dimension permutation
print("out shape: ", out.shape, "DIFFERENT from above!")
print("First output channel:")
plt.figure(figsize=(10,10))
plt.imshow(np.array(out)[0,:,:,0]); 
```

```py
out shape:  (1, 198, 196, 3) DIFFERENT from above!
First output channel: 
```

![../_images/d8f21810f67381c4e5e5ba5e6bcd0f0d8b830af5381b0975dec0b9b38a51afce.png](img/f80b1d21fa54cf1f49fe574b81f958ef.png)

#### SAME 填充，2,2 步长，无扩张

```py
out = lax.conv_general_dilated(img,    # lhs = image tensor
                               kernel, # rhs = conv kernel tensor
                               (2,2),  # window strides
                               'SAME', # padding mode
                               (1,1),  # lhs/image dilation
                               (1,1),  # rhs/kernel dilation
                               dn)     # dimension_numbers = lhs, rhs, out dimension permutation
print("out shape: ", out.shape, " <-- half the size of above")
plt.figure(figsize=(10,10))
print("First output channel:")
plt.imshow(np.array(out)[0,:,:,0]); 
```

```py
out shape:  (1, 100, 99, 3)  <-- half the size of above
First output channel: 
```

![../_images/8051cc233d17fe493c7e0ffd2c2dbc0773e61b4d1138afef6d075b8d8cbfb3cc.png](img/37a5838c540df746a86ce15d3bb0ef71.png)

#### VALID 填充，无步长，rhs 卷积核扩张 ~ 膨胀卷积（用于演示）

```py
out = lax.conv_general_dilated(img,     # lhs = image tensor
                               kernel,  # rhs = conv kernel tensor
                               (1,1),   # window strides
                               'VALID', # padding mode
                               (1,1),   # lhs/image dilation
                               (12,12), # rhs/kernel dilation
                               dn)      # dimension_numbers = lhs, rhs, out dimension permutation
print("out shape: ", out.shape)
plt.figure(figsize=(10,10))
print("First output channel:")
plt.imshow(np.array(out)[0,:,:,0]); 
```

```py
out shape:  (1, 176, 174, 3)
First output channel: 
```

![../_images/3242ab6a93d02ac641e42bd7b9087627444554747e07711b8e61b41904571b71.png](img/4f16c994e14bbfdd9d099fffc2e5abd9.png)

#### VALID 填充，无步长，lhs=input 扩张 ~ 转置卷积

```py
out = lax.conv_general_dilated(img,               # lhs = image tensor
                               kernel,            # rhs = conv kernel tensor
                               (1,1),             # window strides
                               ((0, 0), (0, 0)),  # padding mode
                               (2,2),             # lhs/image dilation
                               (1,1),             # rhs/kernel dilation
                               dn)                # dimension_numbers = lhs, rhs, out dimension permutation
print("out shape: ", out.shape, "<-- larger than original!")
plt.figure(figsize=(10,10))
print("First output channel:")
plt.imshow(np.array(out)[0,:,:,0]); 
```

```py
out shape:  (1, 397, 393, 3) <-- larger than original!
First output channel: 
```

![../_images/c3363d9a17e1cf60f967a6658f171abff3a047bd9a6dc9a57f7c3f5850964c82.png](img/cb19dd89902788c0e2cc076ec1a48289.png)

我们可以用最后一个示例，比如实现 *转置卷积*：

```py
# The following is equivalent to tensorflow:
# N,H,W,C = img.shape
# out = tf.nn.conv2d_transpose(img, kernel, (N,2*H,2*W,C), (1,2,2,1))

# transposed conv = 180deg kernel rotation plus LHS dilation
# rotate kernel 180deg:
kernel_rot = jnp.rot90(jnp.rot90(kernel, axes=(0,1)), axes=(0,1))
# need a custom output padding:
padding = ((2, 1), (2, 1))
out = lax.conv_general_dilated(img,     # lhs = image tensor
                               kernel_rot,  # rhs = conv kernel tensor
                               (1,1),   # window strides
                               padding, # padding mode
                               (2,2),   # lhs/image dilation
                               (1,1),   # rhs/kernel dilation
                               dn)      # dimension_numbers = lhs, rhs, out dimension permutation
print("out shape: ", out.shape, "<-- transposed_conv")
plt.figure(figsize=(10,10))
print("First output channel:")
plt.imshow(np.array(out)[0,:,:,0]); 
```

```py
out shape:  (1, 400, 396, 3) <-- transposed_conv
First output channel: 
```

![../_images/a31887582f261bc887008a3d1ccc329a276e965031f3a3d6f07365c86b694ede.png](img/49ff0f7697e4e37e9bc87de4910d5344.png)

### 1D 卷积

你不仅限于 2D 卷积，下面是一个简单的 1D 演示：

```py
# 1D kernel - WIO layout
kernel = jnp.array([[[1, 0, -1], [-1,  0,  1]], 
                    [[1, 1,  1], [-1, -1, -1]]], 
                    dtype=jnp.float32).transpose([2,1,0])
# 1D data - NWC layout
data = np.zeros((1, 200, 2), dtype=jnp.float32)
for i in range(2):
  for k in range(2):
      x = 35*i + 30 + 60*k
      data[0, x:x+30, k] = 1.0

print("in shapes:", data.shape, kernel.shape)

plt.figure(figsize=(10,5))
plt.plot(data[0]);
dn = lax.conv_dimension_numbers(data.shape, kernel.shape,
                                ('NWC', 'WIO', 'NWC'))
print(dn)

out = lax.conv_general_dilated(data,   # lhs = image tensor
                               kernel, # rhs = conv kernel tensor
                               (1,),   # window strides
                               'SAME', # padding mode
                               (1,),   # lhs/image dilation
                               (1,),   # rhs/kernel dilation
                               dn)     # dimension_numbers = lhs, rhs, out dimension permutation
print("out shape: ", out.shape)
plt.figure(figsize=(10,5))
plt.plot(out[0]); 
```

```py
in shapes: (1, 200, 2) (3, 2, 2)
ConvDimensionNumbers(lhs_spec=(0, 2, 1), rhs_spec=(2, 1, 0), out_spec=(0, 2, 1))
out shape:  (1, 200, 2) 
```

![../_images/f14439a560314f430af73acf634bc696a09066b2609b4e5bace068b40cbfe639.png](img/dba7566216d992189974ce9f231aa30c.png) ![../_images/a816d20e944cdb9853c00466568be6f3d6f956c461202d6b33c6b4a821c21748.png](img/000dc195ccf8e4a2a374335c2321b133.png)

### 3D 卷积

```py
import matplotlib as mpl

# Random 3D kernel - HWDIO layout
kernel = jnp.array([
  [[0, 0,  0], [0,  1,  0], [0,  0,   0]],
  [[0, -1, 0], [-1, 0, -1], [0,  -1,  0]], 
  [[0, 0,  0], [0,  1,  0], [0,  0,   0]]], 
  dtype=jnp.float32)[:, :, :, jnp.newaxis, jnp.newaxis]

# 3D data - NHWDC layout
data = jnp.zeros((1, 30, 30, 30, 1), dtype=jnp.float32)
x, y, z = np.mgrid[0:1:30j, 0:1:30j, 0:1:30j]
data += (jnp.sin(2*x*jnp.pi)*jnp.cos(2*y*jnp.pi)*jnp.cos(2*z*jnp.pi))[None,:,:,:,None]

print("in shapes:", data.shape, kernel.shape)
dn = lax.conv_dimension_numbers(data.shape, kernel.shape,
                                ('NHWDC', 'HWDIO', 'NHWDC'))
print(dn)

out = lax.conv_general_dilated(data,    # lhs = image tensor
                               kernel,  # rhs = conv kernel tensor
                               (1,1,1), # window strides
                               'SAME',  # padding mode
                               (1,1,1), # lhs/image dilation
                               (1,1,1), # rhs/kernel dilation
                               dn)      # dimension_numbers
print("out shape: ", out.shape)

# Make some simple 3d density plots:
from mpl_toolkits.mplot3d import Axes3D
def make_alpha(cmap):
  my_cmap = cmap(jnp.arange(cmap.N))
  my_cmap[:,-1] = jnp.linspace(0, 1, cmap.N)**3
  return mpl.colors.ListedColormap(my_cmap)
my_cmap = make_alpha(plt.cm.viridis)
fig = plt.figure()
ax = fig.add_subplot(projection='3d')
ax.scatter(x.ravel(), y.ravel(), z.ravel(), c=data.ravel(), cmap=my_cmap)
ax.axis('off')
ax.set_title('input')
fig = plt.figure()
ax = fig.add_subplot(projection='3d')
ax.scatter(x.ravel(), y.ravel(), z.ravel(), c=out.ravel(), cmap=my_cmap)
ax.axis('off')
ax.set_title('3D conv output'); 
```

```py
in shapes: (1, 30, 30, 30, 1) (3, 3, 3, 1, 1)
ConvDimensionNumbers(lhs_spec=(0, 4, 1, 2, 3), rhs_spec=(4, 3, 0, 1, 2), out_spec=(0, 4, 1, 2, 3))
out shape:  (1, 30, 30, 30, 1) 
```

![../_images/aa5fabdf6a7e20bcb9b3f6ed4fdecb7c85355a4c25dbf8bd5083f19fc5e44ccc.png](img/c19aa20810da1132fc4c052d9d9faa85.png) ![../_images/f7f2915cb609bebbd6319369ebe9fb40e258ed1ca2c6e92c5ee2ac275562cb94.png](img/317130b3b016ffbed6b09e7292976eb7.png)
