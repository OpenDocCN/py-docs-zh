# jax.experimental.pjit 模块

> 原文：[`jax.readthedocs.io/en/latest/jax.experimental.pjit.html`](https://jax.readthedocs.io/en/latest/jax.experimental.pjit.html)

## API

```py
jax.experimental.pjit.pjit(fun, in_shardings=UnspecifiedValue, out_shardings=UnspecifiedValue, static_argnums=None, static_argnames=None, donate_argnums=None, donate_argnames=None, keep_unused=False, device=None, backend=None, inline=False, abstracted_axes=None)
```

使`fun`编译并自动跨多设备分区。

注意：此函数现在等同于 jax.jit，请改用其代替。返回的函数语义与`fun`相同，但编译为在多个设备（例如多个 GPU 或多个 TPU 核心）上并行运行的 XLA 计算。如果`fun`的 jitted 版本无法适应单个设备的内存，或者为了通过在多个设备上并行运行每个操作来加速`fun`，这将非常有用。

设备上的分区自动基于`in_shardings`中指定的输入分区传播以及`out_shardings`中指定的输出分区进行。这两个参数中指定的资源必须引用由`jax.sharding.Mesh()`上下文管理器定义的网格轴。请注意，`pjit()`应用时的网格定义将被忽略，并且返回的函数将使用每个调用站点可用的网格定义。

未经正确分区的`pjit()`函数输入将自动跨设备分区。在某些情况下，确保输入已经正确预分区可能会提高性能。例如，如果将一个`pjit()`函数的输出传递给另一个`pjit()`函数（或者在循环中使用同一个`pjit()`函数），请确保相关的`out_shardings`与相应的`in_shardings`匹配。

注意

**多进程平台：** 在诸如 TPU pods 的多进程平台上，`pjit()`可用于跨所有可用设备和进程运行计算。为实现此目的，`pjit()`设计为用于 SPMD Python 程序，其中每个进程运行相同的 Python 代码，以便所有进程按相同顺序运行相同的`pjit()`函数。

在此配置中运行时，网格应包含跨所有进程的设备。所有输入参数必须具有全局形状。`fun`仍将在网格中的*所有*设备上执行，包括来自其他进程的设备，并且将以全局视图处理跨多个进程展布的数据作为单个数组。

SPMD 模型还要求所有进程中运行的相同多进程`pjit()`函数必须按相同顺序运行，但可以与在单个进程中运行的任意操作交替进行。

参数：

+   **fun**（[*Callable*](https://docs.python.org/3/library/typing.html#typing.Callable "(在 Python v3.12 中)")） - 要编译的函数。应为纯函数，因为副作用只能执行一次。其参数和返回值应为数组、标量或其（嵌套的）标准 Python 容器（元组/列表/字典）。由 `static_argnums` 指示的位置参数可以是任何东西，只要它们是可散列的并且定义了相等操作。静态参数包含在编译缓存键中，这就是为什么必须定义哈希和相等运算符。

+   **in_shardings** –

    与 `fun` 参数匹配的 pytree 结构，所有实际参数都替换为资源分配规范。还可以指定一个 pytree 前缀（例如，替换整个子树的一个值），在这种情况下，叶子将广播到该子树的所有值。

    `in_shardings` 参数是可选的。JAX 将从输入的 `jax.Array` 推断出分片，并在无法推断出分片时默认复制输入。

    有效的资源分配规范包括：

    +   `Sharding`，它将决定如何分区值。使用网格上下文管理器时，不需要此操作。

    +   [`None`](https://docs.python.org/3/library/constants.html#None "(在 Python v3.12 中)") 是一种特殊情况，其语义为：

        +   如果未提供网格上下文管理器，则 JAX 可以自由选择任何分片方式。对于 in_shardings，JAX 将其标记为复制，但此行为可能在将来更改。对于 out_shardings，我们将依赖于 XLA GSPMD 分区器来确定输出的分片方式。

        +   如果提供了网格上下文管理器，则 `None` 将意味着该值将复制到网格的所有设备上。

    +   为了向后兼容，in_shardings 仍支持接受 `PartitionSpec`。此选项只能与网格上下文管理器一起使用。

        +   `PartitionSpec`，最多与分区值的秩相等长的元组。每个元素可以是 [`None`](https://docs.python.org/3/library/constants.html#None "(在 Python v3.12 中)")，一个网格轴或网格轴的元组，并指定分配给分区值维度的资源集，与其在规范中的位置匹配。

    每个维度的大小必须是其分配的总资源数的倍数。

+   **out_shardings** – 类似于 `in_shardings`，但指定了函数输出的资源分配。`out_shardings` 参数是可选的。如果未指定，`jax.jit()` 将使用 GSPMD 的分片传播来确定如何分片输出。

+   **static_argnums**（[*int*](https://docs.python.org/3/library/functions.html#int "(在 Python v3.12 中)") *|* [*Sequence*](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence "(在 Python v3.12 中)") *[*[*int*](https://docs.python.org/3/library/functions.html#int "(在 Python v3.12 中)")*]* *|* *None*) –

    可选的整数或整数集合，用于指定将哪些位置参数视为静态（编译时常量）。在 Python 中（在追踪期间），仅依赖于静态参数的操作将被常量折叠，因此相应的参数值可以是任何 Python 对象。

    静态参数应该是可哈希的，即实现了 `__hash__` 和 `__eq__`，并且是不可变的。对于这些常量调用 jitted 函数时，使用不同的值将触发重新编译。不是数组或其容器的参数必须标记为静态。

    如果未提供 `static_argnums`，则不将任何参数视为静态。

+   **static_argnames** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12)") *|* [*Iterable*](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable "(在 Python v3.12)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12)")*]* *|* *None*) – 可选的字符串或字符串集合，指定要视为静态（编译时常量）的命名参数。有关详细信息，请参阅关于 `static_argnums` 的注释。如果未提供但设置了 `static_argnums`，则默认基于调用 `inspect.signature(fun)` 查找相应的命名参数。

+   **donate_argnums** ([*int*](https://docs.python.org/3/library/functions.html#int "(在 Python v3.12)") *|* [*Sequence*](https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence "(在 Python v3.12)")*[*[*int*](https://docs.python.org/3/library/functions.html#int "(在 Python v3.12)")*]* *|* *None*) –

    指定要“捐赠”给计算的位置参数缓冲区。如果计算结束后不再需要它们，捐赠参数缓冲区是安全的。在某些情况下，XLA 可以利用捐赠的缓冲区来减少执行计算所需的内存量，例如将您的一个输入缓冲区循环利用来存储结果。您不应重新使用捐赠给计算的缓冲区，如果尝试则 JAX 会引发错误。默认情况下，不会捐赠任何参数缓冲区。

    如果既未提供 `donate_argnums` 也未提供 `donate_argnames`，则不会捐赠任何参数。如果未提供 `donate_argnums`，但提供了 `donate_argnames`，或者反之，则 JAX 使用 `inspect.signature(fun)` 查找与 `donate_argnames` 相对应的任何位置参数（或反之）。如果同时提供了 `donate_argnums` 和 `donate_argnames`，则不使用 `inspect.signature`，并且只有在 `donate_argnums` 或 `donate_argnames` 中列出的实际参数将被捐赠。

    有关缓冲区捐赠的更多详情，请参阅[FAQ](https://jax.readthedocs.io/en/latest/faq.html#buffer-donation)。

+   **捐赠参数名** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12 中)") *|* [*Iterable*](https://docs.python.org/3/library/collections.abc.html#collections.abc.Iterable "(在 Python v3.12 中)")*[*[*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12 中)")*]* *|* *None*) – 一个可选的字符串或字符串集合，指定哪些命名参数将捐赠给计算。有关详细信息，请参见对 `donate_argnums` 的注释。如果未提供但设置了 `donate_argnums`，则默认基于调用 `inspect.signature(fun)` 查找相应的命名参数。

+   **保留未使用** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(在 Python v3.12 中)")) – 如果为 False（默认值），JAX 确定 fun 未使用的参数 *可能* 会从生成的编译后 XLA 可执行文件中删除。这些参数将不会传输到设备，也不会提供给底层可执行文件。如果为 True，则不会剪枝未使用的参数。

+   **设备** (*Device* *|* *None*) – 此参数已弃用。请在将参数传递给 jit 之前将您需要的设备置于其上。可选，jit 函数将在其上运行的设备。 （可通过 `jax.devices()` 获取可用设备。）默认情况下，继承自 XLA 的 DeviceAssignment 逻辑，并通常使用 `jax.devices()[0]`。

+   **后端** ([*str*](https://docs.python.org/3/library/stdtypes.html#str "(在 Python v3.12 中)") *|* *None*) – 此参数已弃用。请在将参数传递给 jit 之前将您需要的后端置于其前。可选，表示 XLA 后端的字符串：`'cpu'`、`'gpu'` 或 `'tpu'`。

+   **内联** ([*bool*](https://docs.python.org/3/library/functions.html#bool "(在 Python v3.12 中)"))

+   **抽象轴** ([*Any*](https://docs.python.org/3/library/typing.html#typing.Any "(在 Python v3.12 中)") *|* *None*)

返回：

`fun` 的包装版本，专为即时编译而设，并在每次调用点根据可用的网格自动分区。

返回类型：

*JitWrapped*

例如，卷积运算符可以通过单个 `pjit()` 应用自动分区到任意一组设备上：

```py
>>> import jax
>>> import jax.numpy as jnp
>>> import numpy as np
>>> from jax.sharding import Mesh, PartitionSpec
>>> from jax.experimental.pjit import pjit
>>>
>>> x = jnp.arange(8, dtype=jnp.float32)
>>> f = pjit(lambda x: jax.numpy.convolve(x, jnp.asarray([0.5, 1.0, 0.5]), 'same'),
...         in_shardings=None, out_shardings=PartitionSpec('devices'))
>>> with Mesh(np.array(jax.devices()), ('devices',)):
...   print(f(x))  
[ 0.5  2\.   4\.   6\.   8\.  10\.  12\.  10\. ] 
```
