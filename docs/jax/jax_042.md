# 使用 Pallas 编写 TPU 内核

> 原文：[`jax.readthedocs.io/en/latest/pallas/tpu/details.html`](https://jax.readthedocs.io/en/latest/pallas/tpu/details.html)

本页关注试图在 Google TPU 上运行 Pallas 内核时的重要细节。首先，TPU 后端仍处于实验阶段，并且只接受 JAX NumPy 的子集。此外，为 TPU 编写高性能代码可能需要仔细考虑硬件的本机能力。虽然许多对硬件不自然的模式将被接受，但它们最终可能需要软件模拟，并可能减慢计算速度。

警告

此功能仍应视为实验性功能，因为工作仍在进行中（特别是在改进错误消息方面）。

注意

虽然此处描述的所有功能都是实验性的，但我们仍然非常认真地维护其正确性。因此，在尝试编写 TPU 内核时可能看到“未实现”错误并不罕见。但是，如果编译器接受了内核，它*必须*返回预期的结果。

如果您看到意外的输出，请将其与传递`interpret=True`到`pallas_call`的内核运行进行比较。如果结果不一致，请提交[错误报告](https://github.com/google/jax/issues/new/choose)。

## 什么是 TPU？

![一个 TPUv4 板](https://lh3.googleusercontent.com/PBWR5LFWaz8Nx4F7vRstDjt_nvUYdfxe9H3O9i3KMam_RmmwIOQMr1GAq3RUfowET2cK5kAcb_zGpw=e14-rw-lo-sc0xffffff-w2540)

TPU 是 Google 开发的硬件加速器。您可以将 TPU 视为专门用于机器学习工作负载的 GPU。因此，它们的架构有相当大的差异。然而，我们相信 Pallas 可以使您轻松开始编写 TPU 内核，即使您没有完全理解底层硬件也是如此。话虽如此，深入了解硬件将确实使编写高性能内核变得更加容易。

简言之，TPU 与 GPU 的主要区别在于 TPU 是顺序机器，具有非常宽的向量寄存器（类似于 CPU！）。与此同时，它们允许软件安排某些操作在后台执行，使其与主指令流异步执行。这包括 HBM 内存访问（无法直接发出，而是必须通过 DMA 子单元预取到较低层次的内存层次结构）、矩阵乘法（由 MXU 单元支持）或矩阵转置和置换（由 XLU 单元支持）。

如果您对详细了解 TPU 架构感兴趣，我们建议阅读多年来发表的一系列论文集。虽然许多论文谈论特定的 TPU 代，但其中许多描述的思想也适用于后续代。

+   [用于训练深度神经网络的领域特定超级计算机](https://dl.acm.org/doi/10.1145/3360307)

+   [Google 培训芯片的设计过程：TPUv2 和 TPUv3](https://ieeexplore.ieee.org/document/9351692)

+   [三代形塑 Google TPUv4i 的十大经验教训：工业产品](https://ieeexplore.ieee.org/document/9499913)

+   [TPU v4：支持嵌入式硬件的机器学习光学可重构超级计算机](https://dl.acm.org/doi/abs/10.1145/3579371.3589350)

## 值得注意的属性和限制

### `BlockSpec`s 和网格迭代

在 Pallas 中，`BlockSpec`s 通常按预期行为——每次核心体调用都会访问输入的片段，并且旨在初始化输出的一个片段。

警告

并非所有的窗口形状都受支持。如果你的输入的最后两个维度分别大于 8 和 128，那么这些维度中的窗口形状必须是对应因子的倍数。如果输入维度较小，则窗口应跨越整个维度。

Pallas TPU 核心的一个有趣方面是它们处理内存空间的方式：虽然`pallas_call`的输入通常驻留在 HBM（主 TPU 内存）中，但传递到核心体的引用将指向内存层次结构较低的缓冲区（VMEM 或 SMEM）。这使得核心体能够以非常高的速度读写它们，而所有与 HBM 的通信（具有非常高的延迟）由编译器处理并与计算重叠。

此外，与 GPU 相比，TPU 实际上是高度序列化的机器。因此，网格通常不是并行处理的，而是按字典顺序顺序处理（尽管请参阅多核 TPU 配置部分的例外情况）。这解锁了一些有趣的功能：

+   当两个（按字典顺序）连续的网格索引使用相同输入的片段时，第二次迭代的 HBM 传输将被跳过，因为数据已经可用。

+   多个核心体调用可以向输出的同一片段写入，而不会有任何竞态条件的风险。但我们确实要求写入特定片段的所有调用是连续的。

关于输出的“连续”限制通常意味着网格维度的某些前缀总是变化，而调用需要访问的输出窗口对于其余后缀保持不变。

例如，在实现矩阵乘法的 Pallas TPU 核心时，通常会使用三维网格：前两个维度对应于沿左操作数的第一轴和第二操作数的第二轴切片。第三和*最后*网格轴将瓦片化减少维度。与减少维度对应的网格轴必须是最后一个，因为输出窗口沿此轴不变。输出引用随后可用作部分结果的累加器。

注意

对于这样一个低级内存层次结构（16MB+），VMEM 相当大，这使得可以使用较大的窗口大小。通常情况下，窗口大小越大，最终硬件利用率就越好。然而，可能会指定一个窗口大小，该大小（加上保存溢出矢量寄存器所需的空间）超过了 VMEM 的大小。在这种情况下，您可能会看到一个低级编译器错误消息，抱怨内存不足错误。

### 维度排序是有意义的

在 JAX 程序中，`jax.jit`内部数组的排序通常不会影响性能，因为编译器可以自由地重新排列它们。但是，由于 Pallas 旨在暴露更低级的功能，维度顺序对生成的代码质量有很大影响。

请记住，TPU 主要在 2D 矢量寄存器上执行大部分计算。Pallas TPU 只会考虑将中间数组的最后两个维度映射到这些矢量寄存器维度（子通道和通道）。形状为`(n, 1, 1)`的数组保证需要至少`n`个矢量寄存器来表示。如果`n`变得太大，则可能会导致溢出，并由于过大的内存占用而导致 VMEM 内存不足错误。但这也可能不会发生 — 低级编译器可以重新排列指令以降低寄存器压力，并且实际上在这方面做得非常好。尽管如此，保持最后两个维度大（特别是最后一个维度），同时使前导维度保持小是一个很好的经验法则。

### 多核 TPU 配置

在更新的 TPU 生成中，芯片上的两个核心通常被抽象为单个设备。为了利用多个核心，Pallas 必须打破顺序网格执行的保证，并且需要在核心上并行化一个网格轴。这是一个选择加入的过程。为了允许这样做，`pallas_call`需要一个额外的名为`dimension_semantics`的参数：

该参数是一个列表，其条目数量与网格中的轴数量相同。只有`parallel`维度可以在核心上分区。作为一个经验法则，维度是并行的，除非输出窗口不变。因此，`dimension_semantics`始终是一些`parallel`轴的数字，后跟一些`arbitrary`轴的数字。

尽管在 2 核 TPU 设备上分区内核通常会导致 2 倍速度提升，但实际上可能会显著小于此值。特别是如果体的不同实例具有非常不同的成本，这一点尤为真实。如果所有昂贵的步骤都映射到一个核心，而所有廉价的步骤都分配给另一个核心，则第二个核心将在第一个完成其任务之前处于空闲状态。

Pallas TPU 通常偏好将大小为 TPU 核心数量倍数的轴进行分区，并且更喜欢分区主导的网格轴。

### 将操作数放入 SMEM

大多数 TPU 计算将在向量单元上进行。然而，有许多情况下进行一些标量操作是有用的，例如执行控制流。因此，TPU 配备了一个单独的标量单元，并附有一个单独的标量存储器（SMEM）。按照一个经验法则，用于执行控制流决策的任何数据应放置在 SMEM 中。

SMEM 是一种低延迟内存，支持随机访问，但只能用单个指令读写 32 位值（与 VMEM 事务的 4KBi 粒度相比非常小，但由于没有对齐要求而更加灵活！）。

当实现不按规则模式访问输入块的内核时，标量内存也非常有用，例如编写块稀疏内核时。在 Pallas 中，可以通过将`pallas_call`的`grid`参数替换为具有非零`num_scalar_prefetch`参数的`PrefetchScalarGridSpec`的`grid_spec`来实现这一点。如果`num_scalar_prefetch`为`n`，那么`pallas_call`的前`n`个参数将放置在 SMEM 中。对于这些参数，不应指定任何`BlockSpec`。但是，对于所有后续参数的`BlockSpec`，不仅会收到网格索引，还会收到领先操作数的 SMEM 引用。

注意

我们正在努力实现此功能的示例。敬请关注！

### 支持的数据类型

目前，Pallas TPU 仅支持以下数据类型：

+   `jnp.float32`

+   `jnp.bfloat16`

+   `jnp.int*`（所有精度，除了`jnp.int4`）

+   `jnp.uint*`（所有精度）

### 计算放置

所有标量（即 0D）数组将存储在标量寄存器中，并在标量核心上执行操作。所有其他操作（甚至是对单个元素但是 1D+数组的操作）将在向量核心上执行。

## 支持的操作

### 矩阵乘法

矩阵乘法始终以`float32`格式生成结果。如果您的输入不是 float32，建议使用`lax.dot`并将`preferred_element_type`设置为`jnp.float32`。

当使用`lax.dot_general`时，可以将矩阵乘法操作数的最后两个维度的转置融合到操作中，这可以提高整体内核性能。

#### 精度控制

Pallas TPU 的降低考虑到了`jax.default_matmul_precision`。为了获得最佳性能（和最低精度），请使用`bfloat16`。如果您关心数值精度，可能需要将精度设置为`float32`。

警告

即使将 32 位操作数传递给矩阵乘法，除非请求`float32`精度，否则它们将会被四舍五入为`bfloat16`。

### 转置

如果值至少有 4 个维度，则除了最后两个轴以外的任意转置都是免费的。否则，仅实现了最后两个轴的转置。请注意，一些最后两个维度的转置可以融合到矩阵乘法中。

### 访问内存

可以读取或更新引用的任意片段，受实现约束的限制。目前，对于宽度为 32 位的输入没有限制，但只支持某些更窄类型的切片模式。总是支持最后两个维度中分别是 8 和 128 的倍数的对齐读写。

通常在向量内存的读写发生在形状为 `(8, 128)` 的瓦片上。因此，当读取或写入至少有两个维度的引用时，最佳性能是在内存访问的基础偏移具有瓦片可整除的索引，并且读取区域的大小是瓦片大小的倍数。

### 逐元素操作

支持许多逐元素操作。值得注意的是，硬件通常仅支持使用 32 位类型进行逐元素计算。在加载使用较低精度类型的操作数时，通常应先将其升级为 32 位类型再应用逐元素操作。

值得注意的是，它们的成本可能*显著*不同。因此，我们列出了三类支持的操作：廉价（🟢）、中等（🌕）和昂贵（🔴）。

| 操作 | 成本 |
| --- | --- |
| `jnp.add`，`+` | 🟢 |
| `jnp.sub`，`-` | 🟢 |
| `jnp.mul`，`*` | 🟢 |
| `/`，`//`，`%` | 🌕 |
| `jnp.max`，`jnp.min` | 🟢 |
| `jnp.where`（选择） | 🟢 |
| `jnp.abs` | 🟢 |
| ` | `，`^`，`&`，`~` | 🟢 |
| `<<`，`>>` | 🟢 |
| 比较运算（`==`，...） | 🟢 |
| 类型转换（`.astype`） | 🟢 |
| `jnp.exp` | 🌕 |
| `jnp.tanh` | 🌕 |
| `jnp.pow` | 🌕 |
| `jnp.sin` | 🔴 |
| `jnp.cos` | 🔴 |

许多 JAX 函数是基于其他 JAX 原语实现的，因此此列表可能不完整。例如，`jax.nn.relu` 是基于比较实现的，而 `jnp.where` 在 Pallas 内核中也能工作。

### 数组构造函数

所有常数数组构造函数都受支持（`jnp.ones`，`jnp.zeros`，`jnp.full`）。特别是，截至今天，`jax.random` 模块与 Pallas **不** 兼容。

### 归约

支持求和、最大值和最小值的归约，但一次只能在一个数组轴上进行。

对最后一个数组维度的归约通常是最慢的。对倒数第二个维度的归约更快，但仍比前面的维度慢。

### 广播

广播的性能特性与归约非常相似。总是支持除了最后两个维度之外的所有广播，且是免费的。沿着倒数第二个维度进行广播较慢，而沿着最后一个维度进行广播最慢。

### 重塑

如常地，所有维度除了最后两个维度的重塑都是支持的且是免费的。

唯一支持的情况是当重塑可以修改数组的最后两个维度时，即（1）某些前导维度展平到倒数第二个维度，或者（2）它添加了刚刚由归约移除的维度。

### 控制流程

目前，TPU 后端对控制流的支持有限。目前支持的函数有`cond`、`fori_loop`和`for_loop`。然而，在编译时，循环原语会完全展开，因此请尽量保持循环执行次数合理小。

过度使用控制流可能导致低级代码生成中的显著回归，建议尽量将多个计算密集型操作挤入一个基本块中。
