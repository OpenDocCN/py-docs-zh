# GPU 内存分配

> 原文：[`jax.readthedocs.io/en/latest/gpu_memory_allocation.html`](https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html)

**当第一个 JAX 操作运行时，JAX 将预先分配总 GPU 内存的 75%。** 预先分配可以最小化分配开销和内存碎片化，但有时会导致内存不足（OOM）错误。如果您的 JAX 进程因内存不足而失败，可以使用以下环境变量来覆盖默认行为：

`XLA_PYTHON_CLIENT_PREALLOCATE=false`

这将禁用预分配行为。JAX 将根据需要分配 GPU 内存，可能会减少总体内存使用。但是，这种行为更容易导致 GPU 内存碎片化，这意味着使用大部分可用 GPU 内存的 JAX 程序可能会在禁用预分配时发生 OOM。

`XLA_PYTHON_CLIENT_MEM_FRACTION=.XX`

如果启用了预分配，这将使 JAX 预分配总 GPU 内存的 XX% ，而不是默认的 75%。减少预分配量可以修复 JAX 程序启动时的内存不足问题。

`XLA_PYTHON_CLIENT_ALLOCATOR=platform`

这使得 JAX 根据需求精确分配内存，并释放不再需要的内存（请注意，这是唯一会释放 GPU 内存而不是重用它的配置）。这样做非常慢，因此不建议用于一般用途，但可能对于以最小可能的 GPU 内存占用运行或调试 OOM 失败非常有用。

## OOM 失败的常见原因

**同时运行多个 JAX 进程。**

要么使用 `XLA_PYTHON_CLIENT_MEM_FRACTION` 为每个进程分配适当的内存量，要么设置 `XLA_PYTHON_CLIENT_PREALLOCATE=false`。

**同时运行 JAX 和 GPU TensorFlow。**

TensorFlow 默认也会预分配，因此这与同时运行多个 JAX 进程类似。

一个解决方案是仅使用 CPU TensorFlow（例如，如果您仅使用 TF 进行数据加载）。您可以使用命令 `tf.config.experimental.set_visible_devices([], "GPU")` 阻止 TensorFlow 使用 GPU。

或者，使用 `XLA_PYTHON_CLIENT_MEM_FRACTION` 或 `XLA_PYTHON_CLIENT_PREALLOCATE`。还有类似的选项可以配置 TensorFlow 的 GPU 内存分配（[gpu_memory_fraction](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L36) 和 [allow_growth](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L40) 在 TF1 中应该设置在传递给 `tf.Session` 的 `tf.ConfigProto` 中。参见 [使用 GPU：限制 GPU 内存增长](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) 用于 TF2）。

**在显示 GPU 上运行 JAX。**

使用 `XLA_PYTHON_CLIENT_MEM_FRACTION` 或 `XLA_PYTHON_CLIENT_PREALLOCATE`。
