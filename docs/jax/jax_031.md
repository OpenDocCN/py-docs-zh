# 提前降低和编译

> 原文：[`jax.readthedocs.io/en/latest/aot.html`](https://jax.readthedocs.io/en/latest/aot.html)

JAX 提供了几种转换，如`jax.jit`和`jax.pmap`，返回一个编译并在加速器或 CPU 上运行的函数。正如 JIT 缩写所示，所有编译都是*即时*执行的。

有些情况需要进行*提前*（AOT）编译。当你希望在执行之前完全编译，或者希望控制编译过程的不同部分何时发生时，JAX 为您提供了一些选项。

首先，让我们回顾一下编译的阶段。假设`f`是由`jax.jit()`输出的函数/可调用对象，例如对于某个输入可调用对象`F`，`f = jax.jit(F)`。当它用参数调用时，例如`f(x, y)`，其中`x`和`y`是数组，JAX 按顺序执行以下操作：

1.  **Stage out**原始 Python 可调用`F`的特殊版本到内部表示。专门化反映了`F`对从参数`x`和`y`的属性推断出的输入类型的限制（通常是它们的形状和元素类型）。

1.  **Lower**这种特殊的阶段计算到 XLA 编译器的输入语言 StableHLO。

1.  **Compile**降低的 HLO 程序以生成针对目标设备（CPU、GPU 或 TPU）的优化可执行文件。

1.  **Execute**使用数组`x`和`y`作为参数执行编译后的可执行文件。

JAX 的 AOT API 允许您直接控制步骤#2、#3 和#4（但不包括#1），以及沿途的一些其他功能。例如：

```py
>>> import jax

>>> def f(x, y): return 2 * x + y
>>> x, y = 3, 4

>>> lowered = jax.jit(f).lower(x, y)

>>> # Print lowered HLO
>>> print(lowered.as_text())
module @jit_f attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {
 func.func public @main(%arg0: tensor<i32> {mhlo.layout_mode = "default"}, %arg1: tensor<i32> {mhlo.layout_mode = "default"}) -> (tensor<i32> {jax.result_info = "", mhlo.layout_mode = "default"}) {
 %c = stablehlo.constant dense<2> : tensor<i32>
 %0 = stablehlo.multiply %c, %arg0 : tensor<i32>
 %1 = stablehlo.add %0, %arg1 : tensor<i32>
 return %1 : tensor<i32>
 }
}

>>> compiled = lowered.compile()

>>> # Query for cost analysis, print FLOP estimate
>>> compiled.cost_analysis()[0]['flops']
2.0

>>> # Execute the compiled function!
>>> compiled(x, y)
Array(10, dtype=int32, weak_type=True) 
```

请注意，降低的对象只能在它们被降低的同一进程中使用。有关导出用例，请参阅导出和序列化 API。

有关降低和编译函数提供的功能的更多详细信息，请参见`jax.stages`文档。

在上面的`jax.jit`的位置，您还可以`lower(...)``jax.pmap()`的结果，以及`pjit`和`xmap`（分别来自`jax.experimental.pjit`和`jax.experimental.maps`）。在每种情况下，您也可以类似地`compile()`结果。

所有`jit`的可选参数——如`static_argnums`——在相应的降低、编译和执行中都得到尊重。同样适用于`pmap`、`pjit`和`xmap`。

在上述示例中，我们可以将`lower`的参数替换为具有`shape`和`dtype`属性的任何对象：

```py
>>> i32_scalar = jax.ShapeDtypeStruct((), jnp.dtype('int32'))
>>> jax.jit(f).lower(i32_scalar, i32_scalar).compile()(x, y)
Array(10, dtype=int32) 
```

更一般地说，`lower`只需其参数结构上提供 JAX 必须了解的内容进行专门化和降低。对于像上面的典型数组参数，这意味着`shape`和`dtype`字段。相比之下，对于静态参数，JAX 需要实际的数组值（下面会详细说明）。

使用与其降低不兼容的参数调用 AOT 编译函数会引发错误：

```py
>>> x_1d = y_1d = jnp.arange(3)
>>> jax.jit(f).lower(i32_scalar, i32_scalar).compile()(x_1d, y_1d)  
...
Traceback (most recent call last):
TypeError: Argument types differ from the types for which this computation was compiled. The mismatches are:
Argument 'x' compiled with int32[] and called with int32[3]
Argument 'y' compiled with int32[] and called with int32[3]

>>> x_f = y_f = jnp.float32(72.)
>>> jax.jit(f).lower(i32_scalar, i32_scalar).compile()(x_f, y_f)  
...
Traceback (most recent call last):
TypeError: Argument types differ from the types for which this computation was compiled. The mismatches are:
Argument 'x' compiled with int32[] and called with float32[]
Argument 'y' compiled with int32[] and called with float32[] 
```

与此相关的是，AOT 编译函数不能通过 JAX 的即时转换（如`jax.jit`、`jax.grad()`和`jax.vmap()`）进行转换。

## 使用静态参数进行降低

使用静态参数进行降级强调了传递给`jax.jit`的选项、传递给`lower`的参数以及调用生成的编译函数所需的参数之间的交互。继续我们上面的示例：

```py
>>> lowered_with_x = jax.jit(f, static_argnums=0).lower(7, 8)

>>> # Lowered HLO, specialized to the *value* of the first argument (7)
>>> print(lowered_with_x.as_text())
module @jit_f attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {
 func.func public @main(%arg0: tensor<i32> {mhlo.layout_mode = "default"}) -> (tensor<i32> {jax.result_info = "", mhlo.layout_mode = "default"}) {
 %c = stablehlo.constant dense<14> : tensor<i32>
 %0 = stablehlo.add %c, %arg0 : tensor<i32>
 return %0 : tensor<i32>
 }
}

>>> lowered_with_x.compile()(5)
Array(19, dtype=int32, weak_type=True) 
```

`lower`的结果不能直接序列化以供在不同进程中使用。有关此目的的额外 API，请参见导出和序列化。

注意，这里的`lower`像往常一样接受两个参数，但随后生成的编译函数仅接受剩余的非静态第二个参数。静态的第一个参数（值为 7）在降级时被视为常量，并内置到降级计算中，其中可能会与其他常量一起折叠。在这种情况下，它的乘以 2 被简化为常量 14。

尽管上面`lower`的第二个参数可以被一个空的形状/数据类型结构替换，但静态的第一个参数必须是一个具体的值。否则，降级将会出错：

```py
>>> jax.jit(f, static_argnums=0).lower(i32_scalar, i32_scalar)  
Traceback (most recent call last):
TypeError: unsupported operand type(s) for *: 'int' and 'ShapeDtypeStruct'

>>> jax.jit(f, static_argnums=0).lower(10, i32_scalar).compile()(5)
Array(25, dtype=int32) 
```

## AOT 编译的函数不能被转换

编译函数专门针对一组特定的参数“类型”，例如我们正在运行的示例中具有特定形状和元素类型的数组。从 JAX 的内部角度来看，诸如`jax.vmap()`之类的转换会以一种方式改变函数的类型签名，使得已编译的类型签名失效。作为一项政策，JAX 简单地禁止已编译的函数参与转换。示例：

```py
>>> def g(x):
...   assert x.shape == (3, 2)
...   return x @ jnp.ones(2)

>>> def make_z(*shape):
...   return jnp.arange(np.prod(shape)).reshape(shape)

>>> z, zs = make_z(3, 2), make_z(4, 3, 2)

>>> g_jit = jax.jit(g)
>>> g_aot = jax.jit(g).lower(z).compile()

>>> jax.vmap(g_jit)(zs)
Array([[ 1.,  5.,  9.],
 [13., 17., 21.],
 [25., 29., 33.],
 [37., 41., 45.]], dtype=float32)

>>> jax.vmap(g_aot)(zs)  
Traceback (most recent call last):
TypeError: Cannot apply JAX transformations to a function lowered and compiled for a particular signature. Detected argument of Tracer type <class 'jax._src.interpreters.batching.BatchTracer'> 
```

当`g_aot`参与自动微分（例如`jax.grad()`）时也会引发类似的错误。为了一致性，`jax.jit`的转换也被禁止，尽管`jit`并没有实质性地修改其参数的类型签名。

## 调试信息和分析，在可用时

除了主要的 AOT 功能（分离和显式的降级、编译和执行），JAX 的各种 AOT 阶段还提供一些额外的功能，以帮助调试和收集编译器反馈。

例如，正如上面的初始示例所示，降级函数通常提供文本表示。编译函数也是如此，并且还提供来自编译器的成本和内存分析。所有这些都通过`jax.stages.Lowered`和`jax.stages.Compiled`对象上的方法提供（例如，上面的`lowered.as_text()`和`compiled.cost_analysis()`）。

这些方法旨在帮助手动检查和调试，而不是作为可靠的可编程 API。它们的可用性和输出因编译器、平台和运行时而异。这导致了两个重要的注意事项：

1.  如果某些功能在 JAX 当前的后端上不可用，则其方法将返回某些微不足道的东西（类似于`False`）。例如，如果支持 JAX 的编译器不提供成本分析，则`compiled.cost_analysis()`将为`None`。

1.  如果某些功能可用，则对应方法提供的内容仍然有非常有限的保证。返回值在 JAX 的配置、后端/平台、版本或甚至方法的调用之间，在类型、结构或值上不需要保持一致。JAX 无法保证 `compiled.cost_analysis()` 在一天的输出将会在随后的一天保持相同。

如果有疑问，请参阅 `jax.stages` 的包 API 文档。

## 检查暂停的计算

此笔记顶部列表中的第一个阶段提到专业化和分阶段，之后是降低。JAX 内部对其参数类型专门化的函数的概念，并非始终在内存中具体化为数据结构。要显式构建 JAX 在内部[Jaxpr 中间语言](https://jax.readthedocs.io/en/latest/jaxpr.html)中函数专门化的视图，请参见 `jax.make_jaxpr()`。
