# `jax.Array` è¿ç§»

> åŸæ–‡ï¼š[`jax.readthedocs.io/en/latest/jax_array_migration.html`](https://jax.readthedocs.io/en/latest/jax_array_migration.html)

**yashkatariya@**

## TL;DR

JAX å°†å…¶é»˜è®¤æ•°ç»„å®ç°åˆ‡æ¢ä¸ºæ–°çš„ `jax.Array` è‡ªç‰ˆæœ¬ 0.4.1 èµ·ã€‚æœ¬æŒ‡å—è§£é‡Šäº†è¿™ä¸€å†³å®šçš„èƒŒæ™¯ï¼Œå®ƒå¯èƒ½å¯¹æ‚¨çš„ä»£ç äº§ç”Ÿçš„å½±å“ï¼Œä»¥åŠå¦‚ä½•ï¼ˆä¸´æ—¶ï¼‰åˆ‡æ¢å›æ—§è¡Œä¸ºã€‚

### å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ

`jax.Array` æ˜¯ JAX ä¸­ç»Ÿä¸€çš„æ•°ç»„ç±»å‹ï¼ŒåŒ…æ‹¬ `DeviceArray`ã€`ShardedDeviceArray` å’Œ `GlobalDeviceArray` ç±»å‹ã€‚`jax.Array` ç±»å‹æœ‰åŠ©äºä½¿å¹¶è¡Œæˆä¸º JAX çš„æ ¸å¿ƒç‰¹æ€§ï¼Œç®€åŒ–å’Œç»Ÿä¸€äº† JAX çš„å†…éƒ¨ç»“æ„ï¼Œå¹¶å…è®¸æˆ‘ä»¬ç»Ÿä¸€ `jit` å’Œ `pjit`ã€‚å¦‚æœä½ çš„ä»£ç æ²¡æœ‰æ¶‰åŠåˆ° `DeviceArray`ã€`ShardedDeviceArray` å’Œ `GlobalDeviceArray` çš„åŒºåˆ«ï¼Œé‚£å°±ä¸éœ€è¦è¿›è¡Œä»»ä½•æ›´æ”¹ã€‚ä½†æ˜¯ä¾èµ–äºè¿™äº›å•ç‹¬ç±»ç»†èŠ‚çš„ä»£ç å¯èƒ½éœ€è¦è¿›è¡Œè°ƒæ•´ä»¥é€‚é…ç»Ÿä¸€çš„ `jax.Array`ã€‚

è¿ç§»å®Œæˆåï¼Œ`jax.Array` å°†æˆä¸º JAX ä¸­å”¯ä¸€çš„æ•°ç»„ç±»å‹ã€‚

æœ¬æ–‡ä»‹ç»äº†å¦‚ä½•å°†ç°æœ‰ä»£ç åº“è¿ç§»åˆ° `jax.Array`ã€‚æœ‰å…³å¦‚ä½•ä½¿ç”¨ `jax.Array` å’Œ JAX å¹¶è¡Œ API çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [Distributed arrays and automatic parallelization](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html) æ•™ç¨‹ã€‚

### å¦‚ä½•å¯ç”¨ `jax.Array`ï¼Ÿ

ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å¯ç”¨ `jax.Array`ï¼š

+   è®¾ç½® shell ç¯å¢ƒå˜é‡ `JAX_ARRAY` ä¸ºçœŸå€¼ï¼ˆä¾‹å¦‚ `1`ï¼‰ï¼›

+   å¦‚æœä½ çš„ä»£ç ä½¿ç”¨ absl è§£ææ ‡å¿—ï¼Œå¯ä»¥å°†å¸ƒå°”æ ‡å¿— `jax_array` è®¾ç½®ä¸ºçœŸå€¼ï¼›

+   åœ¨ä½ çš„ä¸»æ–‡ä»¶é¡¶éƒ¨åŠ å…¥ä»¥ä¸‹å£°æ˜ï¼š

    ```py
    import jax
    jax.config.update('jax_array', True) 
    ```

### å¦‚ä½•åˆ¤æ–­ `jax.Array` æ˜¯å¦ç ´åäº†æˆ‘çš„ä»£ç ï¼Ÿ

æœ€ç®€å•çš„æ–¹æ³•æ˜¯ç¦ç”¨ `jax.Array`ï¼Œçœ‹çœ‹é—®é¢˜æ˜¯å¦è§£å†³ã€‚

### æˆ‘å¦‚ä½•æš‚æ—¶ç¦ç”¨ `jax.Array`ï¼Ÿ

é€šè¿‡ **2023 å¹´ 3 æœˆ 15 æ—¥**ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ç¦ç”¨ `jax.Array`ï¼š

+   è®¾ç½® shell ç¯å¢ƒå˜é‡ `JAX_ARRAY` ä¸ºå‡å€¼ï¼ˆä¾‹å¦‚ `0`ï¼‰ï¼›

+   å¦‚æœä½ çš„ä»£ç ä½¿ç”¨ absl è§£ææ ‡å¿—ï¼Œå¯ä»¥å°†å¸ƒå°”æ ‡å¿— `jax_array` è®¾ç½®ä¸ºå‡å€¼ï¼›

+   åœ¨ä½ çš„ä¸»æ–‡ä»¶é¡¶éƒ¨åŠ å…¥ä»¥ä¸‹å£°æ˜ï¼š

    ```py
    import jax
    jax.config.update('jax_array', False) 
    ```

## ä¸ºä»€ä¹ˆåˆ›å»º `jax.Array`ï¼Ÿ

å½“å‰ JAX æœ‰ä¸‰ç§ç±»å‹ï¼š`DeviceArray`ã€`ShardedDeviceArray` å’Œ `GlobalDeviceArray`ã€‚`jax.Array` åˆå¹¶äº†è¿™ä¸‰ç§ç±»å‹ï¼Œå¹¶æ¸…ç†äº† JAX çš„å†…éƒ¨ç»“æ„ï¼ŒåŒæ—¶å¢åŠ äº†æ–°çš„å¹¶è¡Œç‰¹æ€§ã€‚

æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„ `Sharding` æŠ½è±¡ï¼Œæè¿°äº†é€»è¾‘æ•°ç»„å¦‚ä½•åœ¨ä¸€ä¸ªæˆ–å¤šä¸ªè®¾å¤‡ï¼ˆå¦‚ TPU æˆ– GPUï¼‰ä¸Šç‰©ç†åˆ†ç‰‡ã€‚è¿™ä¸€å˜æ›´è¿˜å‡çº§ã€ç®€åŒ–å¹¶å°† `pjit` çš„å¹¶è¡Œæ€§ç‰¹æ€§åˆå¹¶åˆ° `jit` ä¸­ã€‚ä½¿ç”¨ `jit` è£…é¥°çš„å‡½æ•°å°†èƒ½å¤Ÿåœ¨åˆ†ç‰‡æ•°ç»„ä¸Šæ“ä½œï¼Œè€Œæ— éœ€å°†æ•°æ®å¤åˆ¶åˆ°å•ä¸ªè®¾å¤‡ä¸Šã€‚

ä½¿ç”¨ `jax.Array` å¯ä»¥è·å¾—çš„åŠŸèƒ½ï¼š

+   C++ `pjit` åˆ†æ´¾è·¯å¾„

+   é€æ“ä½œå¹¶è¡Œæ€§ï¼ˆå³ä½¿æ•°ç»„åˆ†å¸ƒåœ¨å¤šå°è®¾å¤‡ä¸Šï¼Œè·¨å¤šä¸ªä¸»æœºï¼‰

+   ä½¿ç”¨ `pjit`/`jit` æ›´ç®€å•çš„æ‰¹æ•°æ®å¹¶è¡Œæ€§ã€‚

+   å¯ä»¥å®Œå…¨åˆ©ç”¨ OpSharding çš„çµæ´»æ€§ï¼Œæˆ–è€…ä»»ä½•æ‚¨æƒ³è¦çš„å…¶ä»–åˆ†ç‰‡æ–¹å¼æ¥åˆ›å»ºä¸ä¸€å®šåŒ…å«ç½‘æ ¼å’Œåˆ†åŒºè§„èŒƒçš„ `Sharding`ã€‚

+   ç­‰ç­‰

ç¤ºä¾‹ï¼š

```py
import jax
import jax.numpy as jnp
from jax.sharding import PartitionSpec as P
import numpy as np
x = jnp.arange(8)

# Let's say there are 8 devices in jax.devices()
mesh = jax.sharding.Mesh(np.array(jax.devices()).reshape(4, 2), ('x', 'y'))
sharding = jax.sharding.NamedSharding(mesh, P('x'))

sharded_x = jax.device_put(x, sharding)

# `matmul_sharded_x` and `sin_sharded_x` are sharded. `jit` is able to operate over a
# sharded array without copying data to a single device.
matmul_sharded_x = sharded_x @ sharded_x.T
sin_sharded_x = jnp.sin(sharded_x)

# Even jnp.copy preserves the sharding on the output.
copy_sharded_x = jnp.copy(sharded_x)

# double_out is also sharded
double_out = jax.jit(lambda x: x * 2)(sharded_x) 
```

## åˆ‡æ¢åˆ° `jax.Array` åå¯èƒ½ä¼šå‡ºç°å“ªäº›é—®é¢˜ï¼Ÿ

### æ–°å…¬å…±ç±»å‹å‘½åä¸º `jax.Array`ã€‚

æ‰€æœ‰ `isinstance(..., jnp.DeviceArray)` æˆ– `isinstance(.., jax.xla.DeviceArray)` ä»¥åŠå…¶ä»– `DeviceArray` çš„å˜ä½“åº”è¯¥åˆ‡æ¢åˆ°ä½¿ç”¨ `isinstance(..., jax.Array)`ã€‚

ç”±äº `jax.Array` å¯ä»¥è¡¨ç¤º DAã€SDA å’Œ GDAï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼åœ¨ `jax.Array` ä¸­åŒºåˆ†è¿™ä¸‰ç§ç±»å‹ï¼š

+   `x.is_fully_addressable and len(x.sharding.device_set) == 1` â€“ è¿™æ„å‘³ç€ `jax.Array` ç±»ä¼¼äº DAã€‚

+   `x.is_fully_addressable and (len(x.sharding.device_set) > 1` â€“ è¿™æ„å‘³ç€ `jax.Array` ç±»ä¼¼äº SDAã€‚

+   `not x.is_fully_addressable` â€“ è¿™æ„å‘³ç€ `jax.Array` ç±»ä¼¼äº GDAï¼Œå¹¶è·¨å¤šä¸ªè¿›ç¨‹ã€‚

å¯¹äº `ShardedDeviceArray`ï¼Œå¯ä»¥å°† `isinstance(..., pxla.ShardedDeviceArray)` è½¬ç§»åˆ° `isinstance(..., jax.Array) and x.is_fully_addressable and len(x.sharding.device_set) > 1`ã€‚

é€šå¸¸æ— æ³•åŒºåˆ†å•è®¾å¤‡æ•°ç»„ä¸Šçš„ `ShardedDeviceArray` ä¸ä»»ä½•å…¶ä»–ç±»å‹çš„å•è®¾å¤‡æ•°ç»„ã€‚

### GDA çš„ API åç§°å˜æ›´

GDA çš„ `local_shards` å’Œ `local_data` å·²ç»è¢«å¼ƒç”¨ã€‚

è¯·ä½¿ç”¨ä¸ `jax.Array` å’Œ `GDA` å…¼å®¹çš„ `addressable_shards` å’Œ `addressable_data`ã€‚

### åˆ›å»º `jax.Array`ã€‚

å½“ `jax_array` æ ‡å¿—ä¸ºçœŸæ—¶ï¼Œæ‰€æœ‰ JAX å‡½æ•°å°†è¾“å‡º `jax.Array`ã€‚å¦‚æœæ‚¨æ›¾ä½¿ç”¨ `GlobalDeviceArray.from_callback`ã€`make_sharded_device_array` æˆ– `make_device_array` å‡½æ•°æ˜¾å¼åˆ›å»ºç›¸åº”çš„ JAX æ•°æ®ç±»å‹ï¼Œåˆ™éœ€è¦åˆ‡æ¢ä¸ºä½¿ç”¨ `jax.make_array_from_callback()` æˆ– `jax.make_array_from_single_device_arrays()`ã€‚

**å¯¹äº GDAï¼š**

`GlobalDeviceArray.from_callback(shape, mesh, pspec, callback)` å¯ä»¥ä¸€å¯¹ä¸€åœ°åˆ‡æ¢ä¸º `jax.make_array_from_callback(shape, jax.sharding.NamedSharding(mesh, pspec), callback)`ã€‚

å¦‚æœæ‚¨æ›¾ä½¿ç”¨åŸå§‹çš„ GDA æ„é€ å‡½æ•°æ¥åˆ›å»º GDAsï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

`GlobalDeviceArray(shape, mesh, pspec, buffers)` å¯ä»¥å˜æˆ `jax.make_array_from_single_device_arrays(shape, jax.sharding.NamedSharding(mesh, pspec), buffers)`ã€‚

**å¯¹äº SDAï¼š**

`make_sharded_device_array(aval, sharding_spec, device_buffers, indices)` å¯ä»¥å˜æˆ `jax.make_array_from_single_device_arrays(shape, sharding, device_buffers)`ã€‚

è¦å†³å®šåˆ†ç‰‡åº”è¯¥æ˜¯ä»€ä¹ˆï¼Œå–å†³äºæ‚¨åˆ›å»º SDA çš„åŸå› ï¼š

å¦‚æœå®ƒè¢«åˆ›å»ºä¸º `pmap` çš„è¾“å…¥ï¼Œåˆ™åˆ†ç‰‡å¯ä»¥æ˜¯ï¼š`jax.sharding.PmapSharding(devices, sharding_spec)`ã€‚

å¦‚æœå®ƒè¢«åˆ›å»ºä¸º pjit çš„è¾“å…¥ï¼Œåˆ™åˆ†ç‰‡å¯ä»¥æ˜¯ `jax.sharding.NamedSharding(mesh, pspec)`ã€‚

### åˆ‡æ¢åˆ° `jax.Array` åå¯¹äºä¸»æœºæœ¬åœ°è¾“å…¥çš„ pjit æœ‰ç ´åæ€§å˜æ›´ã€‚

**å¦‚æœæ‚¨å®Œå…¨ä½¿ç”¨ GDA å‚æ•°ä½œä¸º pjit çš„è¾“å…¥ï¼Œåˆ™å¯ä»¥è·³è¿‡æ­¤éƒ¨åˆ†ï¼ ğŸ‰**

å¯ç”¨`jax.Array`åï¼Œæ‰€æœ‰ä¼ é€’ç»™`pjit`çš„è¾“å…¥å¿…é¡»æ˜¯å…¨å±€å½¢çŠ¶çš„ã€‚è¿™æ˜¯ä¸ä¹‹å‰è¡Œä¸ºä¸å…¼å®¹çš„å˜åŒ–ï¼Œä¹‹å‰çš„`pjit`ä¼šå°†è¿›ç¨‹æœ¬åœ°çš„å‚æ•°è¿æ¥æˆä¸€ä¸ªå…¨å±€å€¼ï¼›ç°åœ¨ä¸å†è¿›è¡Œæ­¤è¿æ¥ã€‚

ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦è¿›è¡Œè¿™ä¸ªçªç ´æ€§çš„å˜åŒ–ï¼Ÿç°åœ¨æ¯ä¸ªæ•°ç»„éƒ½æ˜ç¡®è¯´æ˜äº†å®ƒçš„æœ¬åœ°åˆ†ç‰‡å¦‚ä½•é€‚åˆå…¨å±€æ•´ä½“ï¼Œè€Œä¸æ˜¯ç•™ä¸‹éšå«çš„æƒ…å†µã€‚æ›´æ˜ç¡®çš„è¡¨ç¤ºæ–¹å¼è¿˜å¯ä»¥è§£é”é¢å¤–çš„çµæ´»æ€§ï¼Œä¾‹å¦‚åœ¨æŸäº› TPU æ¨¡å‹ä¸Šå¯ä»¥æé«˜æ•ˆç‡çš„éè¿ç»­ç½‘æ ¼ä½¿ç”¨`pjit`ã€‚

åœ¨å¯ç”¨`jax.Array`æ—¶ï¼Œè¿è¡Œ**å¤šè¿›ç¨‹ pjit è®¡ç®—**å¹¶åœ¨ä¼ é€’ä¸»æœºæœ¬åœ°è¾“å…¥æ—¶å¯èƒ½ä¼šå¯¼è‡´ç±»ä¼¼ä»¥ä¸‹é”™è¯¯ï¼š

ç¤ºä¾‹ï¼š

`Mesh = {'x': 2, 'y': 2, 'z': 2}` å’Œä¸»æœºæœ¬åœ°è¾“å…¥å½¢çŠ¶ == `(4,)` ä»¥åŠ`pspec = P(('x', 'y', 'z'))`

å› ä¸º`pjit`ä¸ä¼šå°†ä¸»æœºæœ¬åœ°å½¢çŠ¶æå‡ä¸ºå…¨å±€å½¢çŠ¶ï¼Œæ‰€ä»¥æ‚¨ä¼šæ”¶åˆ°ä»¥ä¸‹é”™è¯¯ï¼š

æ³¨æ„ï¼šåªæœ‰å½“æ‚¨çš„ä¸»æœºæœ¬åœ°å½¢çŠ¶å°äºç½‘æ ¼çš„å½¢çŠ¶æ—¶ï¼Œæ‰ä¼šçœ‹åˆ°æ­¤é”™è¯¯ã€‚

```py
ValueError: One of pjit arguments was given the sharding of
NamedSharding(mesh={'x': 2, 'y': 2, 'chips': 2}, partition_spec=PartitionSpec(('x', 'y', 'chips'),)),
which implies that the global size of its dimension 0 should be divisible by 8,
but it is equal to 4 
```

é”™è¯¯å‡ºç°æ˜¯å› ä¸ºå½“ç»´åº¦`0`ä¸Šçš„å€¼ä¸º`4`æ—¶ï¼Œæ— æ³•å°†å…¶åˆ†ç‰‡æˆ 8 ä»½ã€‚

å¦‚æœä½ ä»ç„¶å°†ä¸»æœºæœ¬åœ°è¾“å…¥ä¼ é€’ç»™`pjit`ï¼Œå¦‚ä½•è¿ç§»ï¼Ÿæˆ‘ä»¬æä¾›äº†è¿‡æ¸¡ API æ¥å¸®åŠ©æ‚¨è¿ç§»ï¼š

æ³¨æ„ï¼šå¦‚æœæ‚¨åœ¨å•è¿›ç¨‹ä¸Šè¿è¡Œ`pjit`è®¡ç®—ï¼Œåˆ™ä¸éœ€è¦è¿™äº›å®ç”¨ç¨‹åºã€‚

```py
from jax.experimental import multihost_utils

global_inps = multihost_utils.host_local_array_to_global_array(
    local_inputs, mesh, in_pspecs)

global_outputs = pjit(f, in_shardings=in_pspecs,
                      out_shardings=out_pspecs)(global_inps)

local_outs = multihost_utils.global_array_to_host_local_array(
    global_outputs, mesh, out_pspecs) 
```

`host_local_array_to_global_array`æ˜¯ä¸€ç§ç±»å‹è½¬æ¢ï¼Œå®ƒæŸ¥çœ‹å…·æœ‰ä»…æœ¬åœ°åˆ†ç‰‡çš„å€¼ï¼Œå¹¶å°†å…¶æœ¬åœ°å½¢çŠ¶æ›´æ”¹ä¸ºåœ¨æ›´æ”¹ä¹‹å‰å¦‚æœä¼ é€’è¯¥å€¼`pjit`ä¼šå‡å®šçš„å½¢çŠ¶ã€‚

æ”¯æŒå®Œå…¨å¤åˆ¶çš„è¾“å…¥ï¼Œå³æ¯ä¸ªè¿›ç¨‹ä¸Šå…·æœ‰ç›¸åŒå½¢çŠ¶ï¼Œå¹¶ä¸”`in_axis_resources`ä¸º`P(None)`çš„æƒ…å†µã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨æ— éœ€ä½¿ç”¨`host_local_array_to_global_array`ï¼Œå› ä¸ºå½¢çŠ¶å·²ç»æ˜¯å…¨å±€çš„ã€‚

```py
key = jax.random.PRNGKey(1)

# As you can see, using host_local_array_to_global_array is not required since in_axis_resources says
# that the input is fully replicated via P(None)
pjit(f, in_shardings=None, out_shardings=None)(key)

# Mixing inputs
global_inp = multihost_utils.host_local_array_to_global_array(
    local_inp, mesh, P('data'))
global_out = pjit(f, in_shardings=(P(None), P('data')),
                  out_shardings=...)(key, global_inp) 
```

### `FROM_GDA`å’Œ`jax.Array`

å¦‚æœä½ åœ¨`in_axis_resources`å‚æ•°ä¸­ä½¿ç”¨`FROM_GDA`æ¥ä¼ é€’ç»™`pjit`ï¼Œé‚£ä¹ˆåœ¨ä½¿ç”¨`jax.Array`æ—¶ï¼Œæ— éœ€å‘`in_axis_resources`ä¼ é€’ä»»ä½•å†…å®¹ï¼Œå› ä¸º`jax.Array`å°†éµå¾ª**è®¡ç®—éµå¾ªåˆ†ç‰‡**çš„è¯­ä¹‰ã€‚

ä¾‹å¦‚ï¼š

```py
pjit(f, in_shardings=FROM_GDA, out_shardings=...) can be replaced by pjit(f, out_shardings=...) 
```

å¦‚æœä½ çš„è¾“å…¥ä¸­æ··åˆäº†`PartitionSpecs`å’Œ`FROM_GDA`ï¼Œä¾‹å¦‚ numpy æ•°ç»„ç­‰ï¼Œåˆ™ä½¿ç”¨`host_local_array_to_global_array`å°†å®ƒä»¬è½¬æ¢ä¸º`jax.Array`ã€‚

ä¾‹å¦‚ï¼š

å¦‚æœä½ æœ‰è¿™æ ·çš„æƒ…å†µï¼š

```py
pjitted_f = pjit(
    f, in_shardings=(FROM_GDA, P('x'), FROM_GDA, P(None)),
    out_shardings=...)
pjitted_f(gda1, np_array1, gda2, np_array2) 
```

ç„¶åæ‚¨å¯ä»¥å°†å…¶æ›¿æ¢ä¸ºï¼š

```py
 pjitted_f = pjit(f, out_shardings=...)

array2, array3 = multihost_utils.host_local_array_to_global_array(
    (np_array1, np_array2), mesh, (P('x'), P(None)))

pjitted_f(array1, array2, array3, array4) 
```

### `live_buffers`æ›¿æ¢ä¸º`live_arrays`ã€‚

jax `Device`ä¸Šçš„`live_buffers`å±æ€§å·²è¢«å¼ƒç”¨ã€‚è¯·æ”¹ç”¨ä¸`jax.Array`å…¼å®¹çš„`jax.live_arrays()`ã€‚

### å¤„ç†å‘`pjit`ä¼ é€’çš„ä¸»æœºæœ¬åœ°è¾“å…¥ï¼Œä¾‹å¦‚æ‰¹æ¬¡ç­‰ã€‚

å¦‚æœåœ¨**å¤šè¿›ç¨‹ç¯å¢ƒ**ä¸­å‘`pjit`ä¼ é€’ä¸»æœºæœ¬åœ°è¾“å…¥ï¼Œè¯·ä½¿ç”¨`multihost_utils.host_local_array_to_global_array`å°†æ‰¹æ¬¡è½¬æ¢ä¸ºå…¨å±€`jax.Array`ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™`pjit`ã€‚

è¿™ç§ä¸»æœºæœ¬åœ°è¾“å…¥æœ€å¸¸è§çš„ä¾‹å­æ˜¯**è¾“å…¥æ•°æ®æ‰¹æ¬¡**ã€‚

è¿™å¯¹ä»»ä½•ä¸»æœºæœ¬åœ°è¾“å…¥éƒ½æœ‰æ•ˆï¼ˆä¸ä»…ä»…æ˜¯è¾“å…¥æ•°æ®æ‰¹æ¬¡ï¼‰ã€‚

```py
from jax.experimental import multihost_utils

batch = multihost_utils.host_local_array_to_global_array(
    batch, mesh, batch_partition_spec) 
```

å…³äºè¿™ç§å˜åŒ–ä»¥åŠæ›´å¤šç¤ºä¾‹ï¼Œè¯·å‚é˜…ä¸Šé¢çš„ pjit éƒ¨åˆ†ã€‚

### RecursionErrorï¼šé€’å½’è°ƒç”¨ jit æ—¶å‘ç”Ÿçš„é”™è¯¯ã€‚

å½“ä½ çš„ä»£ç çš„æŸéƒ¨åˆ†ç¦ç”¨äº† `jax.Array`ï¼Œç„¶åä½ ä»…åœ¨å…¶ä»–éƒ¨åˆ†å¯ç”¨å®ƒæ—¶ä¼šå‡ºç°è¿™ç§æƒ…å†µã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ ä½¿ç”¨æŸäº›ç¬¬ä¸‰æ–¹ä»£ç ï¼Œè¯¥ä»£ç å·²ç¦ç”¨äº† `jax.Array` å¹¶ä»è¯¥åº“è·å¾—ä¸€ä¸ª `DeviceArray`ï¼Œç„¶ååœ¨ä½ çš„åº“ä¸­å¯ç”¨ `jax.Array` å¹¶å°†è¯¥ `DeviceArray` ä¼ é€’ç»™ JAX å‡½æ•°ï¼Œå°±ä¼šå¯¼è‡´ RecursionErrorã€‚

å½“ `jax.Array` é»˜è®¤å¯ç”¨æ—¶ï¼Œæ‰€æœ‰åº“éƒ½è¿”å› `jax.Array`ï¼Œé™¤éæ˜¾å¼ç¦ç”¨å®ƒï¼Œè¿™ä¸ªé”™è¯¯å°±åº”è¯¥æ¶ˆå¤±ã€‚
