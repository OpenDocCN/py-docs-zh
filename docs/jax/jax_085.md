# `jax.Array` 迁移

> 原文：[`jax.readthedocs.io/en/latest/jax_array_migration.html`](https://jax.readthedocs.io/en/latest/jax_array_migration.html)

**yashkatariya@**

## TL;DR

JAX 将其默认数组实现切换为新的 `jax.Array` 自版本 0.4.1 起。本指南解释了这一决定的背景，它可能对您的代码产生的影响，以及如何（临时）切换回旧行为。

### 发生了什么？

`jax.Array` 是 JAX 中统一的数组类型，包括 `DeviceArray`、`ShardedDeviceArray` 和 `GlobalDeviceArray` 类型。`jax.Array` 类型有助于使并行成为 JAX 的核心特性，简化和统一了 JAX 的内部结构，并允许我们统一 `jit` 和 `pjit`。如果你的代码没有涉及到 `DeviceArray`、`ShardedDeviceArray` 和 `GlobalDeviceArray` 的区别，那就不需要进行任何更改。但是依赖于这些单独类细节的代码可能需要进行调整以适配统一的 `jax.Array`。

迁移完成后，`jax.Array` 将成为 JAX 中唯一的数组类型。

本文介绍了如何将现有代码库迁移到 `jax.Array`。有关如何使用 `jax.Array` 和 JAX 并行 API 的更多信息，请参阅 [Distributed arrays and automatic parallelization](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html) 教程。

### 如何启用 `jax.Array`？

你可以通过以下方式启用 `jax.Array`：

+   设置 shell 环境变量 `JAX_ARRAY` 为真值（例如 `1`）；

+   如果你的代码使用 absl 解析标志，可以将布尔标志 `jax_array` 设置为真值；

+   在你的主文件顶部加入以下声明：

    ```py
    import jax
    jax.config.update('jax_array', True) 
    ```

### 如何判断 `jax.Array` 是否破坏了我的代码？

最简单的方法是禁用 `jax.Array`，看看问题是否解决。

### 我如何暂时禁用 `jax.Array`？

通过 **2023 年 3 月 15 日**，可以通过以下方式禁用 `jax.Array`：

+   设置 shell 环境变量 `JAX_ARRAY` 为假值（例如 `0`）；

+   如果你的代码使用 absl 解析标志，可以将布尔标志 `jax_array` 设置为假值；

+   在你的主文件顶部加入以下声明：

    ```py
    import jax
    jax.config.update('jax_array', False) 
    ```

## 为什么创建 `jax.Array`？

当前 JAX 有三种类型：`DeviceArray`、`ShardedDeviceArray` 和 `GlobalDeviceArray`。`jax.Array` 合并了这三种类型，并清理了 JAX 的内部结构，同时增加了新的并行特性。

我们还引入了一个新的 `Sharding` 抽象，描述了逻辑数组如何在一个或多个设备（如 TPU 或 GPU）上物理分片。这一变更还升级、简化并将 `pjit` 的并行性特性合并到 `jit` 中。使用 `jit` 装饰的函数将能够在分片数组上操作，而无需将数据复制到单个设备上。

使用 `jax.Array` 可以获得的功能：

+   C++ `pjit` 分派路径

+   逐操作并行性（即使数组分布在多台设备上，跨多个主机）

+   使用 `pjit`/`jit` 更简单的批数据并行性。

+   可以完全利用 OpSharding 的灵活性，或者任何您想要的其他分片方式来创建不一定包含网格和分区规范的 `Sharding`。

+   等等

示例：

```py
import jax
import jax.numpy as jnp
from jax.sharding import PartitionSpec as P
import numpy as np
x = jnp.arange(8)

# Let's say there are 8 devices in jax.devices()
mesh = jax.sharding.Mesh(np.array(jax.devices()).reshape(4, 2), ('x', 'y'))
sharding = jax.sharding.NamedSharding(mesh, P('x'))

sharded_x = jax.device_put(x, sharding)

# `matmul_sharded_x` and `sin_sharded_x` are sharded. `jit` is able to operate over a
# sharded array without copying data to a single device.
matmul_sharded_x = sharded_x @ sharded_x.T
sin_sharded_x = jnp.sin(sharded_x)

# Even jnp.copy preserves the sharding on the output.
copy_sharded_x = jnp.copy(sharded_x)

# double_out is also sharded
double_out = jax.jit(lambda x: x * 2)(sharded_x) 
```

## 切换到 `jax.Array` 后可能会出现哪些问题？

### 新公共类型命名为 `jax.Array`。

所有 `isinstance(..., jnp.DeviceArray)` 或 `isinstance(.., jax.xla.DeviceArray)` 以及其他 `DeviceArray` 的变体应该切换到使用 `isinstance(..., jax.Array)`。

由于 `jax.Array` 可以表示 DA、SDA 和 GDA，您可以通过以下方式在 `jax.Array` 中区分这三种类型：

+   `x.is_fully_addressable and len(x.sharding.device_set) == 1` – 这意味着 `jax.Array` 类似于 DA。

+   `x.is_fully_addressable and (len(x.sharding.device_set) > 1` – 这意味着 `jax.Array` 类似于 SDA。

+   `not x.is_fully_addressable` – 这意味着 `jax.Array` 类似于 GDA，并跨多个进程。

对于 `ShardedDeviceArray`，可以将 `isinstance(..., pxla.ShardedDeviceArray)` 转移到 `isinstance(..., jax.Array) and x.is_fully_addressable and len(x.sharding.device_set) > 1`。

通常无法区分单设备数组上的 `ShardedDeviceArray` 与任何其他类型的单设备数组。

### GDA 的 API 名称变更

GDA 的 `local_shards` 和 `local_data` 已经被弃用。

请使用与 `jax.Array` 和 `GDA` 兼容的 `addressable_shards` 和 `addressable_data`。

### 创建 `jax.Array`。

当 `jax_array` 标志为真时，所有 JAX 函数将输出 `jax.Array`。如果您曾使用 `GlobalDeviceArray.from_callback`、`make_sharded_device_array` 或 `make_device_array` 函数显式创建相应的 JAX 数据类型，则需要切换为使用 `jax.make_array_from_callback()` 或 `jax.make_array_from_single_device_arrays()`。

**对于 GDA：**

`GlobalDeviceArray.from_callback(shape, mesh, pspec, callback)` 可以一对一地切换为 `jax.make_array_from_callback(shape, jax.sharding.NamedSharding(mesh, pspec), callback)`。

如果您曾使用原始的 GDA 构造函数来创建 GDAs，则执行以下操作：

`GlobalDeviceArray(shape, mesh, pspec, buffers)` 可以变成 `jax.make_array_from_single_device_arrays(shape, jax.sharding.NamedSharding(mesh, pspec), buffers)`。

**对于 SDA：**

`make_sharded_device_array(aval, sharding_spec, device_buffers, indices)` 可以变成 `jax.make_array_from_single_device_arrays(shape, sharding, device_buffers)`。

要决定分片应该是什么，取决于您创建 SDA 的原因：

如果它被创建为 `pmap` 的输入，则分片可以是：`jax.sharding.PmapSharding(devices, sharding_spec)`。

如果它被创建为 pjit 的输入，则分片可以是 `jax.sharding.NamedSharding(mesh, pspec)`。

### 切换到 `jax.Array` 后对于主机本地输入的 pjit 有破坏性变更。

**如果您完全使用 GDA 参数作为 pjit 的输入，则可以跳过此部分！ 🎉**

启用`jax.Array`后，所有传递给`pjit`的输入必须是全局形状的。这是与之前行为不兼容的变化，之前的`pjit`会将进程本地的参数连接成一个全局值；现在不再进行此连接。

为什么我们要进行这个突破性的变化？现在每个数组都明确说明了它的本地分片如何适合全局整体，而不是留下隐含的情况。更明确的表示方式还可以解锁额外的灵活性，例如在某些 TPU 模型上可以提高效率的非连续网格使用`pjit`。

在启用`jax.Array`时，运行**多进程 pjit 计算**并在传递主机本地输入时可能会导致类似以下错误：

示例：

`Mesh = {'x': 2, 'y': 2, 'z': 2}` 和主机本地输入形状 == `(4,)` 以及`pspec = P(('x', 'y', 'z'))`

因为`pjit`不会将主机本地形状提升为全局形状，所以您会收到以下错误：

注意：只有当您的主机本地形状小于网格的形状时，才会看到此错误。

```py
ValueError: One of pjit arguments was given the sharding of
NamedSharding(mesh={'x': 2, 'y': 2, 'chips': 2}, partition_spec=PartitionSpec(('x', 'y', 'chips'),)),
which implies that the global size of its dimension 0 should be divisible by 8,
but it is equal to 4 
```

错误出现是因为当维度`0`上的值为`4`时，无法将其分片成 8 份。

如果你仍然将主机本地输入传递给`pjit`，如何迁移？我们提供了过渡 API 来帮助您迁移：

注意：如果您在单进程上运行`pjit`计算，则不需要这些实用程序。

```py
from jax.experimental import multihost_utils

global_inps = multihost_utils.host_local_array_to_global_array(
    local_inputs, mesh, in_pspecs)

global_outputs = pjit(f, in_shardings=in_pspecs,
                      out_shardings=out_pspecs)(global_inps)

local_outs = multihost_utils.global_array_to_host_local_array(
    global_outputs, mesh, out_pspecs) 
```

`host_local_array_to_global_array`是一种类型转换，它查看具有仅本地分片的值，并将其本地形状更改为在更改之前如果传递该值`pjit`会假定的形状。

支持完全复制的输入，即每个进程上具有相同形状，并且`in_axis_resources`为`P(None)`的情况。在这种情况下，您无需使用`host_local_array_to_global_array`，因为形状已经是全局的。

```py
key = jax.random.PRNGKey(1)

# As you can see, using host_local_array_to_global_array is not required since in_axis_resources says
# that the input is fully replicated via P(None)
pjit(f, in_shardings=None, out_shardings=None)(key)

# Mixing inputs
global_inp = multihost_utils.host_local_array_to_global_array(
    local_inp, mesh, P('data'))
global_out = pjit(f, in_shardings=(P(None), P('data')),
                  out_shardings=...)(key, global_inp) 
```

### `FROM_GDA`和`jax.Array`

如果你在`in_axis_resources`参数中使用`FROM_GDA`来传递给`pjit`，那么在使用`jax.Array`时，无需向`in_axis_resources`传递任何内容，因为`jax.Array`将遵循**计算遵循分片**的语义。

例如：

```py
pjit(f, in_shardings=FROM_GDA, out_shardings=...) can be replaced by pjit(f, out_shardings=...) 
```

如果你的输入中混合了`PartitionSpecs`和`FROM_GDA`，例如 numpy 数组等，则使用`host_local_array_to_global_array`将它们转换为`jax.Array`。

例如：

如果你有这样的情况：

```py
pjitted_f = pjit(
    f, in_shardings=(FROM_GDA, P('x'), FROM_GDA, P(None)),
    out_shardings=...)
pjitted_f(gda1, np_array1, gda2, np_array2) 
```

然后您可以将其替换为：

```py
 pjitted_f = pjit(f, out_shardings=...)

array2, array3 = multihost_utils.host_local_array_to_global_array(
    (np_array1, np_array2), mesh, (P('x'), P(None)))

pjitted_f(array1, array2, array3, array4) 
```

### `live_buffers`替换为`live_arrays`。

jax `Device`上的`live_buffers`属性已被弃用。请改用与`jax.Array`兼容的`jax.live_arrays()`。

### 处理向`pjit`传递的主机本地输入，例如批次等。

如果在**多进程环境**中向`pjit`传递主机本地输入，请使用`multihost_utils.host_local_array_to_global_array`将批次转换为全局`jax.Array`，然后将其传递给`pjit`。

这种主机本地输入最常见的例子是**输入数据批次**。

这对任何主机本地输入都有效（不仅仅是输入数据批次）。

```py
from jax.experimental import multihost_utils

batch = multihost_utils.host_local_array_to_global_array(
    batch, mesh, batch_partition_spec) 
```

关于这种变化以及更多示例，请参阅上面的 pjit 部分。

### RecursionError：递归调用 jit 时发生的错误。

当你的代码的某部分禁用了 `jax.Array`，然后你仅在其他部分启用它时会出现这种情况。例如，如果你使用某些第三方代码，该代码已禁用了 `jax.Array` 并从该库获得一个 `DeviceArray`，然后在你的库中启用 `jax.Array` 并将该 `DeviceArray` 传递给 JAX 函数，就会导致 RecursionError。

当 `jax.Array` 默认启用时，所有库都返回 `jax.Array`，除非显式禁用它，这个错误就应该消失。
