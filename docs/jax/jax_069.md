# 全面暂存

> 原文：[`jax.readthedocs.io/en/latest/jep/4410-omnistaging.html`](https://jax.readthedocs.io/en/latest/jep/4410-omnistaging.html)

*mattjj@* *Sept 25 2020*

这更像是升级指南而不是设计文档。

## 目录

+   简而言之

+   “全面暂存”是什么以及其有何用处？

+   开启全面暂存可能导致哪些问题？

    +   使用 `jax.numpy` 进行形状计算

    +   副作用

    +   基于 XLA 优化的小数值差异

    +   依赖于已更改的 JAX 内部 API

    +   触发 XLA 编译时错误

## 简而言之

### 发生了什么？

JAX 的跟踪基础设施发生的名为“全面暂存”（[google/jax#3370](https://github.com/google/jax/pull/3370)）在 jax==0.2.0 中启用。此更改改善了内存性能、跟踪执行时间并简化了 jax 内部，但可能导致某些现有代码出现问题。通常情况下，问题是由于有 bug 的代码引起的，因此从长远来看最好修复这些 bug，但全面暂存也可以作为临时解决方法禁用。我们乐意帮助您进行修复！

### 如何知道全面暂存破坏了我的代码？

判断全面暂存是否负责的最简单方法是禁用全面暂存并查看问题是否消失。请参阅下面的“开启全面暂存可能导致哪些问题？”部分。

### 如何暂时禁用全面暂存？

*注意：这适用于 JAX 版本 0.2.0 到 0.2.11；在 JAX 版本 0.2.12 及更高版本中无法禁用全面暂存*

暂时可以通过以下方式禁用全面暂存

1.  将 shell 环境变量 `JAX_OMNISTAGING` 设置为 falsey；

1.  如果你的代码使用 absl 解析标志，则将布尔标志 `jax_omnistaging` 设置为 falsey；

1.  在主文件顶部附近使用此语句：

```py
jax.config.disable_omnistaging() 
```

### 如何修复全面暂存暴露的错误？

全面暂存最常见的问题远远超过了使用 `jax.numpy` 计算形状值或其他跟踪时间常量。请参阅下面的代码块，快速了解示例，并详细了解其他问题，请参阅“开启全面暂存可能导致哪些问题？”部分。

现在改为：

```py
@jit
def f(x):
  input_size = jnp.prod(x.shape)
  if input_size > 100:
    ... 
```

请执行以下操作：

```py
import numpy as np

@jit
def f(x):
  input_size = np.prod(x.shape)
  if input_size > 100:
    ... 
```

现在不再将 `jax.numpy` 视为 `numpy` 的可替代品，现在最好仅在需要在加速器（如 GPU）上执行计算时才考虑使用 `jax.numpy` 操作。

## “全面暂存”是什么以及其有何用处？

全面暂存是 JAX 核心升级的名称，旨在从逐操作的 Python 到 XLA 分阶段进行计算，并避免在 `jit`、`pmap` 和控制流原语中进行“跟踪时间常量折叠”。因此，全面暂存通过减少跟踪过程中的碎片化和生成更少的 XLA 编译时常量（有时会显著降低）来改善 JAX 的内存性能。它还可以通过在跟踪时间消除逐操作执行来改善跟踪性能。此外，全面暂存简化了 JAX 核心内部结构，修复了许多未解决的 bug，并为重要的即将推出的功能铺平了道路。

名称“全面暂存”意味着尽可能分阶段输出所有内容。

### 玩具示例

像`jit`和`pmap`这样的 JAX 变换将计算分阶段到 XLA。也就是说，我们将它们应用于由多个原始操作组成的函数，使得这些操作不再从 Python 中逐个执行，而是作为一个端到端优化的 XLA 计算的一部分。

但确切地说哪些操作被分阶段了？在全阶段之前，JAX 仅基于数据依赖性分阶段计算。这里有一个示例函数，后面是它在全阶段更改*之前*分阶段的 XLA HLO 程序：

```py
from jax import jit
import jax.numpy as jnp

@jit
def f(x):
  y = jnp.add(1, 1)
  return x * y

f(3) 
```

```py
ENTRY jit_f.6 {
  constant.2 = pred[] constant(false)
  parameter.1 = s32[] parameter(0)
  constant.3 = s32[] constant(2)
  multiply.4 = s32[] multiply(parameter.1, constant.3)
  ROOT tuple.5 = (s32[]) tuple(multiply.4)
} 
```

注意，`add`操作没有被分阶段。相反，我们只看到一个乘法。

这是从这个函数生成的 HLO，在全阶段更改*之后*：

```py
ENTRY jit_f.8 {
  constant.2 = pred[] constant(false)
  parameter.1 = s32[] parameter(0)
  constant.3 = s32[] constant(1)
  constant.4 = s32[] constant(1)
  add.5 = s32[] add(constant.3, constant.4)
  multiply.6 = s32[] multiply(parameter.1, add.5)
  ROOT tuple.7 = (s32[]) tuple(multiply.6)
} 
```

### 稍微不那么玩具的示例

这里是在实践中可能出现的一个不那么玩具的示例，当我们想要创建布尔掩码时：

```py
import jax.numpy as jnp
from jax import lax

@jit
def select_tril(x):
  mask = jnp.arange(x.shape[0])[:, None] > jnp.arange(x.shape[1])
  return lax.select(mask, x, jnp.zeros_like(x))  # lax.select is like jnp.where

x = np.arange(12).reshape((3, 4))
select_tril(x) 
```

*在*全阶段之前：

```py
ENTRY jit_select_tril.8 {
  constant.3 = pred[] constant(false)
  constant.1 = pred[3,4]{1,0} constant({...})
  parameter.2 = s32[3,4]{1,0} parameter(0)
  constant.4 = s32[] constant(0)
  broadcast.5 = s32[3,4]{1,0} broadcast(constant.4), dimensions={}
  select.6 = s32[3,4]{1,0} select(constant.1, parameter.2, broadcast.5)
  ROOT tuple.7 = (s32[3,4]{1,0}) tuple(select.6)
} 
```

`select`操作被分阶段了，但用于构建常量`mask`的操作却没有。而不是被分阶段，构建`mask`的操作在 Python 追踪时逐个操作地执行，并且 XLA 只看到一个编译时常量`constant.1`，表示`mask`的值。这是不幸的，因为如果我们已经分阶段了构建`mask`的操作，XLA 可以将它们融合到`select`中，并避免完全实现结果。因此，我们最终会浪费内存，因为一个可能很大的常量，浪费时间分派多个未融合的逐个操作的 XLA 计算，甚至可能会导致内存碎片化。

（与为`jnp.zeros_like(x)`构建零数组的广播相对应的操作被分阶段，因为 JAX 对来自[google/jax#1668](https://github.com/google/jax/pull/1668)的非常简单表达式很懒惰。在全阶段之后，我们可以去掉那个懒惰的子语言，并简化 JAX 内部。）

创建`mask`的原因不被分阶段的原因是，在全阶段之前，`jit`基于数据依赖性运行。也就是说，`jit`仅分阶段一个函数中对参数有数据依赖性的操作。控制流基元和`pmap`的行为类似。在`select_tril`的情况下，用于构建常量`mask`的操作与参数 x 没有数据依赖关系，因此它们不会被分阶段；只有`lax.select`调用具有数据依赖性。

使用全阶段后，`jit`转换函数的动态上下文中的所有`jax.numpy`调用都被分阶段到 XLA。也就是说，在全阶段后，`select_tril`的计算 XLA 看到的是

```py
ENTRY jit_select_tril.16 {
  constant.4 = pred[] constant(false)
  iota.1 = s32[3]{0} iota(), iota_dimension=0
  broadcast.5 = s32[3,1]{1,0} broadcast(iota.1), dimensions={0}
  reshape.7 = s32[3]{0} reshape(broadcast.5)
  broadcast.8 = s32[3,4]{1,0} broadcast(reshape.7), dimensions={0}
  iota.2 = s32[4]{0} iota(), iota_dimension=0
  broadcast.6 = s32[1,4]{1,0} broadcast(iota.2), dimensions={1}
  reshape.9 = s32[4]{0} reshape(broadcast.6)
  broadcast.10 = s32[3,4]{1,0} broadcast(reshape.9), dimensions={1}
  compare.11 = pred[3,4]{1,0} compare(broadcast.8, broadcast.10), direction=GT
  parameter.3 = s32[3,4]{1,0} parameter(0)
  constant.12 = s32[] constant(0)
  broadcast.13 = s32[3,4]{1,0} broadcast(constant.12), dimensions={}
  select.14 = s32[3,4]{1,0} select(compare.11, parameter.3, broadcast.13)
  ROOT tuple.15 = (s32[3,4]{1,0}) tuple(select.14)
} 
```

## 当全阶段打开时可能会出现哪些问题？

当在`jit`或`pmap`的动态上下文中，从 Python 到 XLA 分阶段所有`jax.numpy`操作的结果，一些之前正常工作的代码可能会开始引发大声的错误。正如下文所解释的那样，这些行为在全阶段之前已经存在 bug，但全阶段将它们变成了严格的错误。

### 使用`jax.numpy`进行形状计算

#### 示例

```py
from jax import jit
import jax.numpy as jnp

@jit
def ex1(x):
  size = jnp.prod(jnp.array(x.shape))
  return x.reshape((size,))

ex1(jnp.ones((3, 4))) 
```

#### 错误消息

```py
[... full traceback ...]
  File "/home/mattjj/packages/jax/jax/core.py", line 862, in raise_concretization_error
    raise ConcretizationTypeError(msg)
jax.core.ConcretizationTypeError: Abstract tracer value encountered where concrete value is expected.

The error arose in jax.numpy.reshape.

While tracing the function ex1 at ex1.py:4, this value became a tracer due to JAX operations on these lines:

  operation c:int32[] = reduce_prod[ axes=(0,) ] b:int32[2]
    from line ex1.py:6 (ex1)

You can use transformation parameters such as `static_argnums` for `jit` to avoid tracing particular arguments of transformed functions.

See https://jax.readthedocs.io/en/latest/faq.html#abstract-tracer-value-encountered-where-concrete-value-is-expected-error for more information.

Encountered tracer value: Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=0/1)> 
```

#### 解释

在全面化下，我们不能像上面使用`jnp.prod`一样在 jit 函数的动态上下文中使用`jax.numpy`进行形状计算，因为这些操作将被分阶段为在执行时计算的值，但我们需要它们是编译时常量（因此是跟踪时常量）。

在全面化之前，这段代码不会引发错误，但这是一个常见的性能 bug：`jnp.prod`计算将在跟踪时间在设备上执行，意味着额外的编译、传输、同步、分配和潜在的内存碎片化。

#### 解决方案

解决方法很简单，就是像这样的形状计算使用原始的`numpy`。这不仅避免了错误，还将计算保持在主机上（并且开销更低）。

在代码中，这个问题很常见，我们努力使错误消息尤其好。除了堆栈跟踪显示抽象跟踪器值导致问题的位置（完整堆栈跟踪中的`jnp.reshape`行，在 omni.py:10），我们还解释了这个值首先变成跟踪器的原因，指向导致它成为抽象跟踪器的上游原始操作（来自`jnp.prod`中的`reduce_prod`，在 omni.py:9），以及跟踪器属于哪个带`jit`装饰的函数（在 omni.py:6 中的`ex1`）。

### 副作用

#### 示例

```py
from jax import jit
from jax import random

key = random.PRNGKey(0)

def init():
  global key
  key, subkey = random.split(key)
  return random.normal(subkey, ())

print(init())  # -1.2515389
print(init())  # -0.58665067

init = jit(init)
print(init())  # 0.48648298
print(init())  # 0.48648298  !! 
```

最后一个调用具有重复的随机性，但没有硬错误，因为我们没有重新执行 Python。但是如果我们查看`key`，我们会看到一个逃逸的跟踪器*开启全面化时*：

```py
print(key) # Traced<ShapedArray(uint32[2])>with<DynamicJaxprTrace(level=0/1)> 
```

在全面化之前，`random.split`调用不会被分阶段处理，因此我们不会得到逃逸的跟踪器。由于重复使用相同的 PRNG 密钥，代码仍然存在 bug，即编译函数无法复制原始函数的语义（因为有副作用）。

在开启全面化时，如果再次触及`key`，将会得到一个逃逸的跟踪器错误：

```py
random.normal(key, ()) 
```

#### 错误消息

```py
[... full stack trace …]
  File "/home/mattjj/packages/jax/jax/interpreters/partial_eval.py", line 836, in _assert_live
    raise core.escaped_tracer_error(msg)
jax.core.UnexpectedTracerError: Encountered an unexpected tracer. Perhaps this tracer escaped through global state from a previously traced function.
The functions being transformed should not save traced values to global state. Detail: tracer created on line example.py:8 (init). 
```

#### 解释

我们发现的次大类全面化问题与副作用代码有关。这些代码通过转换有副作用的函数已经使 JAX 的保证失效，但由于预全面化的“跟踪时间常数折叠”行为，一些有副作用的函数仍然可能表现正确。全面化能更多地捕捉这些错误。

#### 解决方案

解决方法是识别依赖副作用的 JAX 转换函数，并重新编写它们以避免有副作用。

### 基于 XLA 优化的小数值差异

因为在全面化下，更多的计算被分阶段到 XLA，而不是在跟踪时间执行，这可能导致浮点运算的重新排序。结果是，我们看到数值行为以一种导致测试在开启全面化时失败的方式改变，因为它们对于过紧容差的测试失败。

### 依赖于 JAX 内部 API 的变化

Omnistaging 涉及对 JAX 核心代码进行了一些重大修改，包括删除或更改内部函数。任何依赖这些内部 JAX API 的代码，在 omnistaging 打开时都可能会出现问题，可能是构建错误（来自 pytype）或运行时错误。

### 触发 XLA 编译时错误

由于 omnistaging 涉及将更多代码分阶段传递给 XLA，我们发现它可能会在某些后端触发现有的 XLA 编译时错误。对于这些问题，最好的做法是报告它们，以便我们与 XLA 团队合作进行修复。
