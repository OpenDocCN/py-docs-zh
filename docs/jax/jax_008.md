# 即时编译

> 原文：[`jax.readthedocs.io/en/latest/jit-compilation.html`](https://jax.readthedocs.io/en/latest/jit-compilation.html)

在这一部分，我们将进一步探讨 JAX 的工作原理，以及如何使其性能卓越。我们将讨论 `jax.jit()` 变换，它将 JAX Python 函数进行即时编译，以便在 XLA 中高效执行。

## 如何工作 JAX 变换

在前一节中，我们讨论了 JAX 允许我们转换 Python 函数的能力。JAX 通过将每个函数减少为一系列原始操作来实现这一点，每个原始操作代表一种基本的计算单位。

查看函数背后原始操作序列的一种方法是使用 `jax.make_jaxpr()`：

```py
import jax
import jax.numpy as jnp

global_list = []

def log2(x):
  global_list.append(x)
  ln_x = jnp.log(x)
  ln_2 = jnp.log(2.0)
  return ln_x / ln_2

print(jax.make_jaxpr(log2)(3.0)) 
```

```py
{ lambda ; a:f32[]. let
    b:f32[] = log a
    c:f32[] = log 2.0
    d:f32[] = div b c
  in (d,) } 
```

文档的理解 Jaxprs 部分提供了有关上述输出含义的更多信息。

重要的是要注意，jaxpr 不捕获函数中存在的副作用：其中没有对 `global_list.append(x)` 的任何内容。这是一个特性，而不是一个错误：JAX 变换旨在理解无副作用（也称为函数纯粹）的代码。如果 *纯函数* 和 *副作用* 是陌生的术语，这在 [🔪 JAX - The Sharp Bits 🔪: Pure Functions](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#pure-functions) 中有稍微详细的解释。

非纯函数很危险，因为在 JAX 变换下它们可能无法按预期运行；它们可能会悄无声息地失败，或者产生意外的下游错误，如泄漏的跟踪器。此外，JAX 通常无法检测到是否存在副作用。（如果需要调试打印，请使用 `jax.debug.print()`。要表达一般性副作用而牺牲性能，请参阅 `jax.experimental.io_callback()`。要检查跟踪器泄漏而牺牲性能，请使用 `jax.check_tracer_leaks()`）。

在跟踪时，JAX 通过 *跟踪器* 对象包装每个参数。这些跟踪器记录了在函数调用期间（即在常规 Python 中发生）对它们执行的所有 JAX 操作。然后，JAX 使用跟踪器记录重构整个函数。重构的输出是 jaxpr。由于跟踪器不记录 Python 的副作用，它们不会出现在 jaxpr 中。但是，副作用仍会在跟踪过程中发生。

注意：Python 的 `print()` 函数不是纯函数：文本输出是函数的副作用。因此，在跟踪期间，任何 `print()` 调用都将只发生一次，并且不会出现在 jaxpr 中：

```py
def log2_with_print(x):
  print("printed x:", x)
  ln_x = jnp.log(x)
  ln_2 = jnp.log(2.0)
  return ln_x / ln_2

print(jax.make_jaxpr(log2_with_print)(3.)) 
```

```py
printed x: Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=1/0)>
{ lambda ; a:f32[]. let
    b:f32[] = log a
    c:f32[] = log 2.0
    d:f32[] = div b c
  in (d,) } 
```

看看打印出来的 `x` 是一个 `Traced` 对象？这就是 JAX 内部的工作原理。

Python 代码至少运行一次的事实严格来说是一个实现细节，因此不应依赖它。然而，在调试时理解它是有用的，因为您可以在计算的中间值打印出来。

一个关键的理解点是，jaxpr 捕捉函数在给定参数上执行的方式。例如，如果我们有一个 Python 条件语句，jaxpr 只会了解我们选择的分支：

```py
def log2_if_rank_2(x):
  if x.ndim == 2:
    ln_x = jnp.log(x)
    ln_2 = jnp.log(2.0)
    return ln_x / ln_2
  else:
    return x

print(jax.make_jaxpr(log2_if_rank_2)(jax.numpy.array([1, 2, 3]))) 
```

```py
{ lambda ; a:i32[3]. let  in (a,) } 
```

## JIT 编译函数

正如之前所解释的，JAX 使得操作能够使用相同的代码在 CPU/GPU/TPU 上执行。让我们看一个计算*缩放指数线性单元*（[SELU](https://proceedings.neurips.cc/paper/6698-self-normalizing-neural-networks.pdf)）的例子，这是深度学习中常用的操作：

```py
import jax
import jax.numpy as jnp

def selu(x, alpha=1.67, lambda_=1.05):
  return lambda_ * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)

x = jnp.arange(1000000)
%timeit selu(x).block_until_ready() 
```

```py
2.81 ms ± 27 μs per loop (mean ± std. dev. of 7 runs, 100 loops each) 
```

上述代码一次只发送一个操作到加速器。这限制了 XLA 编译器优化我们函数的能力。

自然地，我们希望尽可能多地向 XLA 编译器提供代码，以便它能够完全优化它。为此，JAX 提供了`jax.jit()`转换，它将即时编译一个与 JAX 兼容的函数。下面的示例展示了如何使用 JIT 加速前述函数。

```py
selu_jit = jax.jit(selu)

# Pre-compile the function before timing...
selu_jit(x).block_until_ready()

%timeit selu_jit(x).block_until_ready() 
```

```py
1.01 ms ± 2.6 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each) 
```

刚刚发生了什么事：

1.  我们定义了`selu_jit`作为`selu`的编译版本。

1.  我们在`x`上调用了`selu_jit`一次。这是 JAX 进行其追踪的地方 - 它需要一些输入来包装成追踪器。然后，jaxpr 使用 XLA 编译成非常高效的代码，针对您的 GPU 或 TPU 进行优化。最后，编译的代码被执行以满足调用。后续对`selu_jit`的调用将直接使用编译后的代码，跳过 Python 实现。（如果我们没有单独包括预热调用，一切仍将正常运行，但编译时间将包含在基准测试中。因为我们在基准测试中运行多个循环，所以仍会更快，但这不是公平的比较。）

1.  我们计时了编译版本的执行速度。（注意使用`block_until_ready()`，这是由于 JAX 的异步调度所需。）

## 为什么我们不能把所有东西都即时编译（JIT）呢？

在上面的例子中，你可能会想知道我们是否应该简单地对每个函数应用`jax.jit()`。要理解为什么不是这样，并且何时需要/不需要应用`jit`，让我们首先检查一些`jit`不适用的情况。

```py
# Condition on value of x.

def f(x):
  if x > 0:
    return x
  else:
    return 2 * x

jax.jit(f)(10)  # Raises an error 
```

```py
TracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[]..
The error occurred while tracing the function f at /tmp/ipykernel_1169/2956679937.py:3 for jit. This concrete value was not available in Python because it depends on the value of the argument x.
See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError 
```

```py
# While loop conditioned on x and n.

def g(x, n):
  i = 0
  while i < n:
    i += 1
  return x + i

jax.jit(g)(10, 20)  # Raises an error 
```

```py
TracerBoolConversionError: Attempted boolean conversion of traced array with shape bool[]..
The error occurred while tracing the function g at /tmp/ipykernel_1169/722961019.py:3 for jit. This concrete value was not available in Python because it depends on the value of the argument n.
See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError 
```

在这两种情况下的问题是，我们尝试使用运行时值来条件追踪时间流程。在 JIT 中追踪的值，例如这里的`x`和`n`，只能通过它们的静态属性（如`shape`或`dtype`）影响控制流，而不能通过它们的值。有关 Python 控制流与 JAX 交互的更多详细信息，请参见[🔪 JAX - The Sharp Bits 🔪: Control Flow](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#control-flow)。

处理这个问题的一种方法是重写代码，避免在值条件上使用条件语句。另一种方法是使用特殊的控制流操作符，例如`jax.lax.cond()`。然而，有时这并不可行或实际。在这种情况下，可以考虑只对函数的部分进行 JIT 编译。例如，如果函数中最消耗计算资源的部分在循环内部，我们可以只对内部的那部分进行 JIT 编译（但务必查看关于缓存的下一节，以避免出现问题）：

```py
# While loop conditioned on x and n with a jitted body.

@jax.jit
def loop_body(prev_i):
  return prev_i + 1

def g_inner_jitted(x, n):
  i = 0
  while i < n:
    i = loop_body(i)
  return x + i

g_inner_jitted(10, 20) 
```

```py
Array(30, dtype=int32, weak_type=True) 
```

## 将参数标记为静态的

如果我们确实需要对具有输入值条件的函数进行 JIT 编译，我们可以告诉 JAX 通过指定`static_argnums`或`static_argnames`来帮助自己获取特定输入的较少抽象的追踪器。这样做的成本是生成的 jaxpr 和编译的工件依赖于传递的特定值，因此 JAX 将不得不针对指定静态输入的每个新值重新编译函数。只有在函数保证看到有限的静态值集时，这才是一个好策略。

```py
f_jit_correct = jax.jit(f, static_argnums=0)
print(f_jit_correct(10)) 
```

```py
10 
```

```py
g_jit_correct = jax.jit(g, static_argnames=['n'])
print(g_jit_correct(10, 20)) 
```

```py
30 
```

当使用`jit`作为装饰器时，要指定这些参数的一种常见模式是使用 Python 的[`functools.partial()`](https://docs.python.org/3/library/functools.html#functools.partial "(在 Python v3.12 中)")：

```py
from functools import partial

@partial(jax.jit, static_argnames=['n'])
def g_jit_decorated(x, n):
  i = 0
  while i < n:
    i += 1
  return x + i

print(g_jit_decorated(10, 20)) 
```

```py
30 
```

## JIT 和缓存

通过第一次 JIT 调用的编译开销，了解`jax.jit()`如何以及何时缓存先前的编译是有效使用它的关键。

假设我们定义`f = jax.jit(g)`。当我们首次调用`f`时，它会被编译，并且生成的 XLA 代码将被缓存。后续调用`f`将重用缓存的代码。这就是`jax.jit`如何弥补编译的前期成本。

如果我们指定了`static_argnums`，那么缓存的代码将仅在标记为静态的参数值相同时使用。如果它们中任何一个发生更改，将重新编译。如果存在许多值，则您的程序可能会花费更多时间进行编译，而不是逐个执行操作。

避免在循环或其他 Python 作用域内定义的临时函数上调用`jax.jit()`。对于大多数情况，JAX 能够在后续调用`jax.jit()`时使用编译和缓存的函数。然而，由于缓存依赖于函数的哈希值，在重新定义等价函数时会引发问题。这将导致每次在循环中不必要地重新编译：

```py
from functools import partial

def unjitted_loop_body(prev_i):
  return prev_i + 1

def g_inner_jitted_partial(x, n):
  i = 0
  while i < n:
    # Don't do this! each time the partial returns
    # a function with different hash
    i = jax.jit(partial(unjitted_loop_body))(i)
  return x + i

def g_inner_jitted_lambda(x, n):
  i = 0
  while i < n:
    # Don't do this!, lambda will also return
    # a function with a different hash
    i = jax.jit(lambda x: unjitted_loop_body(x))(i)
  return x + i

def g_inner_jitted_normal(x, n):
  i = 0
  while i < n:
    # this is OK, since JAX can find the
    # cached, compiled function
    i = jax.jit(unjitted_loop_body)(i)
  return x + i

print("jit called in a loop with partials:")
%timeit g_inner_jitted_partial(10, 20).block_until_ready()

print("jit called in a loop with lambdas:")
%timeit g_inner_jitted_lambda(10, 20).block_until_ready()

print("jit called in a loop with caching:")
%timeit g_inner_jitted_normal(10, 20).block_until_ready() 
```

```py
jit called in a loop with partials:
217 ms ± 2.03 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
jit called in a loop with lambdas:
219 ms ± 5.44 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
jit called in a loop with caching:
2.33 ms ± 29.5 μs per loop (mean ± std. dev. of 7 runs, 100 loops each) 
```
