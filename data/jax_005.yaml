- en: JAX Frequently Asked Questions (FAQ)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JAX 常见问题解答（FAQ）
- en: 原文：[`jax.readthedocs.io/en/latest/faq.html`](https://jax.readthedocs.io/en/latest/faq.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`jax.readthedocs.io/en/latest/faq.html`](https://jax.readthedocs.io/en/latest/faq.html)
- en: We are collecting answers to frequently asked questions here. Contributions
    welcome!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里收集了一些经常被问到的问题的答案。欢迎贡献！
- en: '`jit` changes the behavior of my function'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`jit`改变了我的函数行为'
- en: 'If you have a Python function that changes behavior after using `jax.jit()`,
    perhaps your function uses global state, or has side-effects. In the following
    code, the `impure_func` uses the global `y` and has a side-effect due to `print`:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个在使用`jax.jit()`后改变行为的 Python 函数，也许你的函数使用了全局状态或具有副作用。在下面的代码中，`impure_func`使用了全局变量`y`并由于`print`而具有副作用：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Without `jit` the output is:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 没有`jit`时的输出是：
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'and with `jit` it is:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 并且使用`jit`时：
- en: '[PRE2]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For `jax.jit()`, the function is executed once using the Python interpreter,
    at which time the `Inside` printing happens, and the first value of `y` is observed.
    Then, the function is compiled and cached, and executed multiple times with different
    values of `x`, but with the same first value of `y`.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`jax.jit()`，函数在 Python 解释器中执行一次，此时发生`Inside`打印，并观察到`y`的第一个值。然后，函数被编译并缓存，以不同的`x`值多次执行，但`y`的第一个值相同。
- en: 'Additional reading:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 更多阅读：
- en: '[JAX - The Sharp Bits](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html)'
  id: totrans-12
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[JAX - 锋利之处](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html)'
- en: '## `jit` changes the exact numerics of outputs'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '## `jit`改变了输出的精确数值'
- en: 'Sometimes users are surprised by the fact that wrapping a function with `jit()`
    can change the function’s outputs. For example:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，用户会对用`jit()`包装一个函数后，函数的输出发生变化感到惊讶。例如：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This slight difference in output comes from optimizations within the XLA compiler:
    during compilation, XLA will sometimes rearrange or elide certain operations to
    make the overall computation more efficient.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这种输出的细微差异来自于 XLA 编译器中的优化：在编译过程中，XLA 有时会重新排列或省略某些操作，以使整体计算更加高效。
- en: In this case, XLA utilizes the properties of the logarithm to replace `log(sqrt(x))`
    with `0.5 * log(x)`, which is a mathematically identical expression that can be
    computed more efficiently than the original. The difference in output comes from
    the fact that floating point arithmetic is only a close approximation of real
    math, so different ways of computing the same expression may have subtly different
    results.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，XLA 利用对数的性质将`log(sqrt(x))`替换为`0.5 * log(x)`，这是一个数学上相同的表达式，可以比原始表达式更有效地计算。输出的差异来自于浮点数运算只是对真实数学的近似，因此计算相同表达式的不同方式可能会有细微的差异。
- en: 'Other times, XLA’s optimizations may lead to even more drastic differences.
    Consider the following example:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 其他时候，XLA 的优化可能导致更加显著的差异。考虑以下例子：
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In non-JIT-compiled op-by-op mode, the result is `inf` because `jnp.exp(x)`
    overflows and returns `inf`. Under JIT, however, XLA recognizes that `log` is
    the inverse of `exp`, and removes the operations from the compiled function, simply
    returning the input. In this case, JIT compilation produces a more accurate floating
    point approximation of the real result.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在非 JIT 编译的逐操作模式下，结果为`inf`，因为`jnp.exp(x)`溢出并返回`inf`。然而，在 JIT 模式下，XLA 认识到`log`是`exp`的反函数，并从编译函数中移除这些操作，简单地返回输入。在这种情况下，JIT
    编译产生了对真实结果更准确的浮点数近似。
- en: 'Unfortunately the full list of XLA’s algebraic simplifications is not well
    documented, but if you’re familiar with C++ and curious about what types of optimizations
    the XLA compiler makes, you can see them in the source code: [algebraic_simplifier.cc](https://github.com/tensorflow/tensorflow/blob/v2.10.0/tensorflow/compiler/xla/service/algebraic_simplifier.cc#L3266).  ##
    `jit` decorated function is very slow to compile'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 遗憾的是，XLA 的代数简化的完整列表文档不是很好，但如果你熟悉 C++ 并且对 XLA 编译器进行的优化类型感兴趣，你可以在源代码中查看它们：[algebraic_simplifier.cc](https://github.com/tensorflow/tensorflow/blob/v2.10.0/tensorflow/compiler/xla/service/algebraic_simplifier.cc#L3266)。##
    `jit`修饰函数编译速度非常慢
- en: If your `jit` decorated function takes tens of seconds (or more!) to run the
    first time you call it, but executes quickly when called again, JAX is taking
    a long time to trace or compile your code.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的`jit`修饰函数在第一次调用时需要数十秒（甚至更长时间！）来运行，但在后续调用时执行速度很快，那么 JAX 正在花费很长时间来追踪或编译你的代码。
- en: This is usually a sign that calling your function generates a large amount of
    code in JAX’s internal representation, typically because it makes heavy use of
    Python control flow such as `for` loops. For a handful of loop iterations, Python
    is OK, but if you need *many* loop iterations, you should rewrite your code to
    make use of JAX’s [structured control flow primitives](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#Structured-control-flow-primitives)
    (such as `lax.scan()`) or avoid wrapping the loop with `jit` (you can still use
    `jit` decorated functions *inside* the loop).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常表明调用你的函数生成了大量 JAX 内部表示的代码，通常是因为它大量使用了 Python 控制流，比如`for`循环。对于少量循环迭代，Python
    是可以接受的，但如果你需要*许多*循环迭代，你应该重写你的代码，利用 JAX 的[结构化控制流原语](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#Structured-control-flow-primitives)（如`lax.scan()`）或避免用`jit`包装循环（你仍然可以在循环内部使用`jit`装饰的函数）。
- en: If you’re not sure if this is the problem, you can try running `jax.make_jaxpr()`
    on your function. You can expect slow compilation if the output is many hundreds
    or thousands of lines long.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不确定问题出在哪里，你可以尝试在你的函数上运行`jax.make_jaxpr()`。如果输出很长，可能会导致编译速度慢。
- en: Sometimes it isn’t obvious how to rewrite your code to avoid Python loops because
    your code makes use of many arrays with different shapes. The recommended solution
    in this case is to make use of functions like `jax.numpy.where()` to do your computation
    on padded arrays with fixed shape.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候不明显如何重写你的代码以避免 Python 循环，因为你的代码使用了多个形状不同的数组。在这种情况下推荐的解决方案是利用像`jax.numpy.where()`这样的函数，在具有固定形状的填充数组上进行计算。
- en: 'If your functions are slow to compile for another reason, please open an issue
    on GitHub.  ## How to use `jit` with methods?'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的函数由于其他原因编译速度很慢，请在 GitHub 上提一个问题。## 如何在方法中使用 `jit`？
- en: 'Most examples of `jax.jit()` concern decorating stand-alone Python functions,
    but decorating a method within a class introduces some complication. For example,
    consider the following simple class, where we’ve used a standard `jit()` annotation
    on a method:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数`jax.jit()`的示例涉及装饰独立的 Python 函数，但在类内部装饰方法会引入一些复杂性。例如，请考虑以下简单的类，我们在方法上使用了标准的`jit()`注解：
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'However, this approach will result in an error when you attempt to call this
    method:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当你尝试调用此方法时，这种方法将导致错误：
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The problem is that the first argument to the function is `self`, which has
    type `CustomClass`, and JAX does not know how to handle this type. There are three
    basic strategies we might use in this case, and we’ll discuss them below.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于函数的第一个参数是`self`，其类型为`CustomClass`，而 JAX 不知道如何处理这种类型。在这种情况下，我们可能会使用三种基本策略，并在下面讨论它们。
- en: 'Strategy 1: JIT-compiled helper function'
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '策略 1: JIT 编译的辅助函数'
- en: 'The most straightforward approach is to create a helper function external to
    the class that can be JIT-decorated in the normal way. For example:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最直接的方法是在类外部创建一个辅助函数，可以像平常一样进行 JIT 装饰。例如：
- en: '[PRE9]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result will work as expected:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将按预期工作：
- en: '[PRE10]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The benefit of such an approach is that it is simple, explicit, and it avoids
    the need to teach JAX how to handle objects of type `CustomClass`. However, you
    may wish to keep all the method logic in the same place.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的好处是简单、明确，避免了教 JAX 如何处理`CustomClass`类型对象的需要。但是，你可能希望将所有方法逻辑保留在同一个地方。
- en: 'Strategy 2: Marking `self` as static'
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '策略 2: 将`self`标记为静态'
- en: 'Another common pattern is to use `static_argnums` to mark the `self` argument
    as static. But this must be done with care to avoid unexpected results. You may
    be tempted to simply do this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见模式是使用`static_argnums`将`self`参数标记为静态。但是必须小心，以避免意外的结果。你可能会简单地这样做：
- en: '[PRE11]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If you call the method, it will no longer raise an error:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你调用该方法，它将不再引发错误：
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'However, there is a catch: if you mutate the object after the first method
    call, the subsequent method call may return an incorrect result:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一个问题：如果在第一次方法调用后修改对象，则后续方法调用可能会返回不正确的结果：
- en: '[PRE13]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Why is this? When you mark an object as static, it will effectively be used
    as a dictionary key in JIT’s internal compilation cache, meaning its hash (i.e.
    `hash(obj)`) equality (i.e. `obj1 == obj2`) and object identity (i.e. `obj1 is
    obj2`) will be assumed to have consistent behavior. The default `__hash__` for
    a custom object is its object ID, and so JAX has no way of knowing that a mutated
    object should trigger a re-compilation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么会这样？当你将对象标记为静态时，它将有效地被用作JIT内部编译缓存中的字典键，这意味着其哈希值（即 `hash(obj)` ）、相等性（即 `obj1
    == obj2` ）和对象身份（即 `obj1 is obj2` ）的行为应保持一致。自定义对象的默认 `__hash__` 是其对象ID，因此JAX无法知道突变对象应触发重新编译。
- en: 'You can partially address this by defining an appropriate `__hash__` and `__eq__`
    methods for your object; for example:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过为对象定义适当的 `__hash__` 和 `__eq__` 方法来部分解决这个问题；例如：
- en: '[PRE14]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: (see the [`object.__hash__()`](https://docs.python.org/3/reference/datamodel.html#object.__hash__
    "(in Python v3.12)") documentation for more discussion of the requirements when
    overriding `__hash__`).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: (参见[`object.__hash__()`](https://docs.python.org/3/reference/datamodel.html#object.__hash__
    "(in Python v3.12)") 的文档，进一步讨论在覆盖 `__hash__` 时的要求)。
- en: This should work correctly with JIT and other transforms **so long as you never
    mutate your object**. Mutations of objects used as hash keys lead to several subtle
    problems, which is why for example mutable Python containers (e.g. [`dict`](https://docs.python.org/3/library/stdtypes.html#dict
    "(in Python v3.12)"), [`list`](https://docs.python.org/3/library/stdtypes.html#list
    "(in Python v3.12)")) don’t define `__hash__`, while their immutable counterparts
    (e.g. [`tuple`](https://docs.python.org/3/library/stdtypes.html#tuple "(in Python
    v3.12)")) do.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 只要你不修改对象，这种方法与JIT和其他转换一起工作正常。将对象用作哈希键的突变会导致几个微妙的问题，这就是为什么例如可变Python容器（如[`dict`](https://docs.python.org/3/library/stdtypes.html#dict
    "(in Python v3.12)")，[`list`](https://docs.python.org/3/library/stdtypes.html#list
    "(in Python v3.12)")）不定义 `__hash__`，而它们的不可变对应物（如[`tuple`](https://docs.python.org/3/library/stdtypes.html#tuple
    "(in Python v3.12)")）会。
- en: If your class relies on in-place mutations (such as setting `self.attr = ...`
    within its methods), then your object is not really “static” and marking it as
    such may lead to problems. Fortunately, there’s another option for this case.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的类依赖于原地突变（比如在其方法中设置 `self.attr = ...`），那么你的对象并非真正“静态”，将其标记为静态可能会导致问题。幸运的是，对于这种情况还有另一种选择。
- en: 'Strategy 3: Making `CustomClass` a PyTree'
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 策略3：将 `CustomClass` 设为PyTree
- en: 'The most flexible approach to correctly JIT-compiling a class method is to
    register the type as a custom PyTree object; see Extending pytrees. This lets
    you specify exactly which components of the class should be treated as static
    and which should be treated as dynamic. Here’s how it might look:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: JIT编译类方法的最灵活方法是将类型注册为自定义的PyTree对象；请参阅扩展pytrees。这样可以明确指定类的哪些组件应视为静态，哪些应视为动态。以下是具体操作：
- en: '[PRE15]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This is certainly more involved, but it solves all the issues associated with
    the simpler approaches used above:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这当然更加复杂，但解决了上述简单方法所带来的所有问题：
- en: '[PRE16]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'So long as your `tree_flatten` and `tree_unflatten` functions correctly handle
    all relevant attributes in the class, you should be able to use objects of this
    type directly as arguments to JIT-compiled functions, without any special annotations.  ##
    Controlling data and computation placement on devices'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '只要你的 `tree_flatten` 和 `tree_unflatten` 函数能正确处理类中所有相关属性，你应该能直接将这种类型的对象用作JIT编译函数的参数，而不需要任何特殊的注释。  ##
    控制数据和计算在设备上的放置'
- en: Let’s first look at the principles of data and computation placement in JAX.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先来看看JAX中数据和计算放置的原则。
- en: 'In JAX, the computation follows data placement. JAX arrays have two placement
    properties: 1) the device where the data resides; and 2) whether it is **committed**
    to the device or not (the data is sometimes referred to as being *sticky* to the
    device).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在JAX中，计算遵循数据放置。JAX数组有两个放置属性：1）数据所在的设备；2）数据是否已**提交**到设备（有时称为数据对设备的*粘性*）。
- en: By default, JAX arrays are placed uncommitted on the default device (`jax.devices()[0]`),
    which is the first GPU or TPU by default. If no GPU or TPU is present, `jax.devices()[0]`
    is the CPU. The default device can be temporarily overridden with the `jax.default_device()`
    context manager, or set for the whole process by setting the environment variable
    `JAX_PLATFORMS` or the absl flag `--jax_platforms` to “cpu”, “gpu”, or “tpu” (`JAX_PLATFORMS`
    can also be a list of platforms, which determines which platforms are available
    in priority order).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，JAX 数组被放置在默认设备上未提交状态 (`jax.devices()[0]`)，这通常是第一个 GPU 或 TPU。如果没有 GPU 或
    TPU 存在，`jax.devices()[0]` 是 CPU。可以通过 `jax.default_device()` 上下文管理器临时覆盖默认设备，或者通过设置环境变量
    `JAX_PLATFORMS` 或 absl 标志 `--jax_platforms` 来设置整个进程的默认设备为 "cpu"、"gpu" 或 "tpu"（`JAX_PLATFORMS`
    也可以是一个平台列表，指定优先顺序中可用的平台）。
- en: '[PRE17]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Computations involving uncommitted data are performed on the default device
    and the results are uncommitted on the default device.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对涉及未提交数据的计算将在默认设备上执行，并且结果也会在默认设备上保持未提交状态。
- en: 'Data can also be placed explicitly on a device using `jax.device_put()` with
    a `device` parameter, in which case the data becomes **committed** to the device:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 数据也可以使用带有 `device` 参数的 `jax.device_put()` 明确地放置到设备上，在这种情况下，数据将会 **提交** 到设备上：
- en: '[PRE18]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Computations involving some committed inputs will happen on the committed device
    and the result will be committed on the same device. Invoking an operation on
    arguments that are committed to more than one device will raise an error.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 包含一些已提交输入的计算将在已提交的设备上执行，并且结果将在同一设备上提交。在已提交到多个设备上的参数上调用操作将会引发错误。
- en: You can also use `jax.device_put()` without a `device` parameter. If the data
    is already on a device (committed or not), it’s left as-is. If the data isn’t
    on any device—that is, it’s a regular Python or NumPy value—it’s placed uncommitted
    on the default device.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以在没有 `device` 参数的情况下使用 `jax.device_put()`。如果数据已经在设备上（无论是已提交还是未提交状态），则保持不变。如果数据不在任何设备上，即它是常规的
    Python 或 NumPy 值，则将其放置在默认设备上未提交状态。
- en: Jitted functions behave like any other primitive operations—they will follow
    the data and will show errors if invoked on data committed on more than one device.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 经过 JIT 编译的函数行为与任何其他基本操作相同——它们会跟随数据，并且如果在提交到多个设备上的数据上调用时将会报错。
- en: '(Before [PR #6002](https://github.com/google/jax/pull/6002) in March 2021 there
    was some laziness in creation of array constants, so that `jax.device_put(jnp.zeros(...),
    jax.devices()[1])` or similar would actually create the array of zeros on `jax.devices()[1]`,
    instead of creating the array on the default device then moving it. But this optimization
    was removed so as to simplify the implementation.)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '(在2021年3月之前的 [PR #6002](https://github.com/google/jax/pull/6002) 中，创建数组常量时存在一些懒惰，因此
    `jax.device_put(jnp.zeros(...), jax.devices()[1])` 或类似的操作实际上会在 `jax.devices()[1]`
    上创建零数组，而不是在默认设备上创建数组然后移动。但为了简化实现，这种优化被移除了。)'
- en: (As of April 2020, `jax.jit()` has a device parameter that affects the device
    placement. That parameter is experimental, is likely to be removed or changed,
    and its use is not recommended.)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: (截至2020年4月，`jax.jit()` 函数有一个影响设备放置的 `device` 参数。该参数是实验性的，可能会被移除或更改，并且不建议使用。)
- en: 'For a worked-out example, we recommend reading through `test_computation_follows_data`
    in [multi_device_test.py](https://github.com/google/jax/blob/main/tests/multi_device_test.py).  ##
    Benchmarking JAX code'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个详细的例子，我们建议阅读 [multi_device_test.py](https://github.com/google/jax/blob/main/tests/multi_device_test.py)
    中的 `test_computation_follows_data`。
- en: You just ported a tricky function from NumPy/SciPy to JAX. Did that actually
    speed things up?
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚将一个复杂的函数从 NumPy/SciPy 移植到 JAX。那真的加快了速度吗？
- en: 'Keep in mind these important differences from NumPy when measuring the speed
    of code using JAX:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用 JAX 测量代码速度时，请记住与 NumPy 的这些重要差异：
- en: '**JAX code is Just-In-Time (JIT) compiled.** Most code written in JAX can be
    written in such a way that it supports JIT compilation, which can make it run
    *much faster* (see [To JIT or not to JIT](https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html#to-jit-or-not-to-jit)).
    To get maximum performance from JAX, you should apply `jax.jit()` on your outer-most
    function calls.'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**JAX 代码是即时编译（JIT）的**。大多数使用 JAX 编写的代码可以以支持 JIT 编译的方式编写，这可以使其运行 *更快*（参见 [To
    JIT or not to JIT](https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html#to-jit-or-not-to-jit)）。为了从
    JAX 中获得最大的性能，应在最外层的函数调用上应用 `jax.jit()`。'
- en: Keep in mind that the first time you run JAX code, it will be slower because
    it is being compiled. This is true even if you don’t use `jit` in your own code,
    because JAX’s builtin functions are also JIT compiled.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请记住，第一次运行 JAX 代码时，它会更慢，因为它正在被编译。即使在您自己的代码中不使用 `jit`，因为 JAX 的内置函数也是 JIT 编译的，这也是真实的。
- en: '**JAX has asynchronous dispatch.** This means that you need to call `.block_until_ready()`
    to ensure that computation has actually happened (see Asynchronous dispatch).'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**JAX 具有异步分派。** 这意味着您需要调用 `.block_until_ready()` 来确保计算实际发生了（参见异步分派）。'
- en: '**JAX by default only uses 32-bit dtypes.** You may want to either explicitly
    use 32-bit dtypes in NumPy or enable 64-bit dtypes in JAX (see [Double (64 bit)
    precision](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#double-64bit-precision))
    for a fair comparison.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**JAX 默认只使用 32 位数据类型。** 您可能希望在 NumPy 中明确使用 32 位数据类型，或者在 JAX 中启用 64 位数据类型（参见[Double
    (64 bit) precision](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#double-64bit-precision)）以进行公平比较。'
- en: '**Transferring data between CPUs and accelerators takes time.** If you only
    want to measure how long it takes to evaluate a function, you may want to transfer
    data to the device on which you want to run it first (see Controlling data and
    computation placement on devices).'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在 CPU 和加速器之间传输数据需要时间。** 如果您只想测量评估函数所需的时间，您可能希望先将数据传输到要运行的设备上（参见控制数据和计算放置在设备上）。'
- en: 'Here’s an example of how to put together all these tricks into a microbenchmark
    for comparing JAX versus NumPy, making using of IPython’s convenient [%time and
    %timeit magics](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-time):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个将所有这些技巧放在一起进行微基准测试以比较 JAX 和 NumPy 的示例，利用 IPython 的便捷的 [%time 和 %timeit
    魔法命令](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-time)：
- en: '[PRE19]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'When run with a GPU in [Colab](https://colab.research.google.com/), we see:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当在 [Colab](https://colab.research.google.com/) 上使用 GPU 运行时，我们看到：
- en: NumPy takes 16.2 ms per evaluation on the CPU
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy 在 CPU 上每次评估需要 16.2 毫秒。
- en: JAX takes 1.26 ms to copy the NumPy arrays onto the GPU
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JAX 将 NumPy 数组复制到 GPU 上花费了 1.26 毫秒。
- en: JAX takes 193 ms to compile the function
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JAX 编译该函数需要 193 毫秒。
- en: JAX takes 485 µs per evaluation on the GPU
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JAX 在 GPU 上每次评估需要 485 微秒。
- en: In this case, we see that once the data is transferred and the function is compiled,
    JAX on the GPU is about 30x faster for repeated evaluations.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们看到一旦数据传输完毕并且函数被编译，JAX 在 GPU 上重复评估时大约快了 30 倍。
- en: Is this a fair comparison? Maybe. The performance that ultimately matters is
    for running full applications, which inevitably include some amount of both data
    transfer and compilation. Also, we were careful to pick large enough arrays (1000x1000)
    and an intensive enough computation (the `@` operator is performing matrix-matrix
    multiplication) to amortize the increased overhead of JAX/accelerators vs NumPy/CPU.
    For example, if we switch this example to use 10x10 input instead, JAX/GPU runs
    10x slower than NumPy/CPU (100 µs vs 10 µs).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这个比较公平吗？也许是。最终重要的性能是运行完整应用程序时的性能，这些应用程序不可避免地包含了一些数据传输和编译。此外，我们小心地选择了足够大的数组（1000x1000）和足够密集的计算（`@`
    操作符执行矩阵乘法），以摊销 JAX/加速器相对于 NumPy/CPU 增加的开销。例如，如果我们将这个例子切换到使用 10x10 的输入，JAX/GPU
    的运行速度比 NumPy/CPU 慢 10 倍（100 µs vs 10 µs）。
- en: '### Is JAX faster than NumPy?'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '### JAX 是否比 NumPy 更快？'
- en: One question users frequently attempt to answer with such benchmarks is whether
    JAX is faster than NumPy; due to the difference in the two packages, there is
    not a simple answer.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 用户经常试图通过这样的基准测试来回答一个问题，即 JAX 是否比 NumPy 更快；由于这两个软件包的差异，这并不是一个简单的问题。
- en: 'Broadly speaking:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 广义上讲：
- en: NumPy operations are executed eagerly, synchronously, and only on CPU.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy 操作是急切地、同步地执行，只在 CPU 上执行。
- en: JAX operations may be executed eagerly or after compilation (if inside `jit()`);
    they are dispatched asynchronously (see Asynchronous dispatch); and they can be
    executed on CPU, GPU, or TPU, each of which have vastly different and continuously
    evolving performance characteristics.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JAX 操作可以被急切地执行或者在编译之后执行（如果在 `jit()` 内部）；它们被异步地分派（参见异步分派）；并且它们可以在 CPU、GPU 或 TPU
    上执行，每种设备都有非常不同且不断演变的性能特征。
- en: These architectural differences make meaningful direct benchmark comparisons
    between NumPy and JAX difficult.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这些架构差异使得直接比较 NumPy 和 JAX 的基准测试变得困难。
- en: 'Additionally, these differences have led to different engineering focus between
    the packages: for example, NumPy has put significant effort into decreasing the
    per-call dispatch overhead for individual array operations, because in NumPy’s
    computational model that overhead cannot be avoided. JAX, on the other hand, has
    several ways to avoid dispatch overhead (e.g. JIT compilation, asynchronous dispatch,
    batching transforms, etc.), and so reducing per-call overhead has been less of
    a priority.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，这些差异还导致了软件包在工程上的不同关注点：例如，NumPy大力减少了单个数组操作的每次调用分派开销，因为在NumPy的计算模型中，这种开销是无法避免的。另一方面，JAX有几种方法可以避免分派开销（例如，JIT编译、异步分派、批处理转换等），因此减少每次调用的开销并不是一个首要任务。
- en: 'Keeping all that in mind, in summary: if you’re doing microbenchmarks of individual
    array operations on CPU, you can generally expect NumPy to outperform JAX due
    to its lower per-operation dispatch overhead. If you’re running your code on GPU
    or TPU, or are benchmarking more complicated JIT-compiled sequences of operations
    on CPU, you can generally expect JAX to outperform NumPy.  ## Different kinds
    of JAX values'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 综上所述，在总结时：如果您在CPU上进行单个数组操作的微基准测试，通常可以预期NumPy由于其较低的每次操作分派开销而胜过JAX。如果您在GPU或TPU上运行代码，或者在CPU上进行更复杂的JIT编译操作序列的基准测试，通常可以预期JAX胜过NumPy。##不同类型的JAX值
- en: In the process of transforming functions, JAX replaces some function arguments
    with special tracer values.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在转换函数过程中，JAX会用特殊的追踪器值替换一些函数参数。
- en: 'You could see this if you use a `print` statement:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用`print`语句，您可以看到这一点：
- en: '[PRE20]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The above code does return the correct value `1.` but it also prints `Traced<ShapedArray(float32[])>`
    for the value of `x`. Normally, JAX handles these tracer values internally in
    a transparent way, e.g., in the numeric JAX primitives that are used to implement
    the `jax.numpy` functions. This is why `jnp.cos` works in the example above.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码确实返回了正确的值`1.`，但它还打印出了`Traced<ShapedArray(float32[])>`作为`x`的值。通常情况下，JAX在内部以透明的方式处理这些追踪器值，例如，在用于实现`jax.numpy`函数的数值JAX原语中。这就是为什么在上面的例子中`jnp.cos`能够正常工作的原因。
- en: 'More precisely, a **tracer** value is introduced for the argument of a JAX-transformed
    function, except the arguments identified by special parameters such as `static_argnums`
    for `jax.jit()` or `static_broadcasted_argnums` for `jax.pmap()`. Typically, computations
    that involve at least a tracer value will produce a tracer value. Besides tracer
    values, there are **regular** Python values: values that are computed outside
    JAX transformations, or arise from above-mentioned static arguments of certain
    JAX transformations, or computed solely from other regular Python values. These
    are the values that are used everywhere in absence of JAX transformations.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 更确切地说，**追踪器**值用于JAX变换函数的参数，除了由`jax.jit()`的特殊参数（如`static_argnums`）或`jax.pmap()`的`static_broadcasted_argnums`标识的参数。通常，涉及至少一个追踪器值的计算将产生一个追踪器值。除了追踪器值之外，还有**常规**Python值：在JAX变换之外计算的值，或者来自上述特定JAX变换的静态参数，或者仅仅是来自其他常规Python值的计算。在缺少JAX变换的情况下，这些值在任何地方都可以使用。
- en: A tracer value carries an **abstract** value, e.g., `ShapedArray` with information
    about the shape and dtype of an array. We will refer here to such tracers as **abstract
    tracers**. Some tracers, e.g., those that are introduced for arguments of autodiff
    transformations, carry `ConcreteArray` abstract values that actually include the
    regular array data, and are used, e.g., for resolving conditionals. We will refer
    here to such tracers as **concrete tracers**. Tracer values computed from these
    concrete tracers, perhaps in combination with regular values, result in concrete
    tracers. A **concrete value** is either a regular value or a concrete tracer.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一个追踪器值携带一个**抽象**值，例如，`ShapedArray`包含有关数组形状和dtype的信息。我们将这些追踪器称为**抽象追踪器**。一些追踪器，例如，为自动微分变换的参数引入的那些，携带包含实际数组数据的`ConcreteArray`抽象值，并且用于解析条件。我们将这些追踪器称为**具体追踪器**。从这些具体追踪器计算出的追踪器值，也许与常规值结合，会产生具体追踪器。**具体值**是指常规值或具体追踪器。
- en: Most often values computed from tracer values are themselves tracer values.
    There are very few exceptions, when a computation can be entirely done using the
    abstract value carried by a tracer, in which case the result can be a regular
    value. For example, getting the shape of a tracer with `ShapedArray` abstract
    value. Another example is when explicitly casting a concrete tracer value to a
    regular type, e.g., `int(x)` or `x.astype(float)`. Another such situation is for
    `bool(x)`, which produces a Python bool when concreteness makes it possible. That
    case is especially salient because of how often it arises in control flow.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，从追踪值计算得到的值本身也是追踪值。只有极少数例外情况，当一个计算可以完全使用追踪器携带的抽象值时，其结果可以是常规值。例如，使用 `ShapedArray`
    抽象值获取追踪器的形状。另一个例子是显式地将具体的追踪器值转换为常规类型，例如 `int(x)` 或 `x.astype(float)`。另一种情况是对 `bool(x)`
    的处理，在具体性允许的情况下会产生 Python 布尔值。由于这种情况在控制流中经常出现，所以这种情况尤为显著。
- en: 'Here is how the transformations introduce abstract or concrete tracers:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是这些转换如何引入抽象或具体追踪器的说明：
- en: '`jax.jit()`: introduces **abstract tracers** for all positional arguments except
    those denoted by `static_argnums`, which remain regular values.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jax.jit()`：除了由 `static_argnums` 指定的位置参数之外，为所有位置参数引入**抽象追踪器**，这些参数保持为常规值。'
- en: '`jax.pmap()`: introduces **abstract tracers** for all positional arguments
    except those denoted by `static_broadcasted_argnums`.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jax.pmap()`：除了由 `static_broadcasted_argnums` 指定的位置参数之外，为所有位置参数引入**抽象追踪器**。'
- en: '`jax.vmap()`, `jax.make_jaxpr()`, `xla_computation()`: introduce **abstract
    tracers** for all positional arguments.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jax.vmap()`、`jax.make_jaxpr()`、`xla_computation()`：为所有位置参数引入**抽象追踪器**。'
- en: '`jax.jvp()` and `jax.grad()` introduce **concrete tracers** for all positional
    arguments. An exception is when these transformations are within an outer transformation
    and the actual arguments are themselves abstract tracers; in that case, the tracers
    introduced by the autodiff transformations are also abstract tracers.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`jax.jvp()` 和 `jax.grad()` 为所有位置参数引入**具体追踪器**。唯一的例外是当这些转换在外部转换内部进行时，实际参数本身就是抽象追踪器时，由自动微分转换引入的追踪器也是抽象追踪器。'
- en: All higher-order control-flow primitives (`lax.cond()`, `lax.while_loop()`,
    `lax.fori_loop()`, `lax.scan()`) when they process the functionals introduce **abstract
    tracers**, whether or not there is a JAX transformation in progress.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有高阶控制流原语（`lax.cond()`、`lax.while_loop()`、`lax.fori_loop()`、`lax.scan()`）在处理函数时引入**抽象追踪器**，无论是否存在
    JAX 转换。
- en: 'All of this is relevant when you have code that can operate only on regular
    Python values, such as code that has conditional control-flow based on data:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 当您的代码仅能操作常规的 Python 值时，例如基于数据的条件控制流的代码时，这些都是相关的：
- en: '[PRE21]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: If we want to apply `jax.jit()`, we must ensure to specify `static_argnums=1`
    to ensure `y` stays a regular value. This is due to the boolean expression `y
    >= 1.`, which requires concrete values (regular or tracers). The same would happen
    if we write explicitly `bool(y >= 1.)`, or `int(y)`, or `float(y)`.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要应用 `jax.jit()`，我们必须确保指定 `static_argnums=1` 以确保 `y` 保持为常规值。这是由于布尔表达式 `y
    >= 1.`，它需要具体的值（常规或追踪器）。如果我们显式地编写 `bool(y >= 1.)`、`int(y)` 或 `float(y)`，也会发生同样的情况。
- en: 'Interestingly, `jax.grad(divide)(3., 2.)`, works because `jax.grad()` uses
    concrete tracers, and resolves the conditional using the concrete value of `y`.  ##
    Buffer donation'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '有趣的是，`jax.grad(divide)(3., 2.)` 是有效的，因为 `jax.grad()` 使用具体追踪器，并使用 `y` 的具体值解析条件。  ##
    缓冲捐赠'
- en: When JAX executes a computation it uses buffers on the device for all inputs
    and outputs. If you know that one of the inputs is not needed after the computation,
    and if it matches the shape and element type of one of the outputs, you can specify
    that you want the corresponding input buffer to be donated to hold an output.
    This will reduce the memory required for the execution by the size of the donated
    buffer.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当 JAX 执行计算时，它使用设备上的缓冲区来处理所有输入和输出。如果您知道某个输入在计算后不再需要，并且它与某个输出的形状和元素类型匹配，您可以指定要捐赠相应输入的缓冲区来保存输出。这将减少执行所需的内存，减少捐赠缓冲区的大小。
- en: 'If you have something like the following pattern, you can use buffer donation:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有类似以下模式的情况，可以使用缓冲捐赠：
- en: '[PRE22]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: You can think of this as a way to do a memory-efficient functional update on
    your immutable JAX arrays. Within the boundaries of a computation XLA can make
    this optimization for you, but at the jit/pmap boundary you need to guarantee
    to XLA that you will not use the donated input buffer after calling the donating
    function.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将此视为一种在不可变JAX数组上进行内存高效的函数更新的方法。在计算的XLA边界内，XLA可以为您进行此优化，但在jit/pmap边界处，您需要向XLA保证在调用捐赠函数后不会再使用捐赠的输入缓冲区。
- en: 'You achieve this by using the donate_argnums parameter to the functions `jax.jit()`,
    `jax.pjit()`, and `jax.pmap()`. This parameter is a sequence of indices (0 based)
    into the positional argument list:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在函数`jax.jit()`、`jax.pjit()`和`jax.pmap()`中使用`donate_argnums`参数来实现这一点。此参数是位置参数列表（从0开始）的索引序列：
- en: '[PRE23]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Note that this currently does not work when calling your function with key-word
    arguments! The following code will not donate any buffers:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果使用关键字参数调用函数，则此方法目前不起作用！以下代码不会捐赠任何缓冲区：
- en: '[PRE24]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'If an argument whose buffer is donated is a pytree, then all the buffers for
    its components are donated:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个参数的缓冲区被捐赠，且其为pytree，则其所有组件的缓冲区都会被捐赠：
- en: '[PRE25]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'It is not allowed to donate a buffer that is used subsequently in the computation,
    and JAX will give an error because the buffer for y has become invalid after it
    was donated:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 不允许捐赠随后在计算中使用的缓冲区，因此在y的缓冲区捐赠后，JAX会报错因为该缓冲区已失效：
- en: '[PRE26]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You will get a warning if the donated buffer is not used, e.g., because there
    are more donated buffers than can be used for the outputs:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果捐赠的缓冲区未被使用，则会收到警告，例如因为捐赠的缓冲区多于输出所需：
- en: '[PRE27]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The donation may also be unused if there is no output whose shape matches the
    donation:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有输出的形状与捐赠匹配，则捐赠可能也不会被使用：
- en: '[PRE28]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Gradients contain NaN where using `where`
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用`where`时，梯度包含NaN
- en: 'If you define a function using `where` to avoid an undefined value, if you
    are not careful you may obtain a `NaN` for reverse differentiation:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果定义一个使用`where`来避免未定义值的函数，如果不小心可能会得到一个反向微分的`NaN`：
- en: '[PRE29]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'A short explanation is that during `grad` computation the adjoint corresponding
    to the undefined `jnp.log(x)` is a `NaN` and it gets accumulated to the adjoint
    of the `jnp.where`. The correct way to write such functions is to ensure that
    there is a `jnp.where` *inside* the partially-defined function, to ensure that
    the adjoint is always finite:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，在`grad`计算期间，对于未定义的`jnp.log(x)`的伴随是`NaN`，并且会累积到`jnp.where`的伴随中。正确的编写这类函数的方法是确保在部分定义的函数*内部*有一个`jnp.where`，以确保伴随始终是有限的：
- en: '[PRE30]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The inner `jnp.where` may be needed in addition to the original one, e.g.:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 除原始`jnp.where`外可能还需要内部的`jnp.where`，例如：
- en: '[PRE31]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Additional reading:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步阅读：
- en: '[Issue: gradients through jnp.where when one of branches is nan](https://github.com/google/jax/issues/1052#issuecomment-514083352).'
  id: totrans-137
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[问题：当一个分支是NaN时通过jnp.where的梯度](https://github.com/google/jax/issues/1052#issuecomment-514083352)。'
- en: ''
  id: totrans-138
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-139
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: '[How to avoid NaN gradients when using where](https://github.com/tensorflow/probability/blob/master/discussion/where-nan.pdf).'
  id: totrans-140
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在使用where时避免NaN梯度](https://github.com/tensorflow/probability/blob/master/discussion/where-nan.pdf)。'
- en: Why are gradients zero for functions based on sort order?
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于排序顺序的函数为何梯度为零？
- en: 'If you define a function that processes the input using operations that depend
    on the relative ordering of inputs (e.g. `max`, `greater`, `argsort`, etc.) then
    you may be surprised to find that the gradient is everywhere zero. Here is an
    example, where we define f(x) to be a step function that returns 0 when x is negative,
    and 1 when x is positive:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果定义一个处理输入的函数，并使用依赖于输入相对顺序的操作（例如`max`、`greater`、`argsort`等），那么可能会惊讶地发现梯度在所有位置都为零。以下是一个例子，我们定义f(x)为一个阶跃函数，在x为负时返回0，在x为正时返回1：
- en: '[PRE32]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The fact that the gradient is everywhere zero may be confusing at first glance:
    after all, the output does change in response to the input, so how can the gradient
    be zero? However, zero turns out to be the correct result in this case.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然输出对输入有响应，但梯度在所有位置为零可能会令人困惑：毕竟，输出确实随输入而变化，那么梯度怎么可能是零呢？然而，在这种情况下，零确实是正确的结果。
- en: 'Why is this? Remember that what differentiation is measuring the change in
    `f` given an infinitesimal change in `x`. For `x=1.0`, `f` returns `1.0`. If we
    perturb `x` to make it slightly larger or smaller, this does not change the output,
    so by definition, `grad(f)(1.0)` should be zero. This same logic holds for all
    values of `f` greater than zero: infinitesimally perturbing the input does not
    change the output, so the gradient is zero. Similarly, for all values of `x` less
    than zero, the output is zero. Perturbing `x` does not change this output, so
    the gradient is zero. That leaves us with the tricky case of `x=0`. Surely, if
    you perturb `x` upward, it will change the output, but this is problematic: an
    infinitesimal change in `x` produces a finite change in the function value, which
    implies the gradient is undefined. Fortunately, there’s another way for us to
    measure the gradient in this case: we perturb the function downward, in which
    case the output does not change, and so the gradient is zero. JAX and other autodiff
    systems tend to handle discontinuities in this way: if the positive gradient and
    negative gradient disagree, but one is defined and the other is not, we use the
    one that is defined. Under this definition of the gradient, mathematically and
    numerically the gradient of this function is everywhere zero.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这是为什么？请记住，微分测量的是给定 `x` 中 `f` 的变化。对于 `x=1.0`，`f` 返回 `1.0`。如果我们微扰 `x` 使其稍大或稍小，这并不会改变输出，因此根据定义，`grad(f)(1.0)`
    应该为零。对于所有大于零的 `f` 值，此逻辑同样成立：微扰输入不会改变输出，因此梯度为零。同样，对于所有小于零的 `x` 值，输出为零。微扰 `x` 不会改变这个输出，因此梯度为零。这让我们面对
    `x=0` 的棘手情况。当然，如果你向上微扰 `x`，它会改变输出，但这是有问题的：`x` 的微小变化会产生函数值的有限变化，这意味着梯度是未定义的。幸运的是，在这种情况下我们还有另一种方法来测量梯度：我们向下微扰函数，此时输出不变，因此梯度为零。JAX
    和其他自动微分系统倾向于以这种方式处理不连续性：如果正梯度和负梯度不一致，但其中一个被定义，另一个未定义，我们使用被定义的那个。根据梯度的这一定义，从数学和数值上来说，此函数的梯度在任何地方都是零。
- en: 'The problem stems from the fact that our function has a discontinuity at `x
    = 0`. Our `f` here is essentially a [Heaviside Step Function](https://en.wikipedia.org/wiki/Heaviside_step_function),
    and we can use a [Sigmoid Function](https://en.wikipedia.org/wiki/Sigmoid_function)
    as a smoothed replacement. The sigmoid is approximately equal to the heaviside
    function when x is far from zero, but replaces the discontinuity at `x = 0` with
    a smooth, differentiable curve. As a result of using `jax.nn.sigmoid()`, we get
    a similar computation with well-defined gradients:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于我们的函数在 `x = 0` 处有不连续点。我们的 `f` 本质上是一个 [Heaviside Step Function](https://en.wikipedia.org/wiki/Heaviside_step_function)，我们可以使用
    [Sigmoid Function](https://en.wikipedia.org/wiki/Sigmoid_function) 作为平滑替代。当 `x`
    远离零时，Sigmoid 函数近似等于 Heaviside 函数，但在 `x = 0` 处用一个平滑的、可微的曲线替换不连续性。通过使用 `jax.nn.sigmoid()`，我们得到一个具有良定义梯度的类似计算：
- en: '[PRE33]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The `jax.nn` submodule also has smooth versions of other common rank-based functions,
    for example `jax.nn.softmax()` can replace uses of `jax.numpy.argmax()`, `jax.nn.soft_sign()`
    can replace uses of `jax.numpy.sign()`, `jax.nn.softplus()` or `jax.nn.squareplus()`
    can replace uses of `jax.nn.relu()`, etc.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`jax.nn` 子模块还有其他常见基于排名的函数的平滑版本，例如 `jax.nn.softmax()` 可以替换 `jax.numpy.argmax()`
    的使用，`jax.nn.soft_sign()` 可以替换 `jax.numpy.sign()` 的使用，`jax.nn.softplus()` 或 `jax.nn.squareplus()`
    可以替换 `jax.nn.relu()` 的使用，等等。'
- en: How can I convert a JAX Tracer to a NumPy array?
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我如何将 JAX 追踪器转换为 NumPy 数组？
- en: 'When inspecting a transformed JAX function at runtime, you’ll find that array
    values are replaced by `Tracer` objects:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行时检查转换后的 JAX 函数时，您会发现数组值被 `Tracer` 对象替换：
- en: '[PRE34]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This prints the following:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印如下内容：
- en: '[PRE35]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: A frequent question is how such a tracer can be converted back to a normal NumPy
    array. In short, **it is impossible to convert a Tracer to a NumPy array**, because
    a tracer is an abstract representation of *every possible* value with a given
    shape and dtype, while a numpy array is a concrete member of that abstract class.
    For more discussion of how tracers work within the context of JAX transformations,
    see [JIT mechanics](https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html#jit-mechanics-tracing-and-static-variables).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的问题是如何将这样的追踪器转换回正常的 NumPy 数组。简而言之，**无法将追踪器转换为 NumPy 数组**，因为追踪器是具有给定形状和数据类型的*每一个可能*值的抽象表示，而
    NumPy 数组是该抽象类的具体成员。有关在 JAX 转换环境中追踪器工作的更多讨论，请参阅 [JIT mechanics](https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html#jit-mechanics-tracing-and-static-variables)。
- en: 'The question of converting Tracers back to arrays usually comes up within the
    context of another goal, related to accessing intermediate values in a computation
    at runtime. For example:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 将跟踪器转换回数组的问题通常出现在与运行时访问计算中的中间值相关的另一个目标的背景下。例如：
- en: If you wish to print a traced value at runtime for debugging purposes, you might
    consider using `jax.debug.print()`.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您希望出于调试目的在运行时打印跟踪值，您可以考虑使用`jax.debug.print()`。
- en: If you wish to call non-JAX code within a transformed JAX function, you might
    consider using `jax.pure_callback()`, an example of which is available at [Pure
    callback example](https://jax.readthedocs.io/en/latest/notebooks/external_callbacks.html#example-pure-callback-with-custom-jvp).
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您希望在转换后的JAX函数中调用非JAX代码，您可以考虑使用`jax.pure_callback()`，其示例可在[纯回调示例](https://jax.readthedocs.io/en/latest/notebooks/external_callbacks.html#example-pure-callback-with-custom-jvp)中找到。
- en: If you wish to input or output array buffers at runtime (for example, load data
    from file, or log the contents of the array to disk), you might consider using
    `jax.experimental.io_callback()`, an example of which can be found at [IO callback
    example](https://jax.readthedocs.io/en/latest/notebooks/external_callbacks.html#exploring-jax-experimental-io-callback).
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您希望在运行时输入或输出数组缓冲区（例如，从文件加载数据或将数组内容记录到磁盘），您可以考虑使用`jax.experimental.io_callback()`，其示例可在[IO回调示例](https://jax.readthedocs.io/en/latest/notebooks/external_callbacks.html#exploring-jax-experimental-io-callback)中找到。
- en: For more information on runtime callbacks and examples of their use, see [External
    callbacks in JAX](https://jax.readthedocs.io/en/latest/notebooks/external_callbacks.html).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 关于运行时回调的更多信息和它们的使用示例，请参阅[JAX中的外部回调](https://jax.readthedocs.io/en/latest/notebooks/external_callbacks.html)。
- en: Why do some CUDA libraries fail to load/initialize?
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么会有些CUDA库加载/初始化失败？
- en: When resolving dynamic libraries, JAX uses the usual [dynamic linker search
    pattern](https://man7.org/linux/man-pages/man8/ld.so.8.html). JAX sets `RPATH`
    to point to the JAX-relative location of the pip-installed NVIDIA CUDA packages,
    preferring them if installed. If `ld.so` cannot find your CUDA runtime libraries
    along its usual search path, then you must include the paths to those libraries
    explicitly in `LD_LIBRARY_PATH`. The easiest way to ensure your CUDA files are
    discoverable is to simply install the `nvidia-*-cu12` pip packages, which are
    included in the standard `jax[cuda_12]` install option.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在解析动态库时，JAX使用通常的[动态链接器搜索模式](https://man7.org/linux/man-pages/man8/ld.so.8.html)。JAX将`RPATH`设置为指向通过pip安装的NVIDIA
    CUDA软件包的JAX相对位置，如果安装了这些软件包，则优先使用它们。如果`ld.so`在其通常的搜索路径中找不到您的CUDA运行时库，则必须在`LD_LIBRARY_PATH`中显式包含这些库的路径。确保您的CUDA文件可被发现的最简单方法是简单地安装标准的`jax[cuda_12]`安装选项中包含的`nvidia-*-cu12`
    pip软件包。
- en: Occasionally, even when you have ensured that your runtime libraries are discoverable,
    there may still be some issues with loading or initializing them. A common cause
    of such issues is simply having insufficient memory for CUDA library initialization
    at runtime. This sometimes occurs because JAX will pre-allocate too large of a
    chunk of currently available device memory for faster execution, occasionally
    resulting in insufficient memory being left available for runtime CUDA library
    initialization.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 偶尔，即使您确保您的运行时库可被发现，仍可能存在加载或初始化的问题。这类问题的常见原因是运行时CUDA库初始化时内存不足。这有时是因为JAX将预分配当前可用设备内存的太大一部分以提高执行速度，偶尔会导致没有足够的内存留给运行时CUDA库初始化。
- en: This is especially likely when running multiple JAX instances, running JAX in
    tandem with TensorFlow which performs its own pre-allocation, or when running
    JAX on a system where the GPU is being heavily utilized by other processes. When
    in doubt, try running the program again with reduced pre-allocation, either by
    reducing `XLA_PYTHON_CLIENT_MEM_FRACTION` from the default of `.75`, or setting
    `XLA_PYTHON_CLIENT_PREALLOCATE=false`. For more details, please see the page on
    [JAX GPU memory allocation](https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行多个JAX实例、与执行自己的预分配的TensorFlow并行运行JAX，或者在GPU被其他进程大量使用的系统上运行JAX时，特别容易发生这种情况。如果有疑问，请尝试使用减少预分配来重新运行程序，可以通过减少`XLA_PYTHON_CLIENT_MEM_FRACTION`（默认为`.75`）或设置`XLA_PYTHON_CLIENT_PREALLOCATE=false`来实现。有关更多详细信息，请参阅[JAX
    GPU内存分配](https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html)页面。
