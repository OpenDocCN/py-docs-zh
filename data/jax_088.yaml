- en: GPU memory allocation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU 内存分配
- en: 原文：[`jax.readthedocs.io/en/latest/gpu_memory_allocation.html`](https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[`jax.readthedocs.io/en/latest/gpu_memory_allocation.html`](https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html)
- en: '**JAX will preallocate 75% of the total GPU memory when the first JAX operation
    is run.** Preallocating minimizes allocation overhead and memory fragmentation,
    but can sometimes cause out-of-memory (OOM) errors. If your JAX process fails
    with OOM, the following environment variables can be used to override the default
    behavior:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**当第一个 JAX 操作运行时，JAX 将预先分配总 GPU 内存的 75%。** 预先分配可以最小化分配开销和内存碎片化，但有时会导致内存不足（OOM）错误。如果您的
    JAX 进程因内存不足而失败，可以使用以下环境变量来覆盖默认行为：'
- en: '`XLA_PYTHON_CLIENT_PREALLOCATE=false`'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '`XLA_PYTHON_CLIENT_PREALLOCATE=false`'
- en: This disables the preallocation behavior. JAX will instead allocate GPU memory
    as needed, potentially decreasing the overall memory usage. However, this behavior
    is more prone to GPU memory fragmentation, meaning a JAX program that uses most
    of the available GPU memory may OOM with preallocation disabled.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这将禁用预分配行为。JAX 将根据需要分配 GPU 内存，可能会减少总体内存使用。但是，这种行为更容易导致 GPU 内存碎片化，这意味着使用大部分可用
    GPU 内存的 JAX 程序可能会在禁用预分配时发生 OOM。
- en: '`XLA_PYTHON_CLIENT_MEM_FRACTION=.XX`'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '`XLA_PYTHON_CLIENT_MEM_FRACTION=.XX`'
- en: If preallocation is enabled, this makes JAX preallocate XX% of the total GPU
    memory, instead of the default 75%. Lowering the amount preallocated can fix OOMs
    that occur when the JAX program starts.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果启用了预分配，这将使 JAX 预分配总 GPU 内存的 XX% ，而不是默认的 75%。减少预分配量可以修复 JAX 程序启动时的内存不足问题。
- en: '`XLA_PYTHON_CLIENT_ALLOCATOR=platform`'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '`XLA_PYTHON_CLIENT_ALLOCATOR=platform`'
- en: This makes JAX allocate exactly what is needed on demand, and deallocate memory
    that is no longer needed (note that this is the only configuration that will deallocate
    GPU memory, instead of reusing it). This is very slow, so is not recommended for
    general use, but may be useful for running with the minimal possible GPU memory
    footprint or debugging OOM failures.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得 JAX 根据需求精确分配内存，并释放不再需要的内存（请注意，这是唯一会释放 GPU 内存而不是重用它的配置）。这样做非常慢，因此不建议用于一般用途，但可能对于以最小可能的
    GPU 内存占用运行或调试 OOM 失败非常有用。
- en: Common causes of OOM failures
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OOM 失败的常见原因
- en: '**Running multiple JAX processes concurrently.**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**同时运行多个 JAX 进程。**'
- en: Either use `XLA_PYTHON_CLIENT_MEM_FRACTION` to give each process an appropriate
    amount of memory, or set `XLA_PYTHON_CLIENT_PREALLOCATE=false`.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要么使用 `XLA_PYTHON_CLIENT_MEM_FRACTION` 为每个进程分配适当的内存量，要么设置 `XLA_PYTHON_CLIENT_PREALLOCATE=false`。
- en: '**Running JAX and GPU TensorFlow concurrently.**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**同时运行 JAX 和 GPU TensorFlow。**'
- en: TensorFlow also preallocates by default, so this is similar to running multiple
    JAX processes concurrently.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 默认也会预分配，因此这与同时运行多个 JAX 进程类似。
- en: One solution is to use CPU-only TensorFlow (e.g. if you’re only doing data loading
    with TF). You can prevent TensorFlow from using the GPU with the command `tf.config.experimental.set_visible_devices([],
    "GPU")`
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个解决方案是仅使用 CPU TensorFlow（例如，如果您仅使用 TF 进行数据加载）。您可以使用命令 `tf.config.experimental.set_visible_devices([],
    "GPU")` 阻止 TensorFlow 使用 GPU。
- en: 'Alternatively, use `XLA_PYTHON_CLIENT_MEM_FRACTION` or `XLA_PYTHON_CLIENT_PREALLOCATE`.
    There are also similar options to configure TensorFlow’s GPU memory allocation
    ([gpu_memory_fraction](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L36)
    and [allow_growth](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L40)
    in TF1, which should be set in a `tf.ConfigProto` passed to `tf.Session`. See
    [Using GPUs: Limiting GPU memory growth](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)
    for TF2).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，使用 `XLA_PYTHON_CLIENT_MEM_FRACTION` 或 `XLA_PYTHON_CLIENT_PREALLOCATE`。还有类似的选项可以配置
    TensorFlow 的 GPU 内存分配（[gpu_memory_fraction](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L36)
    和 [allow_growth](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L40)
    在 TF1 中应该设置在传递给 `tf.Session` 的 `tf.ConfigProto` 中。参见 [使用 GPU：限制 GPU 内存增长](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)
    用于 TF2）。
- en: '**Running JAX on the display GPU.**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**在显示 GPU 上运行 JAX。**'
- en: Use `XLA_PYTHON_CLIENT_MEM_FRACTION` or `XLA_PYTHON_CLIENT_PREALLOCATE`.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `XLA_PYTHON_CLIENT_MEM_FRACTION` 或 `XLA_PYTHON_CLIENT_PREALLOCATE`。
